{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martintmv-git/photogrammetry/blob/main/LoRA%20Training/notebook/HF_AutoTrain_ngrok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "II6F7ThkI10I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f608e2ea-d3a3-45c9-c2eb-fb6bb501cabc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-09 12:00:01\u001b[0m | \u001b[36mautotrain.cli.run_app\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mAutoTrain Public URL: NgrokTunnel: \"https://79d6-34-121-12-35.ngrok-free.app\" -> \"http://localhost:7860\"\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-09 12:00:01\u001b[0m | \u001b[36mautotrain.cli.run_app\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mPlease wait for the app to load...\u001b[0m\n",
            "Your installed package `nvidia-ml-py` is corrupted. Skip patch functions `nvmlDeviceGet{Compute,Graphics,MPSCompute}RunningProcesses`. You may get incorrect or incomplete results. Please consider reinstall package `nvidia-ml-py` via `pip3 install --force-reinstall nvidia-ml-py nvitop`.\n",
            "Your installed package `nvidia-ml-py` is corrupted. Skip patch functions `nvmlDeviceGetMemoryInfo`. You may get incorrect or incomplete results. Please consider reinstall package `nvidia-ml-py` via `pip3 install --force-reinstall nvidia-ml-py nvitop`.\n",
            "INFO     | 2024-06-09 12:00:06 | autotrain.app.ui_routes:<module>:30 - Starting AutoTrain...\n",
            "INFO     | 2024-06-09 12:00:08 | autotrain.app.ui_routes:<module>:287 - AutoTrain started successfully\n",
            "INFO     | 2024-06-09 12:00:08 | autotrain.app.app:<module>:13 - Starting AutoTrain...\n",
            "INFO     | 2024-06-09 12:00:08 | autotrain.app.app:<module>:23 - AutoTrain version: 0.7.118\n",
            "INFO     | 2024-06-09 12:00:08 | autotrain.app.app:<module>:24 - AutoTrain started successfully\n",
            "INFO:     Started server process [1306]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:7860 (Press CTRL+C to quit)\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET / HTTP/1.1\" 307 Temporary Redirect\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/ HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /static/scripts/listeners.js?cb=2024-06-09%2012:00:13 HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /static/scripts/poll.js?cb=2024-06-09%2012:00:13 HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /static/scripts/fetch_data_and_update_models.js?cb=2024-06-09%2012:00:13 HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /static/scripts/utils.js?cb=2024-06-09%2012:00:13 HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /static/scripts/logs.js?cb=2024-06-09%2012:00:13 HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/model_choices/llm%3Asft HTTP/1.1\" 200 OK\n",
            "INFO     | 2024-06-09 12:00:14 | autotrain.app.ui_routes:fetch_params:370 - Task: llm:sft\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/params/llm%3Asft/basic HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/model_choices/dreambooth HTTP/1.1\" 200 OK\n",
            "INFO     | 2024-06-09 12:00:29 | autotrain.app.ui_routes:fetch_params:370 - Task: dreambooth\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/params/dreambooth/basic HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.app.ui_routes:handle_form:483 - hardware: local-ui\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img1.jpeg', size=417521, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img1.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img2.jpeg', size=1016652, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img2.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img3.jpeg', size=1058536, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img3.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img4.jpeg', size=1067803, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img4.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img5.jpeg', size=1030979, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img5.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img6.jpeg', size=282210, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img6.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img7.jpeg', size=135852, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img7.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img8.jpeg', size=215067, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img8.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img9.jpeg', size=7277823, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img9.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img10.jpeg', size=228187, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img10.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img11.jpeg', size=8570856, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img11.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img12.jpeg', size=750102, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img12.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img13.jpeg', size=1205303, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img13.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img14.jpeg', size=278598, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img14.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img15.jpeg', size=138598, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img15.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img16.jpeg', size=317541, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img16.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img17.jpeg', size=396817, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img17.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img18.jpeg', size=71920, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img18.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:08:13 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img19.jpeg', size=1280001, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img19.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"POST /ui/create_project HTTP/1.1\" 500 Internal Server Error\n",
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/protocols/http/httptools_impl.py\", line 411, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/middleware/proxy_headers.py\", line 69, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/applications.py\", line 1054, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/applications.py\", line 123, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/exceptions.py\", line 65, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 64, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 756, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 776, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 297, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 77, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 64, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 72, in app\n",
            "    response = await func(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 278, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 191, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autotrain/app/ui_routes.py\", line 622, in handle_form\n",
            "    params = app_params.munge()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autotrain/app/params.py\", line 162, in munge\n",
            "    return self._munge_params_dreambooth()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autotrain/app/params.py\", line 377, in _munge_params_dreambooth\n",
            "    return DreamBoothTrainingParams(**_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autotrain/trainers/common.py\", line 163, in __init__\n",
            "    raise ValueError(\"project_name must be alphanumeric but can contain hyphens\")\n",
            "ValueError: project_name must be alphanumeric but can contain hyphens\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.app.ui_routes:handle_form:483 - hardware: local-ui\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img1.jpeg', size=417521, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img1.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img2.jpeg', size=1016652, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img2.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img3.jpeg', size=1058536, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img3.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img4.jpeg', size=1067803, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img4.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img5.jpeg', size=1030979, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img5.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img6.jpeg', size=282210, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img6.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img7.jpeg', size=135852, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img7.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img8.jpeg', size=215067, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img8.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img9.jpeg', size=7277823, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img9.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img10.jpeg', size=228187, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img10.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img11.jpeg', size=8570856, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img11.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img12.jpeg', size=750102, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img12.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img13.jpeg', size=1205303, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img13.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img14.jpeg', size=278598, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img14.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img15.jpeg', size=138598, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img15.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img16.jpeg', size=317541, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img16.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img17.jpeg', size=396817, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img17.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img18.jpeg', size=71920, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img18.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:67 - Saving concept images\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.preprocessor.dreambooth:_save_concept_images:68 - UploadFile(filename='img19.jpeg', size=1280001, headers=Headers({'content-disposition': 'form-data; name=\"data_files_training\"; filename=\"img19.jpeg\"', 'content-type': 'image/jpeg'}))\n",
            "WARNING  | 2024-06-09 12:09:02 | autotrain.trainers.common:__init__:180 - Parameters supplied but not used: data_path\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.backends.local:create:8 - Starting local training...\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.commands:launch_command:386 - ['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'advertisement-photography-SD15-LoRA/training_params.json']\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.commands:launch_command:387 - {'model': 'digiplay/Photon_v1', 'vae_model': '', 'revision': None, 'tokenizer': None, 'image_path': 'advertisement-photography-SD15-LoRA/autotrain-data', 'class_image_path': None, 'prompt': 'advertisement photography', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'advertisement-photography-SD15-LoRA', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 500, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': False, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'martintmv', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\n",
            "INFO     | 2024-06-09 12:09:02 | autotrain.backends.local:create:13 - Training PID: 3535\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"POST /ui/create_project HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "WARNING  | 2024-06-09 12:09:06 | __main__:train:39 - Failed to download dataset: 404 Client Error. (Request ID: Root=1-66659b62-76154cc06a0ecfe443f94dad;44f6d94c-92d9-459f-87ea-bd5a83662dc6)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/advertisement-photography-SD15-LoRA/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'timestep_spacing', 'variance_type', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "{'force_upcast', 'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "{'addition_time_embed_dim', 'num_attention_heads', 'dropout', 'attention_type', 'reverse_transformer_layers_per_block', 'transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
            "INFO     | 2024-06-09 12:10:10 | autotrain.trainers.dreambooth.train:main:748 - ***** Running training *****\n",
            "INFO     | 2024-06-09 12:10:10 | autotrain.trainers.dreambooth.train:main:749 -   Num examples = 19\n",
            "INFO     | 2024-06-09 12:10:10 | autotrain.trainers.dreambooth.train:main:750 -   Num batches each epoch = 19\n",
            "INFO     | 2024-06-09 12:10:10 | autotrain.trainers.dreambooth.train:main:751 -   Num Epochs = 100\n",
            "INFO     | 2024-06-09 12:10:10 | autotrain.trainers.dreambooth.train:main:752 -   Instantaneous batch size per device = 1\n",
            "INFO     | 2024-06-09 12:10:10 | autotrain.trainers.dreambooth.train:main:753 -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "INFO     | 2024-06-09 12:10:10 | autotrain.trainers.dreambooth.train:main:754 -   Gradient Accumulation steps = 4\n",
            "INFO     | 2024-06-09 12:10:10 | autotrain.trainers.dreambooth.train:main:755 -   Total optimization steps = 500\n",
            "\n",
            "Steps:   0%|          | 0/500 [00:00<?, ?it/s]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   0%|          | 0/500 [00:06<?, ?it/s, loss=0.678, lr=0.0001]\n",
            "Steps:   0%|          | 0/500 [00:08<?, ?it/s, loss=0.0233, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   0%|          | 0/500 [00:11<?, ?it/s, loss=0.299, lr=0.0001] \n",
            "Steps:   0%|          | 1/500 [00:14<1:58:43, 14.28s/it, loss=0.299, lr=0.0001]\n",
            "Steps:   0%|          | 1/500 [00:14<1:58:43, 14.28s/it, loss=0.00975, lr=0.0001]\n",
            "Steps:   0%|          | 1/500 [00:16<1:58:43, 14.28s/it, loss=0.0153, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   0%|          | 1/500 [00:19<1:58:43, 14.28s/it, loss=0.123, lr=0.0001] \n",
            "Steps:   0%|          | 1/500 [00:22<1:58:43, 14.28s/it, loss=0.0474, lr=0.0001]\n",
            "Steps:   0%|          | 2/500 [00:24<1:41:03, 12.18s/it, loss=0.0474, lr=0.0001]\n",
            "Steps:   0%|          | 2/500 [00:24<1:41:03, 12.18s/it, loss=0.183, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   0%|          | 2/500 [00:29<1:41:03, 12.18s/it, loss=0.00788, lr=0.0001]\n",
            "Steps:   0%|          | 2/500 [00:31<1:41:03, 12.18s/it, loss=0.107, lr=0.0001]  INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   0%|          | 2/500 [00:34<1:41:03, 12.18s/it, loss=0.218, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   1%|          | 3/500 [00:37<1:41:23, 12.24s/it, loss=0.218, lr=0.0001]\n",
            "Steps:   1%|          | 3/500 [00:37<1:41:23, 12.24s/it, loss=0.291, lr=0.0001]\n",
            "Steps:   1%|          | 3/500 [00:39<1:41:23, 12.24s/it, loss=0.0959, lr=0.0001]\n",
            "Steps:   1%|          | 3/500 [00:42<1:41:23, 12.24s/it, loss=0.0215, lr=0.0001]\n",
            "Steps:   1%|          | 3/500 [00:45<1:41:23, 12.24s/it, loss=0.103, lr=0.0001] \n",
            "Steps:   1%|          | 4/500 [00:48<1:37:23, 11.78s/it, loss=0.103, lr=0.0001]\n",
            "Steps:   1%|          | 4/500 [00:48<1:37:23, 11.78s/it, loss=0.0912, lr=0.0001]\n",
            "Steps:   1%|          | 4/500 [00:51<1:37:23, 11.78s/it, loss=0.117, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   1%|          | 4/500 [00:53<1:37:23, 11.78s/it, loss=0.1, lr=0.0001]  INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   1%|          | 5/500 [00:56<1:26:07, 10.44s/it, loss=0.1, lr=0.0001]\n",
            "Steps:   1%|          | 5/500 [00:56<1:26:07, 10.44s/it, loss=0.0027, lr=0.0001]\n",
            "Steps:   1%|          | 5/500 [00:59<1:26:07, 10.44s/it, loss=0.0335, lr=0.0001]\n",
            "Steps:   1%|          | 5/500 [01:01<1:26:07, 10.44s/it, loss=0.00974, lr=0.0001]\n",
            "Steps:   1%|          | 5/500 [01:04<1:26:07, 10.44s/it, loss=0.0633, lr=0.0001] \n",
            "Steps:   1%|          | 6/500 [01:07<1:27:22, 10.61s/it, loss=0.0633, lr=0.0001]\n",
            "Steps:   1%|          | 6/500 [01:07<1:27:22, 10.61s/it, loss=0.0105, lr=0.0001]\n",
            "Steps:   1%|          | 6/500 [01:10<1:27:22, 10.61s/it, loss=0.0755, lr=0.0001]\n",
            "Steps:   1%|          | 6/500 [01:13<1:27:22, 10.61s/it, loss=0.00768, lr=0.0001]\n",
            "Steps:   1%|          | 6/500 [01:15<1:27:22, 10.61s/it, loss=0.237, lr=0.0001]  \n",
            "Steps:   1%|▏         | 7/500 [01:18<1:28:31, 10.77s/it, loss=0.237, lr=0.0001]\n",
            "Steps:   1%|▏         | 7/500 [01:18<1:28:31, 10.77s/it, loss=0.0563, lr=0.0001]\n",
            "Steps:   1%|▏         | 7/500 [01:21<1:28:31, 10.77s/it, loss=0.4, lr=0.0001]   \n",
            "Steps:   1%|▏         | 7/500 [01:25<1:28:31, 10.77s/it, loss=0.0106, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   1%|▏         | 7/500 [01:28<1:28:31, 10.77s/it, loss=0.032, lr=0.0001] \n",
            "Steps:   2%|▏         | 8/500 [01:31<1:33:01, 11.34s/it, loss=0.032, lr=0.0001]\n",
            "Steps:   2%|▏         | 8/500 [01:31<1:33:01, 11.34s/it, loss=0.0672, lr=0.0001]\n",
            "Steps:   2%|▏         | 8/500 [01:33<1:33:01, 11.34s/it, loss=0.0277, lr=0.0001]\n",
            "Steps:   2%|▏         | 8/500 [01:36<1:33:01, 11.34s/it, loss=0.0312, lr=0.0001]\n",
            "Steps:   2%|▏         | 8/500 [01:39<1:33:01, 11.34s/it, loss=0.0142, lr=0.0001]\n",
            "Steps:   2%|▏         | 9/500 [01:42<1:32:12, 11.27s/it, loss=0.0142, lr=0.0001]\n",
            "Steps:   2%|▏         | 9/500 [01:42<1:32:12, 11.27s/it, loss=0.147, lr=0.0001] \n",
            "Steps:   2%|▏         | 9/500 [01:44<1:32:12, 11.27s/it, loss=0.392, lr=0.0001]\n",
            "Steps:   2%|▏         | 9/500 [01:47<1:32:12, 11.27s/it, loss=0.275, lr=0.0001]\n",
            "Steps:   2%|▏         | 10/500 [01:50<1:24:28, 10.34s/it, loss=0.275, lr=0.0001]\n",
            "Steps:   2%|▏         | 10/500 [01:50<1:24:28, 10.34s/it, loss=0.227, lr=0.0001]\n",
            "Steps:   2%|▏         | 10/500 [01:53<1:24:28, 10.34s/it, loss=0.00506, lr=0.0001]\n",
            "Steps:   2%|▏         | 10/500 [01:56<1:24:28, 10.34s/it, loss=0.00784, lr=0.0001]\n",
            "Steps:   2%|▏         | 10/500 [01:58<1:24:28, 10.34s/it, loss=0.0647, lr=0.0001] \n",
            "Steps:   2%|▏         | 11/500 [02:01<1:26:04, 10.56s/it, loss=0.0647, lr=0.0001]\n",
            "Steps:   2%|▏         | 11/500 [02:01<1:26:04, 10.56s/it, loss=0.00187, lr=0.0001]\n",
            "Steps:   2%|▏         | 11/500 [02:04<1:26:04, 10.56s/it, loss=0.00373, lr=0.0001]\n",
            "Steps:   2%|▏         | 11/500 [02:07<1:26:04, 10.56s/it, loss=0.00305, lr=0.0001]\n",
            "Steps:   2%|▏         | 11/500 [02:10<1:26:04, 10.56s/it, loss=0.0874, lr=0.0001] \n",
            "Steps:   2%|▏         | 12/500 [02:13<1:28:21, 10.86s/it, loss=0.0874, lr=0.0001]\n",
            "Steps:   2%|▏         | 12/500 [02:13<1:28:21, 10.86s/it, loss=0.25, lr=0.0001]  \n",
            "Steps:   2%|▏         | 12/500 [02:15<1:28:21, 10.86s/it, loss=0.374, lr=0.0001]\n",
            "Steps:   2%|▏         | 12/500 [02:18<1:28:21, 10.86s/it, loss=0.0402, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   2%|▏         | 12/500 [02:21<1:28:21, 10.86s/it, loss=0.0143, lr=0.0001]\n",
            "Steps:   3%|▎         | 13/500 [02:24<1:29:09, 10.98s/it, loss=0.0143, lr=0.0001]\n",
            "Steps:   3%|▎         | 13/500 [02:24<1:29:09, 10.98s/it, loss=0.00517, lr=0.0001]\n",
            "Steps:   3%|▎         | 13/500 [02:27<1:29:09, 10.98s/it, loss=0.0935, lr=0.0001] \n",
            "Steps:   3%|▎         | 13/500 [02:29<1:29:09, 10.98s/it, loss=0.0605, lr=0.0001]\n",
            "Steps:   3%|▎         | 13/500 [02:34<1:29:09, 10.98s/it, loss=0.00942, lr=0.0001]\n",
            "Steps:   3%|▎         | 14/500 [02:37<1:33:16, 11.52s/it, loss=0.00942, lr=0.0001]\n",
            "Steps:   3%|▎         | 14/500 [02:37<1:33:16, 11.52s/it, loss=0.115, lr=0.0001]  \n",
            "Steps:   3%|▎         | 14/500 [02:39<1:33:16, 11.52s/it, loss=0.0726, lr=0.0001]\n",
            "Steps:   3%|▎         | 14/500 [02:42<1:33:16, 11.52s/it, loss=0.24, lr=0.0001]  INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   3%|▎         | 15/500 [02:45<1:25:45, 10.61s/it, loss=0.24, lr=0.0001]\n",
            "Steps:   3%|▎         | 15/500 [02:45<1:25:45, 10.61s/it, loss=0.222, lr=0.0001]\n",
            "Steps:   3%|▎         | 15/500 [02:48<1:25:45, 10.61s/it, loss=0.117, lr=0.0001]\n",
            "Steps:   3%|▎         | 15/500 [02:51<1:25:45, 10.61s/it, loss=0.189, lr=0.0001]\n",
            "Steps:   3%|▎         | 15/500 [02:54<1:25:45, 10.61s/it, loss=0.124, lr=0.0001]\n",
            "Steps:   3%|▎         | 16/500 [02:56<1:27:31, 10.85s/it, loss=0.124, lr=0.0001]\n",
            "Steps:   3%|▎         | 16/500 [02:56<1:27:31, 10.85s/it, loss=0.00593, lr=0.0001]\n",
            "Steps:   3%|▎         | 16/500 [02:59<1:27:31, 10.85s/it, loss=0.296, lr=0.0001]  \n",
            "Steps:   3%|▎         | 16/500 [03:02<1:27:31, 10.85s/it, loss=0.0144, lr=0.0001]\n",
            "Steps:   3%|▎         | 16/500 [03:05<1:27:31, 10.85s/it, loss=0.00253, lr=0.0001]\n",
            "Steps:   3%|▎         | 17/500 [03:08<1:28:13, 10.96s/it, loss=0.00253, lr=0.0001]\n",
            "Steps:   3%|▎         | 17/500 [03:08<1:28:13, 10.96s/it, loss=0.217, lr=0.0001]  \n",
            "Steps:   3%|▎         | 17/500 [03:11<1:28:13, 10.96s/it, loss=0.0566, lr=0.0001]\n",
            "Steps:   3%|▎         | 17/500 [03:13<1:28:13, 10.96s/it, loss=0.401, lr=0.0001] \n",
            "Steps:   3%|▎         | 17/500 [03:16<1:28:13, 10.96s/it, loss=0.0257, lr=0.0001]\n",
            "Steps:   4%|▎         | 18/500 [03:19<1:29:00, 11.08s/it, loss=0.0257, lr=0.0001]\n",
            "Steps:   4%|▎         | 18/500 [03:19<1:29:00, 11.08s/it, loss=0.101, lr=0.0001] \n",
            "Steps:   4%|▎         | 18/500 [03:22<1:29:00, 11.08s/it, loss=0.429, lr=0.0001]\n",
            "Steps:   4%|▎         | 18/500 [03:25<1:29:00, 11.08s/it, loss=0.013, lr=0.0001]\n",
            "Steps:   4%|▎         | 18/500 [03:28<1:29:00, 11.08s/it, loss=0.0379, lr=0.0001]\n",
            "Steps:   4%|▍         | 19/500 [03:32<1:33:12, 11.63s/it, loss=0.0379, lr=0.0001]\n",
            "Steps:   4%|▍         | 19/500 [03:32<1:33:12, 11.63s/it, loss=0.227, lr=0.0001] \n",
            "Steps:   4%|▍         | 19/500 [03:35<1:33:12, 11.63s/it, loss=0.055, lr=0.0001]\n",
            "Steps:   4%|▍         | 19/500 [03:38<1:33:12, 11.63s/it, loss=0.0198, lr=0.0001]\n",
            "Steps:   4%|▍         | 20/500 [03:41<1:25:58, 10.75s/it, loss=0.0198, lr=0.0001]\n",
            "Steps:   4%|▍         | 20/500 [03:41<1:25:58, 10.75s/it, loss=0.00252, lr=0.0001]\n",
            "Steps:   4%|▍         | 20/500 [03:44<1:25:58, 10.75s/it, loss=0.237, lr=0.0001]  \n",
            "Steps:   4%|▍         | 20/500 [03:46<1:25:58, 10.75s/it, loss=0.0188, lr=0.0001]\n",
            "Steps:   4%|▍         | 20/500 [03:49<1:25:58, 10.75s/it, loss=0.00628, lr=0.0001]\n",
            "Steps:   4%|▍         | 21/500 [03:52<1:27:25, 10.95s/it, loss=0.00628, lr=0.0001]\n",
            "Steps:   4%|▍         | 21/500 [03:52<1:27:25, 10.95s/it, loss=0.0383, lr=0.0001] \n",
            "Steps:   4%|▍         | 21/500 [03:55<1:27:25, 10.95s/it, loss=0.141, lr=0.0001] \n",
            "Steps:   4%|▍         | 21/500 [03:58<1:27:25, 10.95s/it, loss=0.101, lr=0.0001]\n",
            "Steps:   4%|▍         | 21/500 [04:01<1:27:25, 10.95s/it, loss=0.0141, lr=0.0001]\n",
            "Steps:   4%|▍         | 22/500 [04:03<1:28:20, 11.09s/it, loss=0.0141, lr=0.0001]\n",
            "Steps:   4%|▍         | 22/500 [04:03<1:28:20, 11.09s/it, loss=0.132, lr=0.0001] \n",
            "Steps:   4%|▍         | 22/500 [04:08<1:28:20, 11.09s/it, loss=0.0032, lr=0.0001]\n",
            "Steps:   4%|▍         | 22/500 [04:11<1:28:20, 11.09s/it, loss=0.559, lr=0.0001] \n",
            "Steps:   4%|▍         | 22/500 [04:13<1:28:20, 11.09s/it, loss=0.107, lr=0.0001]\n",
            "Steps:   5%|▍         | 23/500 [04:16<1:32:09, 11.59s/it, loss=0.107, lr=0.0001]\n",
            "Steps:   5%|▍         | 23/500 [04:16<1:32:09, 11.59s/it, loss=0.0809, lr=0.0001]\n",
            "Steps:   5%|▍         | 23/500 [04:19<1:32:09, 11.59s/it, loss=0.0721, lr=0.0001]\n",
            "Steps:   5%|▍         | 23/500 [04:22<1:32:09, 11.59s/it, loss=0.0937, lr=0.0001]\n",
            "Steps:   5%|▍         | 23/500 [04:25<1:32:09, 11.59s/it, loss=0.0154, lr=0.0001]\n",
            "Steps:   5%|▍         | 24/500 [04:28<1:32:52, 11.71s/it, loss=0.0154, lr=0.0001]\n",
            "Steps:   5%|▍         | 24/500 [04:28<1:32:52, 11.71s/it, loss=0.732, lr=0.0001] \n",
            "Steps:   5%|▍         | 24/500 [04:31<1:32:52, 11.71s/it, loss=0.48, lr=0.0001] \n",
            "Steps:   5%|▍         | 24/500 [04:34<1:32:52, 11.71s/it, loss=0.135, lr=0.0001]\n",
            "Steps:   5%|▌         | 25/500 [04:37<1:25:13, 10.76s/it, loss=0.135, lr=0.0001]\n",
            "Steps:   5%|▌         | 25/500 [04:37<1:25:13, 10.76s/it, loss=0.087, lr=0.0001]\n",
            "Steps:   5%|▌         | 25/500 [04:40<1:25:13, 10.76s/it, loss=0.233, lr=0.0001]\n",
            "Steps:   5%|▌         | 25/500 [04:43<1:25:13, 10.76s/it, loss=0.283, lr=0.0001]\n",
            "Steps:   5%|▌         | 25/500 [04:46<1:25:13, 10.76s/it, loss=0.00337, lr=0.0001]\n",
            "Steps:   5%|▌         | 26/500 [04:48<1:27:04, 11.02s/it, loss=0.00337, lr=0.0001]\n",
            "Steps:   5%|▌         | 26/500 [04:48<1:27:04, 11.02s/it, loss=0.114, lr=0.0001]  \n",
            "Steps:   5%|▌         | 26/500 [04:51<1:27:04, 11.02s/it, loss=0.077, lr=0.0001]\n",
            "Steps:   5%|▌         | 26/500 [04:54<1:27:04, 11.02s/it, loss=0.409, lr=0.0001]\n",
            "Steps:   5%|▌         | 26/500 [04:57<1:27:04, 11.02s/it, loss=0.163, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   5%|▌         | 27/500 [05:00<1:27:53, 11.15s/it, loss=0.163, lr=0.0001]\n",
            "Steps:   5%|▌         | 27/500 [05:00<1:27:53, 11.15s/it, loss=0.0474, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   5%|▌         | 27/500 [05:03<1:27:53, 11.15s/it, loss=0.0759, lr=0.0001]\n",
            "Steps:   5%|▌         | 27/500 [05:06<1:27:53, 11.15s/it, loss=0.0173, lr=0.0001]\n",
            "Steps:   5%|▌         | 27/500 [05:09<1:27:53, 11.15s/it, loss=0.0398, lr=0.0001]\n",
            "Steps:   6%|▌         | 28/500 [05:14<1:34:09, 11.97s/it, loss=0.0398, lr=0.0001]\n",
            "Steps:   6%|▌         | 28/500 [05:14<1:34:09, 11.97s/it, loss=0.34, lr=0.0001]  \n",
            "Steps:   6%|▌         | 28/500 [05:17<1:34:09, 11.97s/it, loss=0.00339, lr=0.0001]\n",
            "Steps:   6%|▌         | 28/500 [05:19<1:34:09, 11.97s/it, loss=0.0691, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   6%|▌         | 28/500 [05:22<1:34:09, 11.97s/it, loss=0.136, lr=0.0001] \n",
            "Steps:   6%|▌         | 29/500 [05:25<1:32:37, 11.80s/it, loss=0.136, lr=0.0001]\n",
            "Steps:   6%|▌         | 29/500 [05:25<1:32:37, 11.80s/it, loss=0.00259, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   6%|▌         | 29/500 [05:28<1:32:37, 11.80s/it, loss=0.103, lr=0.0001]  \n",
            "Steps:   6%|▌         | 29/500 [05:31<1:32:37, 11.80s/it, loss=0.00581, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   6%|▌         | 30/500 [05:34<1:24:48, 10.83s/it, loss=0.00581, lr=0.0001]\n",
            "Steps:   6%|▌         | 30/500 [05:34<1:24:48, 10.83s/it, loss=0.196, lr=0.0001]  \n",
            "Steps:   6%|▌         | 30/500 [05:37<1:24:48, 10.83s/it, loss=0.179, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   6%|▌         | 30/500 [05:39<1:24:48, 10.83s/it, loss=0.057, lr=0.0001]\n",
            "Steps:   6%|▌         | 30/500 [05:42<1:24:48, 10.83s/it, loss=0.0196, lr=0.0001]\n",
            "Steps:   6%|▌         | 31/500 [05:45<1:26:24, 11.05s/it, loss=0.0196, lr=0.0001]\n",
            "Steps:   6%|▌         | 31/500 [05:45<1:26:24, 11.05s/it, loss=0.443, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   6%|▌         | 31/500 [05:48<1:26:24, 11.05s/it, loss=0.17, lr=0.0001] \n",
            "Steps:   6%|▌         | 31/500 [05:51<1:26:24, 11.05s/it, loss=0.0465, lr=0.0001]\n",
            "Steps:   6%|▌         | 31/500 [05:54<1:26:24, 11.05s/it, loss=0.191, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   6%|▋         | 32/500 [05:57<1:26:59, 11.15s/it, loss=0.191, lr=0.0001]\n",
            "Steps:   6%|▋         | 32/500 [05:57<1:26:59, 11.15s/it, loss=0.0126, lr=0.0001]\n",
            "Steps:   6%|▋         | 32/500 [06:00<1:26:59, 11.15s/it, loss=0.0235, lr=0.0001]\n",
            "Steps:   6%|▋         | 32/500 [06:02<1:26:59, 11.15s/it, loss=0.086, lr=0.0001] \n",
            "Steps:   6%|▋         | 32/500 [06:05<1:26:59, 11.15s/it, loss=0.0036, lr=0.0001]\n",
            "Steps:   7%|▋         | 33/500 [06:10<1:32:08, 11.84s/it, loss=0.0036, lr=0.0001]\n",
            "Steps:   7%|▋         | 33/500 [06:10<1:32:08, 11.84s/it, loss=0.257, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   7%|▋         | 33/500 [06:13<1:32:08, 11.84s/it, loss=0.058, lr=0.0001]\n",
            "Steps:   7%|▋         | 33/500 [06:16<1:32:08, 11.84s/it, loss=0.139, lr=0.0001]\n",
            "Steps:   7%|▋         | 33/500 [06:19<1:32:08, 11.84s/it, loss=0.0951, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   7%|▋         | 34/500 [06:22<1:32:04, 11.86s/it, loss=0.0951, lr=0.0001]\n",
            "Steps:   7%|▋         | 34/500 [06:22<1:32:04, 11.86s/it, loss=0.0421, lr=0.0001]\n",
            "Steps:   7%|▋         | 34/500 [06:25<1:32:04, 11.86s/it, loss=0.148, lr=0.0001] \n",
            "Steps:   7%|▋         | 34/500 [06:28<1:32:04, 11.86s/it, loss=0.0128, lr=0.0001]\n",
            "Steps:   7%|▋         | 35/500 [06:31<1:24:10, 10.86s/it, loss=0.0128, lr=0.0001]\n",
            "Steps:   7%|▋         | 35/500 [06:31<1:24:10, 10.86s/it, loss=0.266, lr=0.0001] \n",
            "Steps:   7%|▋         | 35/500 [06:33<1:24:10, 10.86s/it, loss=0.00346, lr=0.0001]\n",
            "Steps:   7%|▋         | 35/500 [06:36<1:24:10, 10.86s/it, loss=0.113, lr=0.0001]  \n",
            "Steps:   7%|▋         | 35/500 [06:39<1:24:10, 10.86s/it, loss=0.0237, lr=0.0001]\n",
            "Steps:   7%|▋         | 36/500 [06:42<1:25:27, 11.05s/it, loss=0.0237, lr=0.0001]\n",
            "Steps:   7%|▋         | 36/500 [06:42<1:25:27, 11.05s/it, loss=0.00962, lr=0.0001]\n",
            "Steps:   7%|▋         | 36/500 [06:45<1:25:27, 11.05s/it, loss=0.032, lr=0.0001]  \n",
            "Steps:   7%|▋         | 36/500 [06:48<1:25:27, 11.05s/it, loss=0.0484, lr=0.0001]\n",
            "Steps:   7%|▋         | 36/500 [06:51<1:25:27, 11.05s/it, loss=0.162, lr=0.0001] \n",
            "Steps:   7%|▋         | 37/500 [06:53<1:26:07, 11.16s/it, loss=0.162, lr=0.0001]\n",
            "Steps:   7%|▋         | 37/500 [06:53<1:26:07, 11.16s/it, loss=0.0352, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   7%|▋         | 37/500 [06:57<1:26:07, 11.16s/it, loss=0.00373, lr=0.0001]\n",
            "Steps:   7%|▋         | 37/500 [07:00<1:26:07, 11.16s/it, loss=0.138, lr=0.0001]  \n",
            "Steps:   7%|▋         | 37/500 [07:03<1:26:07, 11.16s/it, loss=0.0343, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   8%|▊         | 38/500 [07:05<1:27:39, 11.38s/it, loss=0.0343, lr=0.0001]\n",
            "Steps:   8%|▊         | 38/500 [07:05<1:27:39, 11.38s/it, loss=0.106, lr=0.0001] \n",
            "Steps:   8%|▊         | 38/500 [07:08<1:27:39, 11.38s/it, loss=0.0804, lr=0.0001]\n",
            "Steps:   8%|▊         | 38/500 [07:11<1:27:39, 11.38s/it, loss=0.209, lr=0.0001] \n",
            "Steps:   8%|▊         | 38/500 [07:15<1:27:39, 11.38s/it, loss=0.195, lr=0.0001]\n",
            "Steps:   8%|▊         | 39/500 [07:18<1:31:05, 11.85s/it, loss=0.195, lr=0.0001]\n",
            "Steps:   8%|▊         | 39/500 [07:18<1:31:05, 11.85s/it, loss=0.0389, lr=0.0001]\n",
            "Steps:   8%|▊         | 39/500 [07:21<1:31:05, 11.85s/it, loss=0.0499, lr=0.0001]\n",
            "Steps:   8%|▊         | 39/500 [07:24<1:31:05, 11.85s/it, loss=0.0107, lr=0.0001]\n",
            "Steps:   8%|▊         | 40/500 [07:27<1:23:23, 10.88s/it, loss=0.0107, lr=0.0001]\n",
            "Steps:   8%|▊         | 40/500 [07:27<1:23:23, 10.88s/it, loss=0.0077, lr=0.0001]\n",
            "Steps:   8%|▊         | 40/500 [07:31<1:23:23, 10.88s/it, loss=0.471, lr=0.0001] \n",
            "Steps:   8%|▊         | 40/500 [07:34<1:23:23, 10.88s/it, loss=0.13, lr=0.0001] \n",
            "Steps:   8%|▊         | 40/500 [07:37<1:23:23, 10.88s/it, loss=0.208, lr=0.0001]\n",
            "Steps:   8%|▊         | 41/500 [07:40<1:27:57, 11.50s/it, loss=0.208, lr=0.0001]\n",
            "Steps:   8%|▊         | 41/500 [07:40<1:27:57, 11.50s/it, loss=0.0021, lr=0.0001]\n",
            "Steps:   8%|▊         | 41/500 [07:43<1:27:57, 11.50s/it, loss=0.317, lr=0.0001] \n",
            "Steps:   8%|▊         | 41/500 [07:46<1:27:57, 11.50s/it, loss=0.00605, lr=0.0001]\n",
            "Steps:   8%|▊         | 41/500 [07:48<1:27:57, 11.50s/it, loss=0.209, lr=0.0001]  \n",
            "Steps:   8%|▊         | 42/500 [07:51<1:27:35, 11.47s/it, loss=0.209, lr=0.0001]\n",
            "Steps:   8%|▊         | 42/500 [07:51<1:27:35, 11.47s/it, loss=0.0737, lr=0.0001]\n",
            "Steps:   8%|▊         | 42/500 [07:54<1:27:35, 11.47s/it, loss=0.303, lr=0.0001] \n",
            "Steps:   8%|▊         | 42/500 [07:57<1:27:35, 11.47s/it, loss=0.313, lr=0.0001]\n",
            "Steps:   8%|▊         | 42/500 [08:00<1:27:35, 11.47s/it, loss=0.00757, lr=0.0001]\n",
            "Steps:   9%|▊         | 43/500 [08:03<1:27:23, 11.47s/it, loss=0.00757, lr=0.0001]\n",
            "Steps:   9%|▊         | 43/500 [08:03<1:27:23, 11.47s/it, loss=0.033, lr=0.0001]  \n",
            "Steps:   9%|▊         | 43/500 [08:06<1:27:23, 11.47s/it, loss=0.0157, lr=0.0001]\n",
            "Steps:   9%|▊         | 43/500 [08:08<1:27:23, 11.47s/it, loss=0.118, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   9%|▊         | 43/500 [08:11<1:27:23, 11.47s/it, loss=0.00611, lr=0.0001]\n",
            "Steps:   9%|▉         | 44/500 [08:15<1:28:01, 11.58s/it, loss=0.00611, lr=0.0001]\n",
            "Steps:   9%|▉         | 44/500 [08:15<1:28:01, 11.58s/it, loss=0.0533, lr=0.0001] \n",
            "Steps:   9%|▉         | 44/500 [08:17<1:28:01, 11.58s/it, loss=0.383, lr=0.0001] \n",
            "Steps:   9%|▉         | 44/500 [08:20<1:28:01, 11.58s/it, loss=0.00843, lr=0.0001]\n",
            "Steps:   9%|▉         | 45/500 [08:23<1:20:46, 10.65s/it, loss=0.00843, lr=0.0001]\n",
            "Steps:   9%|▉         | 45/500 [08:23<1:20:46, 10.65s/it, loss=0.281, lr=0.0001]  \n",
            "Steps:   9%|▉         | 45/500 [08:26<1:20:46, 10.65s/it, loss=0.0838, lr=0.0001]\n",
            "Steps:   9%|▉         | 45/500 [08:29<1:20:46, 10.65s/it, loss=0.372, lr=0.0001] \n",
            "Steps:   9%|▉         | 45/500 [08:32<1:20:46, 10.65s/it, loss=0.161, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:   9%|▉         | 46/500 [08:35<1:23:48, 11.07s/it, loss=0.161, lr=0.0001]\n",
            "Steps:   9%|▉         | 46/500 [08:35<1:23:48, 11.07s/it, loss=0.0553, lr=0.0001]\n",
            "Steps:   9%|▉         | 46/500 [08:38<1:23:48, 11.07s/it, loss=0.186, lr=0.0001] \n",
            "Steps:   9%|▉         | 46/500 [08:41<1:23:48, 11.07s/it, loss=0.00378, lr=0.0001]\n",
            "Steps:   9%|▉         | 46/500 [08:44<1:23:48, 11.07s/it, loss=0.0344, lr=0.0001] \n",
            "Steps:   9%|▉         | 47/500 [08:47<1:24:42, 11.22s/it, loss=0.0344, lr=0.0001]\n",
            "Steps:   9%|▉         | 47/500 [08:47<1:24:42, 11.22s/it, loss=0.00365, lr=0.0001]\n",
            "Steps:   9%|▉         | 47/500 [08:50<1:24:42, 11.22s/it, loss=0.0372, lr=0.0001] \n",
            "Steps:   9%|▉         | 47/500 [08:52<1:24:42, 11.22s/it, loss=0.44, lr=0.0001]  \n",
            "Steps:   9%|▉         | 47/500 [08:55<1:24:42, 11.22s/it, loss=0.0365, lr=0.0001]\n",
            "Steps:  10%|▉         | 48/500 [09:00<1:29:04, 11.82s/it, loss=0.0365, lr=0.0001]\n",
            "Steps:  10%|▉         | 48/500 [09:00<1:29:04, 11.82s/it, loss=0.0184, lr=0.0001]\n",
            "Steps:  10%|▉         | 48/500 [09:03<1:29:04, 11.82s/it, loss=0.165, lr=0.0001] \n",
            "Steps:  10%|▉         | 48/500 [09:06<1:29:04, 11.82s/it, loss=0.0739, lr=0.0001]\n",
            "Steps:  10%|▉         | 48/500 [09:08<1:29:04, 11.82s/it, loss=0.00443, lr=0.0001]\n",
            "Steps:  10%|▉         | 49/500 [09:11<1:28:01, 11.71s/it, loss=0.00443, lr=0.0001]\n",
            "Steps:  10%|▉         | 49/500 [09:11<1:28:01, 11.71s/it, loss=0.00592, lr=0.0001]\n",
            "Steps:  10%|▉         | 49/500 [09:14<1:28:01, 11.71s/it, loss=0.0569, lr=0.0001] \n",
            "Steps:  10%|▉         | 49/500 [09:17<1:28:01, 11.71s/it, loss=0.0389, lr=0.0001]\n",
            "Steps:  10%|█         | 50/500 [09:20<1:20:37, 10.75s/it, loss=0.0389, lr=0.0001]\n",
            "Steps:  10%|█         | 50/500 [09:20<1:20:37, 10.75s/it, loss=0.0864, lr=0.0001]\n",
            "Steps:  10%|█         | 50/500 [09:23<1:20:37, 10.75s/it, loss=0.0032, lr=0.0001]\n",
            "Steps:  10%|█         | 50/500 [09:26<1:20:37, 10.75s/it, loss=0.0155, lr=0.0001]\n",
            "Steps:  10%|█         | 50/500 [09:29<1:20:37, 10.75s/it, loss=0.0479, lr=0.0001]\n",
            "Steps:  10%|█         | 51/500 [09:32<1:23:12, 11.12s/it, loss=0.0479, lr=0.0001]\n",
            "Steps:  10%|█         | 51/500 [09:32<1:23:12, 11.12s/it, loss=0.0851, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  10%|█         | 51/500 [09:35<1:23:12, 11.12s/it, loss=0.0143, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  10%|█         | 51/500 [09:38<1:23:12, 11.12s/it, loss=0.167, lr=0.0001] \n",
            "Steps:  10%|█         | 51/500 [09:40<1:23:12, 11.12s/it, loss=0.0261, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  10%|█         | 52/500 [09:46<1:29:07, 11.94s/it, loss=0.0261, lr=0.0001]\n",
            "Steps:  10%|█         | 52/500 [09:46<1:29:07, 11.94s/it, loss=0.136, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  10%|█         | 52/500 [09:48<1:29:07, 11.94s/it, loss=0.0435, lr=0.0001]\n",
            "Steps:  10%|█         | 52/500 [09:51<1:29:07, 11.94s/it, loss=0.112, lr=0.0001] \n",
            "Steps:  10%|█         | 52/500 [09:54<1:29:07, 11.94s/it, loss=0.0161, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  11%|█         | 53/500 [09:57<1:27:41, 11.77s/it, loss=0.0161, lr=0.0001]\n",
            "Steps:  11%|█         | 53/500 [09:57<1:27:41, 11.77s/it, loss=0.126, lr=0.0001] \n",
            "Steps:  11%|█         | 53/500 [10:00<1:27:41, 11.77s/it, loss=0.00273, lr=0.0001]\n",
            "Steps:  11%|█         | 53/500 [10:03<1:27:41, 11.77s/it, loss=0.187, lr=0.0001]  \n",
            "Steps:  11%|█         | 53/500 [10:06<1:27:41, 11.77s/it, loss=0.0975, lr=0.0001]\n",
            "Steps:  11%|█         | 54/500 [10:09<1:26:54, 11.69s/it, loss=0.0975, lr=0.0001]\n",
            "Steps:  11%|█         | 54/500 [10:09<1:26:54, 11.69s/it, loss=0.0691, lr=0.0001]\n",
            "Steps:  11%|█         | 54/500 [10:11<1:26:54, 11.69s/it, loss=0.0647, lr=0.0001]\n",
            "Steps:  11%|█         | 54/500 [10:14<1:26:54, 11.69s/it, loss=0.0389, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  11%|█         | 55/500 [10:17<1:19:34, 10.73s/it, loss=0.0389, lr=0.0001]\n",
            "Steps:  11%|█         | 55/500 [10:17<1:19:34, 10.73s/it, loss=0.00722, lr=0.0001]\n",
            "Steps:  11%|█         | 55/500 [10:20<1:19:34, 10.73s/it, loss=0.193, lr=0.0001]  \n",
            "Steps:  11%|█         | 55/500 [10:23<1:19:34, 10.73s/it, loss=0.146, lr=0.0001]\n",
            "Steps:  11%|█         | 55/500 [10:26<1:19:34, 10.73s/it, loss=0.0967, lr=0.0001]\n",
            "Steps:  11%|█         | 56/500 [10:29<1:22:13, 11.11s/it, loss=0.0967, lr=0.0001]\n",
            "Steps:  11%|█         | 56/500 [10:29<1:22:13, 11.11s/it, loss=0.225, lr=0.0001] \n",
            "Steps:  11%|█         | 56/500 [10:32<1:22:13, 11.11s/it, loss=0.206, lr=0.0001]\n",
            "Steps:  11%|█         | 56/500 [10:35<1:22:13, 11.11s/it, loss=0.00286, lr=0.0001]\n",
            "Steps:  11%|█         | 56/500 [10:38<1:22:13, 11.11s/it, loss=0.297, lr=0.0001]  \n",
            "Steps:  11%|█▏        | 57/500 [10:40<1:22:41, 11.20s/it, loss=0.297, lr=0.0001]\n",
            "Steps:  11%|█▏        | 57/500 [10:40<1:22:41, 11.20s/it, loss=0.189, lr=0.0001]\n",
            "Steps:  11%|█▏        | 57/500 [10:43<1:22:41, 11.20s/it, loss=0.00962, lr=0.0001]\n",
            "Steps:  11%|█▏        | 57/500 [10:46<1:22:41, 11.20s/it, loss=0.0487, lr=0.0001] \n",
            "Steps:  11%|█▏        | 57/500 [10:49<1:22:41, 11.20s/it, loss=0.401, lr=0.0001] \n",
            "Steps:  12%|█▏        | 58/500 [10:53<1:26:22, 11.72s/it, loss=0.401, lr=0.0001]\n",
            "Steps:  12%|█▏        | 58/500 [10:53<1:26:22, 11.72s/it, loss=0.125, lr=0.0001]\n",
            "Steps:  12%|█▏        | 58/500 [10:56<1:26:22, 11.72s/it, loss=0.0959, lr=0.0001]\n",
            "Steps:  12%|█▏        | 58/500 [10:59<1:26:22, 11.72s/it, loss=0.0237, lr=0.0001]\n",
            "Steps:  12%|█▏        | 58/500 [11:02<1:26:22, 11.72s/it, loss=0.101, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  12%|█▏        | 59/500 [11:05<1:25:26, 11.62s/it, loss=0.101, lr=0.0001]\n",
            "Steps:  12%|█▏        | 59/500 [11:05<1:25:26, 11.62s/it, loss=0.00217, lr=0.0001]\n",
            "Steps:  12%|█▏        | 59/500 [11:08<1:25:26, 11.62s/it, loss=0.00988, lr=0.0001]\n",
            "Steps:  12%|█▏        | 59/500 [11:11<1:25:26, 11.62s/it, loss=0.1, lr=0.0001]    \n",
            "Steps:  12%|█▏        | 60/500 [11:13<1:18:22, 10.69s/it, loss=0.1, lr=0.0001]\n",
            "Steps:  12%|█▏        | 60/500 [11:13<1:18:22, 10.69s/it, loss=0.022, lr=0.0001]\n",
            "Steps:  12%|█▏        | 60/500 [11:16<1:18:22, 10.69s/it, loss=0.0826, lr=0.0001]\n",
            "Steps:  12%|█▏        | 60/500 [11:19<1:18:22, 10.69s/it, loss=0.054, lr=0.0001] \n",
            "Steps:  12%|█▏        | 60/500 [11:22<1:18:22, 10.69s/it, loss=0.0334, lr=0.0001]\n",
            "Steps:  12%|█▏        | 61/500 [11:25<1:19:49, 10.91s/it, loss=0.0334, lr=0.0001]\n",
            "Steps:  12%|█▏        | 61/500 [11:25<1:19:49, 10.91s/it, loss=0.0479, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  12%|█▏        | 61/500 [11:28<1:19:49, 10.91s/it, loss=0.0239, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  12%|█▏        | 61/500 [11:30<1:19:49, 10.91s/it, loss=0.00527, lr=0.0001]\n",
            "Steps:  12%|█▏        | 61/500 [11:33<1:19:49, 10.91s/it, loss=0.0143, lr=0.0001] \n",
            "Steps:  12%|█▏        | 62/500 [11:36<1:20:38, 11.05s/it, loss=0.0143, lr=0.0001]\n",
            "Steps:  12%|█▏        | 62/500 [11:36<1:20:38, 11.05s/it, loss=0.0209, lr=0.0001]\n",
            "Steps:  12%|█▏        | 62/500 [11:40<1:20:38, 11.05s/it, loss=0.00202, lr=0.0001]\n",
            "Steps:  12%|█▏        | 62/500 [11:43<1:20:38, 11.05s/it, loss=0.335, lr=0.0001]  \n",
            "Steps:  12%|█▏        | 62/500 [11:46<1:20:38, 11.05s/it, loss=0.073, lr=0.0001]\n",
            "Steps:  13%|█▎        | 63/500 [11:49<1:24:39, 11.62s/it, loss=0.073, lr=0.0001]\n",
            "Steps:  13%|█▎        | 63/500 [11:49<1:24:39, 11.62s/it, loss=0.0249, lr=0.0001]\n",
            "Steps:  13%|█▎        | 63/500 [11:52<1:24:39, 11.62s/it, loss=0.15, lr=0.0001]  \n",
            "Steps:  13%|█▎        | 63/500 [11:55<1:24:39, 11.62s/it, loss=0.0956, lr=0.0001]\n",
            "Steps:  13%|█▎        | 63/500 [11:58<1:24:39, 11.62s/it, loss=0.255, lr=0.0001] \n",
            "Steps:  13%|█▎        | 64/500 [12:01<1:24:02, 11.57s/it, loss=0.255, lr=0.0001]\n",
            "Steps:  13%|█▎        | 64/500 [12:01<1:24:02, 11.57s/it, loss=0.0891, lr=0.0001]\n",
            "Steps:  13%|█▎        | 64/500 [12:04<1:24:02, 11.57s/it, loss=0.00737, lr=0.0001]\n",
            "Steps:  13%|█▎        | 64/500 [12:07<1:24:02, 11.57s/it, loss=0.038, lr=0.0001]  \n",
            "Steps:  13%|█▎        | 65/500 [12:09<1:17:54, 10.75s/it, loss=0.038, lr=0.0001]\n",
            "Steps:  13%|█▎        | 65/500 [12:09<1:17:54, 10.75s/it, loss=0.486, lr=0.0001]\n",
            "Steps:  13%|█▎        | 65/500 [12:12<1:17:54, 10.75s/it, loss=0.0067, lr=0.0001]\n",
            "Steps:  13%|█▎        | 65/500 [12:15<1:17:54, 10.75s/it, loss=0.0734, lr=0.0001]\n",
            "Steps:  13%|█▎        | 65/500 [12:18<1:17:54, 10.75s/it, loss=0.00488, lr=0.0001]\n",
            "Steps:  13%|█▎        | 66/500 [12:21<1:19:36, 11.01s/it, loss=0.00488, lr=0.0001]\n",
            "Steps:  13%|█▎        | 66/500 [12:21<1:19:36, 11.01s/it, loss=0.372, lr=0.0001]  \n",
            "Steps:  13%|█▎        | 66/500 [12:26<1:19:36, 11.01s/it, loss=0.00636, lr=0.0001]\n",
            "Steps:  13%|█▎        | 66/500 [12:29<1:19:36, 11.01s/it, loss=0.0897, lr=0.0001] \n",
            "Steps:  13%|█▎        | 66/500 [12:32<1:19:36, 11.01s/it, loss=0.0936, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  13%|█▎        | 67/500 [12:35<1:26:15, 11.95s/it, loss=0.0936, lr=0.0001]\n",
            "Steps:  13%|█▎        | 67/500 [12:35<1:26:15, 11.95s/it, loss=0.135, lr=0.0001] \n",
            "Steps:  13%|█▎        | 67/500 [12:38<1:26:15, 11.95s/it, loss=0.107, lr=0.0001]\n",
            "Steps:  13%|█▎        | 67/500 [12:41<1:26:15, 11.95s/it, loss=0.00359, lr=0.0001]\n",
            "Steps:  13%|█▎        | 67/500 [12:44<1:26:15, 11.95s/it, loss=0.0945, lr=0.0001] \n",
            "Steps:  14%|█▎        | 68/500 [12:47<1:24:52, 11.79s/it, loss=0.0945, lr=0.0001]\n",
            "Steps:  14%|█▎        | 68/500 [12:47<1:24:52, 11.79s/it, loss=0.104, lr=0.0001] \n",
            "Steps:  14%|█▎        | 68/500 [12:49<1:24:52, 11.79s/it, loss=0.0994, lr=0.0001]\n",
            "Steps:  14%|█▎        | 68/500 [12:52<1:24:52, 11.79s/it, loss=0.0294, lr=0.0001]\n",
            "Steps:  14%|█▎        | 68/500 [12:55<1:24:52, 11.79s/it, loss=0.376, lr=0.0001] \n",
            "Steps:  14%|█▍        | 69/500 [12:58<1:24:02, 11.70s/it, loss=0.376, lr=0.0001]\n",
            "Steps:  14%|█▍        | 69/500 [12:58<1:24:02, 11.70s/it, loss=0.0377, lr=0.0001]\n",
            "Steps:  14%|█▍        | 69/500 [13:01<1:24:02, 11.70s/it, loss=0.0208, lr=0.0001]\n",
            "Steps:  14%|█▍        | 69/500 [13:04<1:24:02, 11.70s/it, loss=0.0255, lr=0.0001]\n",
            "Steps:  14%|█▍        | 70/500 [13:07<1:17:14, 10.78s/it, loss=0.0255, lr=0.0001]\n",
            "Steps:  14%|█▍        | 70/500 [13:07<1:17:14, 10.78s/it, loss=0.182, lr=0.0001] \n",
            "Steps:  14%|█▍        | 70/500 [13:10<1:17:14, 10.78s/it, loss=0.0486, lr=0.0001]\n",
            "Steps:  14%|█▍        | 70/500 [13:12<1:17:14, 10.78s/it, loss=0.0121, lr=0.0001]\n",
            "Steps:  14%|█▍        | 70/500 [13:15<1:17:14, 10.78s/it, loss=0.112, lr=0.0001] \n",
            "Steps:  14%|█▍        | 71/500 [13:18<1:18:40, 11.00s/it, loss=0.112, lr=0.0001]\n",
            "Steps:  14%|█▍        | 71/500 [13:18<1:18:40, 11.00s/it, loss=0.343, lr=0.0001]\n",
            "Steps:  14%|█▍        | 71/500 [13:21<1:18:40, 11.00s/it, loss=0.104, lr=0.0001]\n",
            "Steps:  14%|█▍        | 71/500 [13:24<1:18:40, 11.00s/it, loss=0.0489, lr=0.0001]\n",
            "Steps:  14%|█▍        | 71/500 [13:29<1:18:40, 11.00s/it, loss=0.121, lr=0.0001] \n",
            "Steps:  14%|█▍        | 72/500 [13:31<1:23:20, 11.68s/it, loss=0.121, lr=0.0001]\n",
            "Steps:  14%|█▍        | 72/500 [13:31<1:23:20, 11.68s/it, loss=0.183, lr=0.0001]\n",
            "Steps:  14%|█▍        | 72/500 [13:34<1:23:20, 11.68s/it, loss=0.011, lr=0.0001]\n",
            "Steps:  14%|█▍        | 72/500 [13:37<1:23:20, 11.68s/it, loss=0.031, lr=0.0001]\n",
            "Steps:  14%|█▍        | 72/500 [13:40<1:23:20, 11.68s/it, loss=0.00443, lr=0.0001]\n",
            "Steps:  15%|█▍        | 73/500 [13:43<1:22:42, 11.62s/it, loss=0.00443, lr=0.0001]\n",
            "Steps:  15%|█▍        | 73/500 [13:43<1:22:42, 11.62s/it, loss=0.472, lr=0.0001]  \n",
            "Steps:  15%|█▍        | 73/500 [13:46<1:22:42, 11.62s/it, loss=0.238, lr=0.0001]\n",
            "Steps:  15%|█▍        | 73/500 [13:49<1:22:42, 11.62s/it, loss=0.0761, lr=0.0001]\n",
            "Steps:  15%|█▍        | 73/500 [13:51<1:22:42, 11.62s/it, loss=0.105, lr=0.0001] \n",
            "Steps:  15%|█▍        | 74/500 [13:54<1:22:03, 11.56s/it, loss=0.105, lr=0.0001]\n",
            "Steps:  15%|█▍        | 74/500 [13:54<1:22:03, 11.56s/it, loss=0.1, lr=0.0001]  \n",
            "Steps:  15%|█▍        | 74/500 [13:57<1:22:03, 11.56s/it, loss=0.0899, lr=0.0001]\n",
            "Steps:  15%|█▍        | 74/500 [14:00<1:22:03, 11.56s/it, loss=0.00427, lr=0.0001]\n",
            "Steps:  15%|█▌        | 75/500 [14:03<1:15:27, 10.65s/it, loss=0.00427, lr=0.0001]\n",
            "Steps:  15%|█▌        | 75/500 [14:03<1:15:27, 10.65s/it, loss=0.00727, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  15%|█▌        | 75/500 [14:06<1:15:27, 10.65s/it, loss=0.0833, lr=0.0001] \n",
            "Steps:  15%|█▌        | 75/500 [14:10<1:15:27, 10.65s/it, loss=0.136, lr=0.0001] \n",
            "Steps:  15%|█▌        | 75/500 [14:13<1:15:27, 10.65s/it, loss=0.0622, lr=0.0001]\n",
            "Steps:  15%|█▌        | 76/500 [14:16<1:20:20, 11.37s/it, loss=0.0622, lr=0.0001]\n",
            "Steps:  15%|█▌        | 76/500 [14:16<1:20:20, 11.37s/it, loss=0.0281, lr=0.0001]\n",
            "Steps:  15%|█▌        | 76/500 [14:19<1:20:20, 11.37s/it, loss=0.00618, lr=0.0001]\n",
            "Steps:  15%|█▌        | 76/500 [14:22<1:20:20, 11.37s/it, loss=0.0643, lr=0.0001] \n",
            "Steps:  15%|█▌        | 76/500 [14:24<1:20:20, 11.37s/it, loss=0.00215, lr=0.0001]\n",
            "Steps:  15%|█▌        | 77/500 [14:27<1:20:12, 11.38s/it, loss=0.00215, lr=0.0001]\n",
            "Steps:  15%|█▌        | 77/500 [14:27<1:20:12, 11.38s/it, loss=0.0543, lr=0.0001] \n",
            "Steps:  15%|█▌        | 77/500 [14:30<1:20:12, 11.38s/it, loss=0.00486, lr=0.0001]\n",
            "Steps:  15%|█▌        | 77/500 [14:33<1:20:12, 11.38s/it, loss=0.0101, lr=0.0001] \n",
            "Steps:  15%|█▌        | 77/500 [14:36<1:20:12, 11.38s/it, loss=0.146, lr=0.0001] \n",
            "Steps:  16%|█▌        | 78/500 [14:39<1:20:13, 11.41s/it, loss=0.146, lr=0.0001]\n",
            "Steps:  16%|█▌        | 78/500 [14:39<1:20:13, 11.41s/it, loss=0.00435, lr=0.0001]\n",
            "Steps:  16%|█▌        | 78/500 [14:42<1:20:13, 11.41s/it, loss=0.0112, lr=0.0001] \n",
            "Steps:  16%|█▌        | 78/500 [14:44<1:20:13, 11.41s/it, loss=0.018, lr=0.0001] \n",
            "Steps:  16%|█▌        | 78/500 [14:47<1:20:13, 11.41s/it, loss=0.0157, lr=0.0001]\n",
            "Steps:  16%|█▌        | 79/500 [14:50<1:19:56, 11.39s/it, loss=0.0157, lr=0.0001]\n",
            "Steps:  16%|█▌        | 79/500 [14:50<1:19:56, 11.39s/it, loss=0.039, lr=0.0001] \n",
            "Steps:  16%|█▌        | 79/500 [14:53<1:19:56, 11.39s/it, loss=0.0717, lr=0.0001]\n",
            "Steps:  16%|█▌        | 79/500 [14:56<1:19:56, 11.39s/it, loss=0.286, lr=0.0001] \n",
            "Steps:  16%|█▌        | 80/500 [14:59<1:14:33, 10.65s/it, loss=0.286, lr=0.0001]\n",
            "Steps:  16%|█▌        | 80/500 [14:59<1:14:33, 10.65s/it, loss=0.00785, lr=0.0001]\n",
            "Steps:  16%|█▌        | 80/500 [15:02<1:14:33, 10.65s/it, loss=0.0533, lr=0.0001] \n",
            "Steps:  16%|█▌        | 80/500 [15:05<1:14:33, 10.65s/it, loss=0.0942, lr=0.0001]\n",
            "Steps:  16%|█▌        | 80/500 [15:08<1:14:33, 10.65s/it, loss=0.135, lr=0.0001] \n",
            "Steps:  16%|█▌        | 81/500 [15:11<1:16:28, 10.95s/it, loss=0.135, lr=0.0001]\n",
            "Steps:  16%|█▌        | 81/500 [15:11<1:16:28, 10.95s/it, loss=0.0112, lr=0.0001]\n",
            "Steps:  16%|█▌        | 81/500 [15:14<1:16:28, 10.95s/it, loss=0.117, lr=0.0001] \n",
            "Steps:  16%|█▌        | 81/500 [15:19<1:16:28, 10.95s/it, loss=0.0603, lr=0.0001]\n",
            "Steps:  16%|█▌        | 81/500 [15:21<1:16:28, 10.95s/it, loss=0.0292, lr=0.0001]\n",
            "Steps:  16%|█▋        | 82/500 [15:25<1:22:27, 11.83s/it, loss=0.0292, lr=0.0001]\n",
            "Steps:  16%|█▋        | 82/500 [15:25<1:22:27, 11.83s/it, loss=0.0158, lr=0.0001]\n",
            "Steps:  16%|█▋        | 82/500 [15:27<1:22:27, 11.83s/it, loss=0.229, lr=0.0001] \n",
            "Steps:  16%|█▋        | 82/500 [15:30<1:22:27, 11.83s/it, loss=0.00305, lr=0.0001]\n",
            "Steps:  16%|█▋        | 82/500 [15:33<1:22:27, 11.83s/it, loss=0.00986, lr=0.0001]\n",
            "Steps:  17%|█▋        | 83/500 [15:36<1:21:24, 11.71s/it, loss=0.00986, lr=0.0001]\n",
            "Steps:  17%|█▋        | 83/500 [15:36<1:21:24, 11.71s/it, loss=0.0014, lr=0.0001] \n",
            "Steps:  17%|█▋        | 83/500 [15:39<1:21:24, 11.71s/it, loss=0.136, lr=0.0001] \n",
            "Steps:  17%|█▋        | 83/500 [15:42<1:21:24, 11.71s/it, loss=0.0342, lr=0.0001]\n",
            "Steps:  17%|█▋        | 83/500 [15:45<1:21:24, 11.71s/it, loss=0.188, lr=0.0001] \n",
            "Steps:  17%|█▋        | 84/500 [15:48<1:20:50, 11.66s/it, loss=0.188, lr=0.0001]\n",
            "Steps:  17%|█▋        | 84/500 [15:48<1:20:50, 11.66s/it, loss=0.022, lr=0.0001]\n",
            "Steps:  17%|█▋        | 84/500 [15:50<1:20:50, 11.66s/it, loss=0.0152, lr=0.0001]\n",
            "Steps:  17%|█▋        | 84/500 [15:53<1:20:50, 11.66s/it, loss=0.103, lr=0.0001] \n",
            "Steps:  17%|█▋        | 85/500 [15:56<1:14:07, 10.72s/it, loss=0.103, lr=0.0001]\n",
            "Steps:  17%|█▋        | 85/500 [15:56<1:14:07, 10.72s/it, loss=0.0102, lr=0.0001]\n",
            "Steps:  17%|█▋        | 85/500 [15:59<1:14:07, 10.72s/it, loss=0.11, lr=0.0001]  \n",
            "Steps:  17%|█▋        | 85/500 [16:02<1:14:07, 10.72s/it, loss=0.00425, lr=0.0001]\n",
            "Steps:  17%|█▋        | 85/500 [16:05<1:14:07, 10.72s/it, loss=0.212, lr=0.0001]  \n",
            "Steps:  17%|█▋        | 86/500 [16:08<1:16:16, 11.05s/it, loss=0.212, lr=0.0001]\n",
            "Steps:  17%|█▋        | 86/500 [16:08<1:16:16, 11.05s/it, loss=0.00832, lr=0.0001]\n",
            "Steps:  17%|█▋        | 86/500 [16:11<1:16:16, 11.05s/it, loss=0.207, lr=0.0001]  \n",
            "Steps:  17%|█▋        | 86/500 [16:14<1:16:16, 11.05s/it, loss=0.261, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  17%|█▋        | 86/500 [16:19<1:16:16, 11.05s/it, loss=0.388, lr=0.0001]\n",
            "Steps:  17%|█▋        | 87/500 [16:22<1:21:29, 11.84s/it, loss=0.388, lr=0.0001]\n",
            "Steps:  17%|█▋        | 87/500 [16:22<1:21:29, 11.84s/it, loss=0.134, lr=0.0001]\n",
            "Steps:  17%|█▋        | 87/500 [16:24<1:21:29, 11.84s/it, loss=0.145, lr=0.0001]\n",
            "Steps:  17%|█▋        | 87/500 [16:27<1:21:29, 11.84s/it, loss=0.239, lr=0.0001]\n",
            "Steps:  17%|█▋        | 87/500 [16:30<1:21:29, 11.84s/it, loss=0.00557, lr=0.0001]\n",
            "Steps:  18%|█▊        | 88/500 [16:33<1:20:27, 11.72s/it, loss=0.00557, lr=0.0001]\n",
            "Steps:  18%|█▊        | 88/500 [16:33<1:20:27, 11.72s/it, loss=0.126, lr=0.0001]  \n",
            "Steps:  18%|█▊        | 88/500 [16:36<1:20:27, 11.72s/it, loss=0.0234, lr=0.0001]\n",
            "Steps:  18%|█▊        | 88/500 [16:39<1:20:27, 11.72s/it, loss=0.00274, lr=0.0001]\n",
            "Steps:  18%|█▊        | 88/500 [16:42<1:20:27, 11.72s/it, loss=0.078, lr=0.0001]  \n",
            "Steps:  18%|█▊        | 89/500 [16:44<1:19:40, 11.63s/it, loss=0.078, lr=0.0001]\n",
            "Steps:  18%|█▊        | 89/500 [16:44<1:19:40, 11.63s/it, loss=0.04, lr=0.0001] \n",
            "Steps:  18%|█▊        | 89/500 [16:47<1:19:40, 11.63s/it, loss=0.00364, lr=0.0001]\n",
            "Steps:  18%|█▊        | 89/500 [16:50<1:19:40, 11.63s/it, loss=0.192, lr=0.0001]  \n",
            "Steps:  18%|█▊        | 90/500 [16:53<1:13:03, 10.69s/it, loss=0.192, lr=0.0001]\n",
            "Steps:  18%|█▊        | 90/500 [16:53<1:13:03, 10.69s/it, loss=0.0176, lr=0.0001]\n",
            "Steps:  18%|█▊        | 90/500 [16:56<1:13:03, 10.69s/it, loss=0.2, lr=0.0001]   \n",
            "Steps:  18%|█▊        | 90/500 [16:59<1:13:03, 10.69s/it, loss=0.58, lr=0.0001]\n",
            "Steps:  18%|█▊        | 90/500 [17:02<1:13:03, 10.69s/it, loss=0.00416, lr=0.0001]\n",
            "Steps:  18%|█▊        | 91/500 [17:04<1:14:36, 10.94s/it, loss=0.00416, lr=0.0001]\n",
            "Steps:  18%|█▊        | 91/500 [17:04<1:14:36, 10.94s/it, loss=0.189, lr=0.0001]  \n",
            "Steps:  18%|█▊        | 91/500 [17:07<1:14:36, 10.94s/it, loss=0.0496, lr=0.0001]\n",
            "Steps:  18%|█▊        | 91/500 [17:10<1:14:36, 10.94s/it, loss=0.00733, lr=0.0001]\n",
            "Steps:  18%|█▊        | 91/500 [17:13<1:14:36, 10.94s/it, loss=0.0339, lr=0.0001] \n",
            "Steps:  18%|█▊        | 92/500 [17:16<1:15:23, 11.09s/it, loss=0.0339, lr=0.0001]\n",
            "Steps:  18%|█▊        | 92/500 [17:16<1:15:23, 11.09s/it, loss=0.0503, lr=0.0001]\n",
            "Steps:  18%|█▊        | 92/500 [17:19<1:15:23, 11.09s/it, loss=0.0228, lr=0.0001]\n",
            "Steps:  18%|█▊        | 92/500 [17:22<1:15:23, 11.09s/it, loss=0.108, lr=0.0001] \n",
            "Steps:  18%|█▊        | 92/500 [17:24<1:15:23, 11.09s/it, loss=0.0252, lr=0.0001]\n",
            "Steps:  19%|█▊        | 93/500 [17:29<1:18:50, 11.62s/it, loss=0.0252, lr=0.0001]\n",
            "Steps:  19%|█▊        | 93/500 [17:29<1:18:50, 11.62s/it, loss=0.111, lr=0.0001] \n",
            "Steps:  19%|█▊        | 93/500 [17:32<1:18:50, 11.62s/it, loss=0.0139, lr=0.0001]\n",
            "Steps:  19%|█▊        | 93/500 [17:35<1:18:50, 11.62s/it, loss=0.004, lr=0.0001] \n",
            "Steps:  19%|█▊        | 93/500 [17:37<1:18:50, 11.62s/it, loss=0.00373, lr=0.0001]\n",
            "Steps:  19%|█▉        | 94/500 [17:40<1:18:17, 11.57s/it, loss=0.00373, lr=0.0001]\n",
            "Steps:  19%|█▉        | 94/500 [17:40<1:18:17, 11.57s/it, loss=0.108, lr=0.0001]  \n",
            "Steps:  19%|█▉        | 94/500 [17:43<1:18:17, 11.57s/it, loss=0.00361, lr=0.0001]\n",
            "Steps:  19%|█▉        | 94/500 [17:46<1:18:17, 11.57s/it, loss=0.0134, lr=0.0001] \n",
            "Steps:  19%|█▉        | 95/500 [17:49<1:12:21, 10.72s/it, loss=0.0134, lr=0.0001]\n",
            "Steps:  19%|█▉        | 95/500 [17:49<1:12:21, 10.72s/it, loss=0.572, lr=0.0001] \n",
            "Steps:  19%|█▉        | 95/500 [17:52<1:12:21, 10.72s/it, loss=0.00265, lr=0.0001]\n",
            "Steps:  19%|█▉        | 95/500 [17:55<1:12:21, 10.72s/it, loss=0.01, lr=0.0001]   \n",
            "Steps:  19%|█▉        | 95/500 [17:58<1:12:21, 10.72s/it, loss=0.00239, lr=0.0001]\n",
            "Steps:  19%|█▉        | 96/500 [18:00<1:13:48, 10.96s/it, loss=0.00239, lr=0.0001]\n",
            "Steps:  19%|█▉        | 96/500 [18:00<1:13:48, 10.96s/it, loss=0.0582, lr=0.0001] \n",
            "Steps:  19%|█▉        | 96/500 [18:03<1:13:48, 10.96s/it, loss=0.00841, lr=0.0001]\n",
            "Steps:  19%|█▉        | 96/500 [18:06<1:13:48, 10.96s/it, loss=0.23, lr=0.0001]   \n",
            "Steps:  19%|█▉        | 96/500 [18:09<1:13:48, 10.96s/it, loss=0.0538, lr=0.0001]\n",
            "Steps:  19%|█▉        | 97/500 [18:12<1:14:40, 11.12s/it, loss=0.0538, lr=0.0001]\n",
            "Steps:  19%|█▉        | 97/500 [18:12<1:14:40, 11.12s/it, loss=0.0345, lr=0.0001]\n",
            "Steps:  19%|█▉        | 97/500 [18:15<1:14:40, 11.12s/it, loss=0.208, lr=0.0001] \n",
            "Steps:  19%|█▉        | 97/500 [18:20<1:14:40, 11.12s/it, loss=0.0638, lr=0.0001]\n",
            "Steps:  19%|█▉        | 97/500 [18:23<1:14:40, 11.12s/it, loss=0.0376, lr=0.0001]\n",
            "Steps:  20%|█▉        | 98/500 [18:26<1:20:15, 11.98s/it, loss=0.0376, lr=0.0001]\n",
            "Steps:  20%|█▉        | 98/500 [18:26<1:20:15, 11.98s/it, loss=0.134, lr=0.0001] \n",
            "Steps:  20%|█▉        | 98/500 [18:29<1:20:15, 11.98s/it, loss=0.0206, lr=0.0001]\n",
            "Steps:  20%|█▉        | 98/500 [18:32<1:20:15, 11.98s/it, loss=0.0217, lr=0.0001]\n",
            "Steps:  20%|█▉        | 98/500 [18:34<1:20:15, 11.98s/it, loss=0.244, lr=0.0001] \n",
            "Steps:  20%|█▉        | 99/500 [18:37<1:18:47, 11.79s/it, loss=0.244, lr=0.0001]\n",
            "Steps:  20%|█▉        | 99/500 [18:37<1:18:47, 11.79s/it, loss=0.14, lr=0.0001] \n",
            "Steps:  20%|█▉        | 99/500 [18:40<1:18:47, 11.79s/it, loss=0.246, lr=0.0001]\n",
            "Steps:  20%|█▉        | 99/500 [18:43<1:18:47, 11.79s/it, loss=0.245, lr=0.0001]\n",
            "Steps:  20%|██        | 100/500 [18:46<1:12:05, 10.81s/it, loss=0.245, lr=0.0001]\n",
            "Steps:  20%|██        | 100/500 [18:46<1:12:05, 10.81s/it, loss=0.104, lr=0.0001]\n",
            "Steps:  20%|██        | 100/500 [18:49<1:12:05, 10.81s/it, loss=0.0052, lr=0.0001]\n",
            "Steps:  20%|██        | 100/500 [18:52<1:12:05, 10.81s/it, loss=0.144, lr=0.0001] \n",
            "Steps:  20%|██        | 100/500 [18:55<1:12:05, 10.81s/it, loss=0.188, lr=0.0001]\n",
            "Steps:  20%|██        | 101/500 [18:57<1:13:29, 11.05s/it, loss=0.188, lr=0.0001]\n",
            "Steps:  20%|██        | 101/500 [18:57<1:13:29, 11.05s/it, loss=0.00576, lr=0.0001]\n",
            "Steps:  20%|██        | 101/500 [19:00<1:13:29, 11.05s/it, loss=0.0195, lr=0.0001] \n",
            "Steps:  20%|██        | 101/500 [19:06<1:13:29, 11.05s/it, loss=0.105, lr=0.0001] \n",
            "Steps:  20%|██        | 101/500 [19:08<1:13:29, 11.05s/it, loss=0.0744, lr=0.0001]\n",
            "Steps:  20%|██        | 102/500 [19:11<1:18:58, 11.91s/it, loss=0.0744, lr=0.0001]\n",
            "Steps:  20%|██        | 102/500 [19:11<1:18:58, 11.91s/it, loss=0.567, lr=0.0001] \n",
            "Steps:  20%|██        | 102/500 [19:14<1:18:58, 11.91s/it, loss=0.125, lr=0.0001]\n",
            "Steps:  20%|██        | 102/500 [19:17<1:18:58, 11.91s/it, loss=0.00467, lr=0.0001]\n",
            "Steps:  20%|██        | 102/500 [19:20<1:18:58, 11.91s/it, loss=0.0219, lr=0.0001] \n",
            "Steps:  21%|██        | 103/500 [19:23<1:17:51, 11.77s/it, loss=0.0219, lr=0.0001]\n",
            "Steps:  21%|██        | 103/500 [19:23<1:17:51, 11.77s/it, loss=0.00784, lr=0.0001]\n",
            "Steps:  21%|██        | 103/500 [19:26<1:17:51, 11.77s/it, loss=0.00774, lr=0.0001]\n",
            "Steps:  21%|██        | 103/500 [19:29<1:17:51, 11.77s/it, loss=0.00376, lr=0.0001]\n",
            "Steps:  21%|██        | 103/500 [19:31<1:17:51, 11.77s/it, loss=0.0423, lr=0.0001] \n",
            "Steps:  21%|██        | 104/500 [19:34<1:17:10, 11.69s/it, loss=0.0423, lr=0.0001]\n",
            "Steps:  21%|██        | 104/500 [19:34<1:17:10, 11.69s/it, loss=0.00336, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  21%|██        | 104/500 [19:37<1:17:10, 11.69s/it, loss=0.00354, lr=0.0001]\n",
            "Steps:  21%|██        | 104/500 [19:40<1:17:10, 11.69s/it, loss=0.0711, lr=0.0001] \n",
            "Steps:  21%|██        | 105/500 [19:43<1:11:09, 10.81s/it, loss=0.0711, lr=0.0001]\n",
            "Steps:  21%|██        | 105/500 [19:43<1:11:09, 10.81s/it, loss=0.0214, lr=0.0001]\n",
            "Steps:  21%|██        | 105/500 [19:46<1:11:09, 10.81s/it, loss=0.0915, lr=0.0001]\n",
            "Steps:  21%|██        | 105/500 [19:49<1:11:09, 10.81s/it, loss=0.0525, lr=0.0001]\n",
            "Steps:  21%|██        | 105/500 [19:52<1:11:09, 10.81s/it, loss=0.0601, lr=0.0001]\n",
            "Steps:  21%|██        | 106/500 [19:55<1:12:25, 11.03s/it, loss=0.0601, lr=0.0001]\n",
            "Steps:  21%|██        | 106/500 [19:55<1:12:25, 11.03s/it, loss=0.0187, lr=0.0001]\n",
            "Steps:  21%|██        | 106/500 [19:57<1:12:25, 11.03s/it, loss=0.0122, lr=0.0001]\n",
            "Steps:  21%|██        | 106/500 [20:00<1:12:25, 11.03s/it, loss=0.0139, lr=0.0001]\n",
            "Steps:  21%|██        | 106/500 [20:03<1:12:25, 11.03s/it, loss=0.329, lr=0.0001] \n",
            "Steps:  21%|██▏       | 107/500 [20:06<1:13:46, 11.26s/it, loss=0.329, lr=0.0001]\n",
            "Steps:  21%|██▏       | 107/500 [20:06<1:13:46, 11.26s/it, loss=0.06, lr=0.0001] \n",
            "Steps:  21%|██▏       | 107/500 [20:09<1:13:46, 11.26s/it, loss=0.0104, lr=0.0001]\n",
            "Steps:  21%|██▏       | 107/500 [20:12<1:13:46, 11.26s/it, loss=0.0393, lr=0.0001]\n",
            "Steps:  21%|██▏       | 107/500 [20:15<1:13:46, 11.26s/it, loss=0.136, lr=0.0001] \n",
            "Steps:  22%|██▏       | 108/500 [20:18<1:14:06, 11.34s/it, loss=0.136, lr=0.0001]\n",
            "Steps:  22%|██▏       | 108/500 [20:18<1:14:06, 11.34s/it, loss=0.0232, lr=0.0001]\n",
            "Steps:  22%|██▏       | 108/500 [20:21<1:14:06, 11.34s/it, loss=0.029, lr=0.0001] \n",
            "Steps:  22%|██▏       | 108/500 [20:24<1:14:06, 11.34s/it, loss=0.00303, lr=0.0001]\n",
            "Steps:  22%|██▏       | 108/500 [20:27<1:14:06, 11.34s/it, loss=0.52, lr=0.0001]   \n",
            "Steps:  22%|██▏       | 109/500 [20:31<1:16:57, 11.81s/it, loss=0.52, lr=0.0001]\n",
            "Steps:  22%|██▏       | 109/500 [20:31<1:16:57, 11.81s/it, loss=0.00183, lr=0.0001]\n",
            "Steps:  22%|██▏       | 109/500 [20:34<1:16:57, 11.81s/it, loss=0.0202, lr=0.0001] \n",
            "Steps:  22%|██▏       | 109/500 [20:37<1:16:57, 11.81s/it, loss=0.384, lr=0.0001] \n",
            "Steps:  22%|██▏       | 110/500 [20:39<1:10:27, 10.84s/it, loss=0.384, lr=0.0001]\n",
            "Steps:  22%|██▏       | 110/500 [20:39<1:10:27, 10.84s/it, loss=0.03, lr=0.0001] \n",
            "Steps:  22%|██▏       | 110/500 [20:42<1:10:27, 10.84s/it, loss=0.0464, lr=0.0001]\n",
            "Steps:  22%|██▏       | 110/500 [20:45<1:10:27, 10.84s/it, loss=0.0566, lr=0.0001]\n",
            "Steps:  22%|██▏       | 110/500 [20:48<1:10:27, 10.84s/it, loss=0.0579, lr=0.0001]\n",
            "Steps:  22%|██▏       | 111/500 [20:51<1:11:42, 11.06s/it, loss=0.0579, lr=0.0001]\n",
            "Steps:  22%|██▏       | 111/500 [20:51<1:11:42, 11.06s/it, loss=0.00909, lr=0.0001]\n",
            "Steps:  22%|██▏       | 111/500 [20:54<1:11:42, 11.06s/it, loss=0.0679, lr=0.0001] \n",
            "Steps:  22%|██▏       | 111/500 [20:57<1:11:42, 11.06s/it, loss=0.306, lr=0.0001] \n",
            "Steps:  22%|██▏       | 111/500 [21:00<1:11:42, 11.06s/it, loss=0.0938, lr=0.0001]\n",
            "Steps:  22%|██▏       | 112/500 [21:05<1:17:11, 11.94s/it, loss=0.0938, lr=0.0001]\n",
            "Steps:  22%|██▏       | 112/500 [21:05<1:17:11, 11.94s/it, loss=0.308, lr=0.0001] \n",
            "Steps:  22%|██▏       | 112/500 [21:08<1:17:11, 11.94s/it, loss=0.0197, lr=0.0001]\n",
            "Steps:  22%|██▏       | 112/500 [21:11<1:17:11, 11.94s/it, loss=0.476, lr=0.0001] \n",
            "Steps:  22%|██▏       | 112/500 [21:14<1:17:11, 11.94s/it, loss=0.0047, lr=0.0001]\n",
            "Steps:  23%|██▎       | 113/500 [21:16<1:16:05, 11.80s/it, loss=0.0047, lr=0.0001]\n",
            "Steps:  23%|██▎       | 113/500 [21:16<1:16:05, 11.80s/it, loss=0.163, lr=0.0001] \n",
            "Steps:  23%|██▎       | 113/500 [21:19<1:16:05, 11.80s/it, loss=0.0276, lr=0.0001]\n",
            "Steps:  23%|██▎       | 113/500 [21:22<1:16:05, 11.80s/it, loss=0.226, lr=0.0001] \n",
            "Steps:  23%|██▎       | 113/500 [21:25<1:16:05, 11.80s/it, loss=0.227, lr=0.0001]\n",
            "Steps:  23%|██▎       | 114/500 [21:28<1:15:04, 11.67s/it, loss=0.227, lr=0.0001]\n",
            "Steps:  23%|██▎       | 114/500 [21:28<1:15:04, 11.67s/it, loss=0.00333, lr=0.0001]\n",
            "Steps:  23%|██▎       | 114/500 [21:31<1:15:04, 11.67s/it, loss=0.00789, lr=0.0001]\n",
            "Steps:  23%|██▎       | 114/500 [21:34<1:15:04, 11.67s/it, loss=0.0132, lr=0.0001] \n",
            "Steps:  23%|██▎       | 115/500 [21:36<1:08:47, 10.72s/it, loss=0.0132, lr=0.0001]\n",
            "Steps:  23%|██▎       | 115/500 [21:36<1:08:47, 10.72s/it, loss=0.00126, lr=0.0001]\n",
            "Steps:  23%|██▎       | 115/500 [21:39<1:08:47, 10.72s/it, loss=0.09, lr=0.0001]   \n",
            "Steps:  23%|██▎       | 115/500 [21:42<1:08:47, 10.72s/it, loss=0.0332, lr=0.0001]\n",
            "Steps:  23%|██▎       | 115/500 [21:45<1:08:47, 10.72s/it, loss=0.0634, lr=0.0001]\n",
            "Steps:  23%|██▎       | 116/500 [21:48<1:10:40, 11.04s/it, loss=0.0634, lr=0.0001]\n",
            "Steps:  23%|██▎       | 116/500 [21:48<1:10:40, 11.04s/it, loss=0.0236, lr=0.0001]\n",
            "Steps:  23%|██▎       | 116/500 [21:51<1:10:40, 11.04s/it, loss=0.0057, lr=0.0001]\n",
            "Steps:  23%|██▎       | 116/500 [21:54<1:10:40, 11.04s/it, loss=0.155, lr=0.0001] \n",
            "Steps:  23%|██▎       | 116/500 [21:57<1:10:40, 11.04s/it, loss=0.18, lr=0.0001] \n",
            "Steps:  23%|██▎       | 117/500 [22:01<1:14:09, 11.62s/it, loss=0.18, lr=0.0001]\n",
            "Steps:  23%|██▎       | 117/500 [22:01<1:14:09, 11.62s/it, loss=0.0171, lr=0.0001]\n",
            "Steps:  23%|██▎       | 117/500 [22:04<1:14:09, 11.62s/it, loss=0.0208, lr=0.0001]\n",
            "Steps:  23%|██▎       | 117/500 [22:07<1:14:09, 11.62s/it, loss=0.393, lr=0.0001] \n",
            "Steps:  23%|██▎       | 117/500 [22:10<1:14:09, 11.62s/it, loss=0.107, lr=0.0001]\n",
            "Steps:  24%|██▎       | 118/500 [22:13<1:13:39, 11.57s/it, loss=0.107, lr=0.0001]\n",
            "Steps:  24%|██▎       | 118/500 [22:13<1:13:39, 11.57s/it, loss=0.196, lr=0.0001]\n",
            "Steps:  24%|██▎       | 118/500 [22:15<1:13:39, 11.57s/it, loss=0.00624, lr=0.0001]\n",
            "Steps:  24%|██▎       | 118/500 [22:18<1:13:39, 11.57s/it, loss=0.131, lr=0.0001]  \n",
            "Steps:  24%|██▎       | 118/500 [22:21<1:13:39, 11.57s/it, loss=0.0154, lr=0.0001]\n",
            "Steps:  24%|██▍       | 119/500 [22:24<1:13:17, 11.54s/it, loss=0.0154, lr=0.0001]\n",
            "Steps:  24%|██▍       | 119/500 [22:24<1:13:17, 11.54s/it, loss=0.0264, lr=0.0001]\n",
            "Steps:  24%|██▍       | 119/500 [22:27<1:13:17, 11.54s/it, loss=0.00287, lr=0.0001]\n",
            "Steps:  24%|██▍       | 119/500 [22:30<1:13:17, 11.54s/it, loss=0.345, lr=0.0001]  \n",
            "Steps:  24%|██▍       | 120/500 [22:33<1:07:21, 10.63s/it, loss=0.345, lr=0.0001]\n",
            "Steps:  24%|██▍       | 120/500 [22:33<1:07:21, 10.63s/it, loss=0.0119, lr=0.0001]\n",
            "Steps:  24%|██▍       | 120/500 [22:35<1:07:21, 10.63s/it, loss=0.00308, lr=0.0001]\n",
            "Steps:  24%|██▍       | 120/500 [22:38<1:07:21, 10.63s/it, loss=0.0315, lr=0.0001] \n",
            "Steps:  24%|██▍       | 120/500 [22:41<1:07:21, 10.63s/it, loss=0.00575, lr=0.0001]\n",
            "Steps:  24%|██▍       | 121/500 [22:44<1:09:25, 10.99s/it, loss=0.00575, lr=0.0001]\n",
            "Steps:  24%|██▍       | 121/500 [22:44<1:09:25, 10.99s/it, loss=0.00241, lr=0.0001]\n",
            "Steps:  24%|██▍       | 121/500 [22:47<1:09:25, 10.99s/it, loss=0.13, lr=0.0001]   \n",
            "Steps:  24%|██▍       | 121/500 [22:50<1:09:25, 10.99s/it, loss=0.0748, lr=0.0001]\n",
            "Steps:  24%|██▍       | 121/500 [22:53<1:09:25, 10.99s/it, loss=0.00548, lr=0.0001]\n",
            "Steps:  24%|██▍       | 122/500 [22:56<1:09:56, 11.10s/it, loss=0.00548, lr=0.0001]\n",
            "Steps:  24%|██▍       | 122/500 [22:56<1:09:56, 11.10s/it, loss=0.12, lr=0.0001]   \n",
            "Steps:  24%|██▍       | 122/500 [22:59<1:09:56, 11.10s/it, loss=0.0723, lr=0.0001]\n",
            "Steps:  24%|██▍       | 122/500 [23:01<1:09:56, 11.10s/it, loss=0.033, lr=0.0001] \n",
            "Steps:  24%|██▍       | 122/500 [23:06<1:09:56, 11.10s/it, loss=0.217, lr=0.0001]\n",
            "Steps:  25%|██▍       | 123/500 [23:09<1:14:35, 11.87s/it, loss=0.217, lr=0.0001]\n",
            "Steps:  25%|██▍       | 123/500 [23:09<1:14:35, 11.87s/it, loss=0.0563, lr=0.0001]\n",
            "Steps:  25%|██▍       | 123/500 [23:12<1:14:35, 11.87s/it, loss=0.0829, lr=0.0001]\n",
            "Steps:  25%|██▍       | 123/500 [23:15<1:14:35, 11.87s/it, loss=0.212, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  25%|██▍       | 123/500 [23:18<1:14:35, 11.87s/it, loss=0.0406, lr=0.0001]\n",
            "Steps:  25%|██▍       | 124/500 [23:21<1:13:47, 11.78s/it, loss=0.0406, lr=0.0001]\n",
            "Steps:  25%|██▍       | 124/500 [23:21<1:13:47, 11.78s/it, loss=0.0723, lr=0.0001]\n",
            "Steps:  25%|██▍       | 124/500 [23:24<1:13:47, 11.78s/it, loss=0.106, lr=0.0001] \n",
            "Steps:  25%|██▍       | 124/500 [23:27<1:13:47, 11.78s/it, loss=0.00737, lr=0.0001]\n",
            "Steps:  25%|██▌       | 125/500 [23:29<1:07:21, 10.78s/it, loss=0.00737, lr=0.0001]\n",
            "Steps:  25%|██▌       | 125/500 [23:29<1:07:21, 10.78s/it, loss=0.0174, lr=0.0001] \n",
            "Steps:  25%|██▌       | 125/500 [23:32<1:07:21, 10.78s/it, loss=0.00739, lr=0.0001]\n",
            "Steps:  25%|██▌       | 125/500 [23:35<1:07:21, 10.78s/it, loss=0.00677, lr=0.0001]\n",
            "Steps:  25%|██▌       | 125/500 [23:38<1:07:21, 10.78s/it, loss=0.0099, lr=0.0001] \n",
            "Steps:  25%|██▌       | 126/500 [23:41<1:08:34, 11.00s/it, loss=0.0099, lr=0.0001]\n",
            "Steps:  25%|██▌       | 126/500 [23:41<1:08:34, 11.00s/it, loss=0.156, lr=0.0001] \n",
            "Steps:  25%|██▌       | 126/500 [23:45<1:08:34, 11.00s/it, loss=0.0935, lr=0.0001]\n",
            "Steps:  25%|██▌       | 126/500 [23:48<1:08:34, 11.00s/it, loss=0.0974, lr=0.0001]\n",
            "Steps:  25%|██▌       | 126/500 [23:51<1:08:34, 11.00s/it, loss=0.416, lr=0.0001] \n",
            "Steps:  25%|██▌       | 127/500 [23:54<1:12:05, 11.60s/it, loss=0.416, lr=0.0001]\n",
            "Steps:  25%|██▌       | 127/500 [23:54<1:12:05, 11.60s/it, loss=0.158, lr=0.0001]\n",
            "Steps:  25%|██▌       | 127/500 [23:57<1:12:05, 11.60s/it, loss=0.0359, lr=0.0001]\n",
            "Steps:  25%|██▌       | 127/500 [24:00<1:12:05, 11.60s/it, loss=0.0325, lr=0.0001]\n",
            "Steps:  25%|██▌       | 127/500 [24:02<1:12:05, 11.60s/it, loss=0.277, lr=0.0001] \n",
            "Steps:  26%|██▌       | 128/500 [24:05<1:11:39, 11.56s/it, loss=0.277, lr=0.0001]\n",
            "Steps:  26%|██▌       | 128/500 [24:05<1:11:39, 11.56s/it, loss=0.0413, lr=0.0001]\n",
            "Steps:  26%|██▌       | 128/500 [24:08<1:11:39, 11.56s/it, loss=0.101, lr=0.0001] \n",
            "Steps:  26%|██▌       | 128/500 [24:11<1:11:39, 11.56s/it, loss=0.0136, lr=0.0001]\n",
            "Steps:  26%|██▌       | 128/500 [24:14<1:11:39, 11.56s/it, loss=0.0692, lr=0.0001]\n",
            "Steps:  26%|██▌       | 129/500 [24:17<1:11:21, 11.54s/it, loss=0.0692, lr=0.0001]\n",
            "Steps:  26%|██▌       | 129/500 [24:17<1:11:21, 11.54s/it, loss=0.0137, lr=0.0001]\n",
            "Steps:  26%|██▌       | 129/500 [24:20<1:11:21, 11.54s/it, loss=0.101, lr=0.0001] \n",
            "Steps:  26%|██▌       | 129/500 [24:23<1:11:21, 11.54s/it, loss=0.576, lr=0.0001]\n",
            "Steps:  26%|██▌       | 130/500 [24:26<1:06:26, 10.77s/it, loss=0.576, lr=0.0001]\n",
            "Steps:  26%|██▌       | 130/500 [24:26<1:06:26, 10.77s/it, loss=0.211, lr=0.0001]\n",
            "Steps:  26%|██▌       | 130/500 [24:29<1:06:26, 10.77s/it, loss=0.0366, lr=0.0001]\n",
            "Steps:  26%|██▌       | 130/500 [24:33<1:06:26, 10.77s/it, loss=0.397, lr=0.0001] \n",
            "Steps:  26%|██▌       | 130/500 [24:36<1:06:26, 10.77s/it, loss=0.00149, lr=0.0001]\n",
            "Steps:  26%|██▌       | 131/500 [24:39<1:10:16, 11.43s/it, loss=0.00149, lr=0.0001]\n",
            "Steps:  26%|██▌       | 131/500 [24:39<1:10:16, 11.43s/it, loss=0.117, lr=0.0001]  \n",
            "Steps:  26%|██▌       | 131/500 [24:42<1:10:16, 11.43s/it, loss=0.00473, lr=0.0001]\n",
            "Steps:  26%|██▌       | 131/500 [24:45<1:10:16, 11.43s/it, loss=0.0751, lr=0.0001] \n",
            "Steps:  26%|██▌       | 131/500 [24:47<1:10:16, 11.43s/it, loss=0.353, lr=0.0001] \n",
            "Steps:  26%|██▋       | 132/500 [24:50<1:10:09, 11.44s/it, loss=0.353, lr=0.0001]\n",
            "Steps:  26%|██▋       | 132/500 [24:50<1:10:09, 11.44s/it, loss=0.0853, lr=0.0001]\n",
            "Steps:  26%|██▋       | 132/500 [24:53<1:10:09, 11.44s/it, loss=0.0201, lr=0.0001]\n",
            "Steps:  26%|██▋       | 132/500 [24:56<1:10:09, 11.44s/it, loss=0.00311, lr=0.0001]\n",
            "Steps:  26%|██▋       | 132/500 [24:59<1:10:09, 11.44s/it, loss=0.00417, lr=0.0001]\n",
            "Steps:  27%|██▋       | 133/500 [25:02<1:10:06, 11.46s/it, loss=0.00417, lr=0.0001]\n",
            "Steps:  27%|██▋       | 133/500 [25:02<1:10:06, 11.46s/it, loss=0.107, lr=0.0001]  \n",
            "Steps:  27%|██▋       | 133/500 [25:05<1:10:06, 11.46s/it, loss=0.00536, lr=0.0001]\n",
            "Steps:  27%|██▋       | 133/500 [25:07<1:10:06, 11.46s/it, loss=0.0531, lr=0.0001] \n",
            "Steps:  27%|██▋       | 133/500 [25:11<1:10:06, 11.46s/it, loss=0.132, lr=0.0001] \n",
            "Steps:  27%|██▋       | 134/500 [25:13<1:10:21, 11.53s/it, loss=0.132, lr=0.0001]\n",
            "Steps:  27%|██▋       | 134/500 [25:13<1:10:21, 11.53s/it, loss=0.0256, lr=0.0001]\n",
            "Steps:  27%|██▋       | 134/500 [25:16<1:10:21, 11.53s/it, loss=0.0676, lr=0.0001]\n",
            "Steps:  27%|██▋       | 134/500 [25:19<1:10:21, 11.53s/it, loss=0.161, lr=0.0001] \n",
            "Steps:  27%|██▋       | 135/500 [25:22<1:04:44, 10.64s/it, loss=0.161, lr=0.0001]\n",
            "Steps:  27%|██▋       | 135/500 [25:22<1:04:44, 10.64s/it, loss=0.00459, lr=0.0001]\n",
            "Steps:  27%|██▋       | 135/500 [25:25<1:04:44, 10.64s/it, loss=0.153, lr=0.0001]  \n",
            "Steps:  27%|██▋       | 135/500 [25:28<1:04:44, 10.64s/it, loss=0.0144, lr=0.0001]\n",
            "Steps:  27%|██▋       | 135/500 [25:31<1:04:44, 10.64s/it, loss=0.0448, lr=0.0001]\n",
            "Steps:  27%|██▋       | 136/500 [25:34<1:06:17, 10.93s/it, loss=0.0448, lr=0.0001]\n",
            "Steps:  27%|██▋       | 136/500 [25:34<1:06:17, 10.93s/it, loss=0.00791, lr=0.0001]\n",
            "Steps:  27%|██▋       | 136/500 [25:36<1:06:17, 10.93s/it, loss=0.0036, lr=0.0001] \n",
            "Steps:  27%|██▋       | 136/500 [25:40<1:06:17, 10.93s/it, loss=0.0114, lr=0.0001]\n",
            "Steps:  27%|██▋       | 136/500 [25:42<1:06:17, 10.93s/it, loss=0.00469, lr=0.0001]\n",
            "Steps:  27%|██▋       | 137/500 [25:45<1:07:30, 11.16s/it, loss=0.00469, lr=0.0001]\n",
            "Steps:  27%|██▋       | 137/500 [25:45<1:07:30, 11.16s/it, loss=0.0577, lr=0.0001] \n",
            "Steps:  27%|██▋       | 137/500 [25:48<1:07:30, 11.16s/it, loss=0.0303, lr=0.0001]\n",
            "Steps:  27%|██▋       | 137/500 [25:51<1:07:30, 11.16s/it, loss=0.0213, lr=0.0001]\n",
            "Steps:  27%|██▋       | 137/500 [25:54<1:07:30, 11.16s/it, loss=0.00756, lr=0.0001]\n",
            "Steps:  28%|██▊       | 138/500 [25:57<1:07:47, 11.24s/it, loss=0.00756, lr=0.0001]\n",
            "Steps:  28%|██▊       | 138/500 [25:57<1:07:47, 11.24s/it, loss=0.00276, lr=0.0001]\n",
            "Steps:  28%|██▊       | 138/500 [26:01<1:07:47, 11.24s/it, loss=0.0173, lr=0.0001] \n",
            "Steps:  28%|██▊       | 138/500 [26:04<1:07:47, 11.24s/it, loss=0.0164, lr=0.0001]\n",
            "Steps:  28%|██▊       | 138/500 [26:07<1:07:47, 11.24s/it, loss=0.0446, lr=0.0001]\n",
            "Steps:  28%|██▊       | 139/500 [26:10<1:10:33, 11.73s/it, loss=0.0446, lr=0.0001]\n",
            "Steps:  28%|██▊       | 139/500 [26:10<1:10:33, 11.73s/it, loss=0.0018, lr=0.0001]\n",
            "Steps:  28%|██▊       | 139/500 [26:12<1:10:33, 11.73s/it, loss=0.104, lr=0.0001] \n",
            "Steps:  28%|██▊       | 139/500 [26:15<1:10:33, 11.73s/it, loss=0.189, lr=0.0001]\n",
            "Steps:  28%|██▊       | 140/500 [26:18<1:04:33, 10.76s/it, loss=0.189, lr=0.0001]\n",
            "Steps:  28%|██▊       | 140/500 [26:18<1:04:33, 10.76s/it, loss=0.0114, lr=0.0001]\n",
            "Steps:  28%|██▊       | 140/500 [26:21<1:04:33, 10.76s/it, loss=0.00265, lr=0.0001]\n",
            "Steps:  28%|██▊       | 140/500 [26:24<1:04:33, 10.76s/it, loss=0.183, lr=0.0001]  \n",
            "Steps:  28%|██▊       | 140/500 [26:27<1:04:33, 10.76s/it, loss=0.00695, lr=0.0001]\n",
            "Steps:  28%|██▊       | 141/500 [26:31<1:08:39, 11.48s/it, loss=0.00695, lr=0.0001]\n",
            "Steps:  28%|██▊       | 141/500 [26:31<1:08:39, 11.48s/it, loss=0.0047, lr=0.0001] \n",
            "Steps:  28%|██▊       | 141/500 [26:34<1:08:39, 11.48s/it, loss=0.0013, lr=0.0001]\n",
            "Steps:  28%|██▊       | 141/500 [26:37<1:08:39, 11.48s/it, loss=0.00248, lr=0.0001]\n",
            "Steps:  28%|██▊       | 141/500 [26:40<1:08:39, 11.48s/it, loss=0.48, lr=0.0001]   \n",
            "Steps:  28%|██▊       | 142/500 [26:43<1:08:19, 11.45s/it, loss=0.48, lr=0.0001]\n",
            "Steps:  28%|██▊       | 142/500 [26:43<1:08:19, 11.45s/it, loss=0.00366, lr=0.0001]\n",
            "Steps:  28%|██▊       | 142/500 [26:46<1:08:19, 11.45s/it, loss=0.0153, lr=0.0001] \n",
            "Steps:  28%|██▊       | 142/500 [26:48<1:08:19, 11.45s/it, loss=0.034, lr=0.0001] \n",
            "Steps:  28%|██▊       | 142/500 [26:51<1:08:19, 11.45s/it, loss=0.00254, lr=0.0001]\n",
            "Steps:  29%|██▊       | 143/500 [26:54<1:08:09, 11.45s/it, loss=0.00254, lr=0.0001]\n",
            "Steps:  29%|██▊       | 143/500 [26:54<1:08:09, 11.45s/it, loss=0.00663, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  29%|██▊       | 143/500 [26:57<1:08:09, 11.45s/it, loss=0.139, lr=0.0001]  \n",
            "Steps:  29%|██▊       | 143/500 [27:00<1:08:09, 11.45s/it, loss=0.00973, lr=0.0001]\n",
            "Steps:  29%|██▊       | 143/500 [27:03<1:08:09, 11.45s/it, loss=0.293, lr=0.0001]  \n",
            "Steps:  29%|██▉       | 144/500 [27:06<1:08:32, 11.55s/it, loss=0.293, lr=0.0001]\n",
            "Steps:  29%|██▉       | 144/500 [27:06<1:08:32, 11.55s/it, loss=0.0715, lr=0.0001]\n",
            "Steps:  29%|██▉       | 144/500 [27:09<1:08:32, 11.55s/it, loss=0.102, lr=0.0001] \n",
            "Steps:  29%|██▉       | 144/500 [27:12<1:08:32, 11.55s/it, loss=0.00436, lr=0.0001]\n",
            "Steps:  29%|██▉       | 145/500 [27:14<1:02:56, 10.64s/it, loss=0.00436, lr=0.0001]\n",
            "Steps:  29%|██▉       | 145/500 [27:14<1:02:56, 10.64s/it, loss=0.332, lr=0.0001]  \n",
            "Steps:  29%|██▉       | 145/500 [27:17<1:02:56, 10.64s/it, loss=0.0535, lr=0.0001]\n",
            "Steps:  29%|██▉       | 145/500 [27:20<1:02:56, 10.64s/it, loss=0.0939, lr=0.0001]\n",
            "Steps:  29%|██▉       | 145/500 [27:25<1:02:56, 10.64s/it, loss=0.255, lr=0.0001] \n",
            "Steps:  29%|██▉       | 146/500 [27:28<1:08:11, 11.56s/it, loss=0.255, lr=0.0001]\n",
            "Steps:  29%|██▉       | 146/500 [27:28<1:08:11, 11.56s/it, loss=0.0483, lr=0.0001]\n",
            "Steps:  29%|██▉       | 146/500 [27:31<1:08:11, 11.56s/it, loss=0.129, lr=0.0001] \n",
            "Steps:  29%|██▉       | 146/500 [27:34<1:08:11, 11.56s/it, loss=0.272, lr=0.0001]\n",
            "Steps:  29%|██▉       | 146/500 [27:37<1:08:11, 11.56s/it, loss=0.00191, lr=0.0001]\n",
            "Steps:  29%|██▉       | 147/500 [27:40<1:07:55, 11.54s/it, loss=0.00191, lr=0.0001]\n",
            "Steps:  29%|██▉       | 147/500 [27:40<1:07:55, 11.54s/it, loss=0.0204, lr=0.0001] \n",
            "Steps:  29%|██▉       | 147/500 [27:42<1:07:55, 11.54s/it, loss=0.107, lr=0.0001] \n",
            "Steps:  29%|██▉       | 147/500 [27:45<1:07:55, 11.54s/it, loss=0.00962, lr=0.0001]\n",
            "Steps:  29%|██▉       | 147/500 [27:48<1:07:55, 11.54s/it, loss=0.00374, lr=0.0001]\n",
            "Steps:  30%|██▉       | 148/500 [27:51<1:07:32, 11.51s/it, loss=0.00374, lr=0.0001]\n",
            "Steps:  30%|██▉       | 148/500 [27:51<1:07:32, 11.51s/it, loss=0.427, lr=0.0001]  \n",
            "Steps:  30%|██▉       | 148/500 [27:54<1:07:32, 11.51s/it, loss=0.0676, lr=0.0001]\n",
            "Steps:  30%|██▉       | 148/500 [27:57<1:07:32, 11.51s/it, loss=0.0186, lr=0.0001]\n",
            "Steps:  30%|██▉       | 148/500 [28:00<1:07:32, 11.51s/it, loss=0.409, lr=0.0001] \n",
            "Steps:  30%|██▉       | 149/500 [28:03<1:07:25, 11.53s/it, loss=0.409, lr=0.0001]\n",
            "Steps:  30%|██▉       | 149/500 [28:03<1:07:25, 11.53s/it, loss=0.00377, lr=0.0001]\n",
            "Steps:  30%|██▉       | 149/500 [28:06<1:07:25, 11.53s/it, loss=0.0199, lr=0.0001] \n",
            "Steps:  30%|██▉       | 149/500 [28:09<1:07:25, 11.53s/it, loss=0.0347, lr=0.0001]\n",
            "Steps:  30%|███       | 150/500 [28:12<1:02:44, 10.75s/it, loss=0.0347, lr=0.0001]\n",
            "Steps:  30%|███       | 150/500 [28:12<1:02:44, 10.75s/it, loss=0.0449, lr=0.0001]\n",
            "Steps:  30%|███       | 150/500 [28:15<1:02:44, 10.75s/it, loss=0.127, lr=0.0001] \n",
            "Steps:  30%|███       | 150/500 [28:19<1:02:44, 10.75s/it, loss=0.0344, lr=0.0001]\n",
            "Steps:  30%|███       | 150/500 [28:22<1:02:44, 10.75s/it, loss=0.0764, lr=0.0001]\n",
            "Steps:  30%|███       | 151/500 [28:25<1:06:33, 11.44s/it, loss=0.0764, lr=0.0001]\n",
            "Steps:  30%|███       | 151/500 [28:25<1:06:33, 11.44s/it, loss=0.0218, lr=0.0001]\n",
            "Steps:  30%|███       | 151/500 [28:27<1:06:33, 11.44s/it, loss=0.131, lr=0.0001] \n",
            "Steps:  30%|███       | 151/500 [28:30<1:06:33, 11.44s/it, loss=0.0474, lr=0.0001]\n",
            "Steps:  30%|███       | 151/500 [28:33<1:06:33, 11.44s/it, loss=0.0379, lr=0.0001]\n",
            "Steps:  30%|███       | 152/500 [28:36<1:06:23, 11.45s/it, loss=0.0379, lr=0.0001]\n",
            "Steps:  30%|███       | 152/500 [28:36<1:06:23, 11.45s/it, loss=0.00719, lr=0.0001]\n",
            "Steps:  30%|███       | 152/500 [28:39<1:06:23, 11.45s/it, loss=0.187, lr=0.0001]  \n",
            "Steps:  30%|███       | 152/500 [28:42<1:06:23, 11.45s/it, loss=0.00761, lr=0.0001]\n",
            "Steps:  30%|███       | 152/500 [28:45<1:06:23, 11.45s/it, loss=0.00498, lr=0.0001]\n",
            "Steps:  31%|███       | 153/500 [28:47<1:06:07, 11.44s/it, loss=0.00498, lr=0.0001]\n",
            "Steps:  31%|███       | 153/500 [28:47<1:06:07, 11.44s/it, loss=0.00184, lr=0.0001]\n",
            "Steps:  31%|███       | 153/500 [28:50<1:06:07, 11.44s/it, loss=0.157, lr=0.0001]  \n",
            "Steps:  31%|███       | 153/500 [28:53<1:06:07, 11.44s/it, loss=0.0107, lr=0.0001]\n",
            "Steps:  31%|███       | 153/500 [28:56<1:06:07, 11.44s/it, loss=0.061, lr=0.0001] \n",
            "Steps:  31%|███       | 154/500 [28:59<1:06:28, 11.53s/it, loss=0.061, lr=0.0001]\n",
            "Steps:  31%|███       | 154/500 [28:59<1:06:28, 11.53s/it, loss=0.154, lr=0.0001]\n",
            "Steps:  31%|███       | 154/500 [29:02<1:06:28, 11.53s/it, loss=0.197, lr=0.0001]\n",
            "Steps:  31%|███       | 154/500 [29:05<1:06:28, 11.53s/it, loss=0.0579, lr=0.0001]\n",
            "Steps:  31%|███       | 155/500 [29:08<1:01:04, 10.62s/it, loss=0.0579, lr=0.0001]\n",
            "Steps:  31%|███       | 155/500 [29:08<1:01:04, 10.62s/it, loss=0.455, lr=0.0001] \n",
            "Steps:  31%|███       | 155/500 [29:11<1:01:04, 10.62s/it, loss=0.18, lr=0.0001] \n",
            "Steps:  31%|███       | 155/500 [29:14<1:01:04, 10.62s/it, loss=0.00451, lr=0.0001]\n",
            "Steps:  31%|███       | 155/500 [29:16<1:01:04, 10.62s/it, loss=0.0598, lr=0.0001] \n",
            "Steps:  31%|███       | 156/500 [29:19<1:02:28, 10.90s/it, loss=0.0598, lr=0.0001]\n",
            "Steps:  31%|███       | 156/500 [29:19<1:02:28, 10.90s/it, loss=0.0547, lr=0.0001]\n",
            "Steps:  31%|███       | 156/500 [29:22<1:02:28, 10.90s/it, loss=0.0727, lr=0.0001]\n",
            "Steps:  31%|███       | 156/500 [29:25<1:02:28, 10.90s/it, loss=0.0052, lr=0.0001]\n",
            "Steps:  31%|███       | 156/500 [29:28<1:02:28, 10.90s/it, loss=0.037, lr=0.0001] \n",
            "Steps:  31%|███▏      | 157/500 [29:31<1:03:08, 11.04s/it, loss=0.037, lr=0.0001]\n",
            "Steps:  31%|███▏      | 157/500 [29:31<1:03:08, 11.04s/it, loss=0.0294, lr=0.0001]\n",
            "Steps:  31%|███▏      | 157/500 [29:34<1:03:08, 11.04s/it, loss=0.0428, lr=0.0001]\n",
            "Steps:  31%|███▏      | 157/500 [29:37<1:03:08, 11.04s/it, loss=0.0554, lr=0.0001]\n",
            "Steps:  31%|███▏      | 157/500 [29:39<1:03:08, 11.04s/it, loss=0.182, lr=0.0001] \n",
            "Steps:  32%|███▏      | 158/500 [29:44<1:07:16, 11.80s/it, loss=0.182, lr=0.0001]\n",
            "Steps:  32%|███▏      | 158/500 [29:44<1:07:16, 11.80s/it, loss=0.141, lr=0.0001]\n",
            "Steps:  32%|███▏      | 158/500 [29:47<1:07:16, 11.80s/it, loss=0.0247, lr=0.0001]\n",
            "Steps:  32%|███▏      | 158/500 [29:50<1:07:16, 11.80s/it, loss=0.0774, lr=0.0001]\n",
            "Steps:  32%|███▏      | 158/500 [29:53<1:07:16, 11.80s/it, loss=0.0286, lr=0.0001]\n",
            "Steps:  32%|███▏      | 159/500 [29:56<1:06:30, 11.70s/it, loss=0.0286, lr=0.0001]\n",
            "Steps:  32%|███▏      | 159/500 [29:56<1:06:30, 11.70s/it, loss=0.109, lr=0.0001] \n",
            "Steps:  32%|███▏      | 159/500 [29:59<1:06:30, 11.70s/it, loss=0.0521, lr=0.0001]\n",
            "Steps:  32%|███▏      | 159/500 [30:01<1:06:30, 11.70s/it, loss=0.00494, lr=0.0001]\n",
            "Steps:  32%|███▏      | 160/500 [30:04<1:01:02, 10.77s/it, loss=0.00494, lr=0.0001]\n",
            "Steps:  32%|███▏      | 160/500 [30:04<1:01:02, 10.77s/it, loss=0.0148, lr=0.0001] \n",
            "Steps:  32%|███▏      | 160/500 [30:07<1:01:02, 10.77s/it, loss=0.195, lr=0.0001] \n",
            "Steps:  32%|███▏      | 160/500 [30:10<1:01:02, 10.77s/it, loss=0.00911, lr=0.0001]\n",
            "Steps:  32%|███▏      | 160/500 [30:13<1:01:02, 10.77s/it, loss=0.00312, lr=0.0001]\n",
            "Steps:  32%|███▏      | 161/500 [30:16<1:02:43, 11.10s/it, loss=0.00312, lr=0.0001]\n",
            "Steps:  32%|███▏      | 161/500 [30:16<1:02:43, 11.10s/it, loss=0.351, lr=0.0001]  \n",
            "Steps:  32%|███▏      | 161/500 [30:19<1:02:43, 11.10s/it, loss=0.294, lr=0.0001]\n",
            "Steps:  32%|███▏      | 161/500 [30:22<1:02:43, 11.10s/it, loss=0.111, lr=0.0001]\n",
            "Steps:  32%|███▏      | 161/500 [30:25<1:02:43, 11.10s/it, loss=0.0503, lr=0.0001]\n",
            "Steps:  32%|███▏      | 162/500 [30:28<1:03:02, 11.19s/it, loss=0.0503, lr=0.0001]\n",
            "Steps:  32%|███▏      | 162/500 [30:28<1:03:02, 11.19s/it, loss=0.0351, lr=0.0001]\n",
            "Steps:  32%|███▏      | 162/500 [30:30<1:03:02, 11.19s/it, loss=0.00392, lr=0.0001]\n",
            "Steps:  32%|███▏      | 162/500 [30:33<1:03:02, 11.19s/it, loss=0.327, lr=0.0001]  \n",
            "Steps:  32%|███▏      | 162/500 [30:36<1:03:02, 11.19s/it, loss=0.075, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  33%|███▎      | 163/500 [30:41<1:07:23, 12.00s/it, loss=0.075, lr=0.0001]\n",
            "Steps:  33%|███▎      | 163/500 [30:41<1:07:23, 12.00s/it, loss=0.00917, lr=0.0001]\n",
            "Steps:  33%|███▎      | 163/500 [30:44<1:07:23, 12.00s/it, loss=0.0722, lr=0.0001] \n",
            "Steps:  33%|███▎      | 163/500 [30:47<1:07:23, 12.00s/it, loss=0.245, lr=0.0001] \n",
            "Steps:  33%|███▎      | 163/500 [30:50<1:07:23, 12.00s/it, loss=0.281, lr=0.0001]\n",
            "Steps:  33%|███▎      | 164/500 [30:53<1:06:01, 11.79s/it, loss=0.281, lr=0.0001]\n",
            "Steps:  33%|███▎      | 164/500 [30:53<1:06:01, 11.79s/it, loss=0.00678, lr=0.0001]\n",
            "Steps:  33%|███▎      | 164/500 [30:56<1:06:01, 11.79s/it, loss=0.0479, lr=0.0001] \n",
            "Steps:  33%|███▎      | 164/500 [30:59<1:06:01, 11.79s/it, loss=0.0401, lr=0.0001]\n",
            "Steps:  33%|███▎      | 165/500 [31:01<1:00:23, 10.82s/it, loss=0.0401, lr=0.0001]\n",
            "Steps:  33%|███▎      | 165/500 [31:01<1:00:23, 10.82s/it, loss=0.0827, lr=0.0001]\n",
            "Steps:  33%|███▎      | 165/500 [31:04<1:00:23, 10.82s/it, loss=0.0656, lr=0.0001]\n",
            "Steps:  33%|███▎      | 165/500 [31:07<1:00:23, 10.82s/it, loss=0.262, lr=0.0001] \n",
            "Steps:  33%|███▎      | 165/500 [31:10<1:00:23, 10.82s/it, loss=0.0677, lr=0.0001]\n",
            "Steps:  33%|███▎      | 166/500 [31:13<1:01:39, 11.08s/it, loss=0.0677, lr=0.0001]\n",
            "Steps:  33%|███▎      | 166/500 [31:13<1:01:39, 11.08s/it, loss=0.18, lr=0.0001]  \n",
            "Steps:  33%|███▎      | 166/500 [31:16<1:01:39, 11.08s/it, loss=0.0514, lr=0.0001]\n",
            "Steps:  33%|███▎      | 166/500 [31:19<1:01:39, 11.08s/it, loss=0.171, lr=0.0001] \n",
            "Steps:  33%|███▎      | 166/500 [31:22<1:01:39, 11.08s/it, loss=0.0515, lr=0.0001]\n",
            "Steps:  33%|███▎      | 167/500 [31:24<1:01:57, 11.16s/it, loss=0.0515, lr=0.0001]\n",
            "Steps:  33%|███▎      | 167/500 [31:24<1:01:57, 11.16s/it, loss=0.116, lr=0.0001] \n",
            "Steps:  33%|███▎      | 167/500 [31:27<1:01:57, 11.16s/it, loss=0.158, lr=0.0001]\n",
            "Steps:  33%|███▎      | 167/500 [31:30<1:01:57, 11.16s/it, loss=0.0443, lr=0.0001]\n",
            "Steps:  33%|███▎      | 167/500 [31:33<1:01:57, 11.16s/it, loss=0.249, lr=0.0001] \n",
            "Steps:  34%|███▎      | 168/500 [31:36<1:02:50, 11.36s/it, loss=0.249, lr=0.0001]\n",
            "Steps:  34%|███▎      | 168/500 [31:36<1:02:50, 11.36s/it, loss=0.017, lr=0.0001]\n",
            "Steps:  34%|███▎      | 168/500 [31:39<1:02:50, 11.36s/it, loss=0.364, lr=0.0001]\n",
            "Steps:  34%|███▎      | 168/500 [31:42<1:02:50, 11.36s/it, loss=0.00569, lr=0.0001]\n",
            "Steps:  34%|███▎      | 168/500 [31:45<1:02:50, 11.36s/it, loss=0.0244, lr=0.0001] \n",
            "Steps:  34%|███▍      | 169/500 [31:49<1:05:07, 11.81s/it, loss=0.0244, lr=0.0001]\n",
            "Steps:  34%|███▍      | 169/500 [31:49<1:05:07, 11.81s/it, loss=0.145, lr=0.0001] \n",
            "Steps:  34%|███▍      | 169/500 [31:52<1:05:07, 11.81s/it, loss=0.00316, lr=0.0001]\n",
            "Steps:  34%|███▍      | 169/500 [31:55<1:05:07, 11.81s/it, loss=0.0339, lr=0.0001] \n",
            "Steps:  34%|███▍      | 170/500 [31:58<59:27, 10.81s/it, loss=0.0339, lr=0.0001]  \n",
            "Steps:  34%|███▍      | 170/500 [31:58<59:27, 10.81s/it, loss=0.0521, lr=0.0001]\n",
            "Steps:  34%|███▍      | 170/500 [32:02<59:27, 10.81s/it, loss=0.171, lr=0.0001] \n",
            "Steps:  34%|███▍      | 170/500 [32:05<59:27, 10.81s/it, loss=0.00475, lr=0.0001]\n",
            "Steps:  34%|███▍      | 170/500 [32:08<59:27, 10.81s/it, loss=0.266, lr=0.0001]  \n",
            "Steps:  34%|███▍      | 171/500 [32:11<1:03:18, 11.55s/it, loss=0.266, lr=0.0001]\n",
            "Steps:  34%|███▍      | 171/500 [32:11<1:03:18, 11.55s/it, loss=0.00496, lr=0.0001]\n",
            "Steps:  34%|███▍      | 171/500 [32:14<1:03:18, 11.55s/it, loss=0.0546, lr=0.0001] \n",
            "Steps:  34%|███▍      | 171/500 [32:16<1:03:18, 11.55s/it, loss=0.0787, lr=0.0001]\n",
            "Steps:  34%|███▍      | 171/500 [32:19<1:03:18, 11.55s/it, loss=0.229, lr=0.0001] \n",
            "Steps:  34%|███▍      | 172/500 [32:22<1:02:49, 11.49s/it, loss=0.229, lr=0.0001]\n",
            "Steps:  34%|███▍      | 172/500 [32:22<1:02:49, 11.49s/it, loss=0.0164, lr=0.0001]\n",
            "Steps:  34%|███▍      | 172/500 [32:25<1:02:49, 11.49s/it, loss=0.021, lr=0.0001] \n",
            "Steps:  34%|███▍      | 172/500 [32:28<1:02:49, 11.49s/it, loss=0.0325, lr=0.0001]\n",
            "Steps:  34%|███▍      | 172/500 [32:31<1:02:49, 11.49s/it, loss=0.0547, lr=0.0001]\n",
            "Steps:  35%|███▍      | 173/500 [32:34<1:02:45, 11.51s/it, loss=0.0547, lr=0.0001]\n",
            "Steps:  35%|███▍      | 173/500 [32:34<1:02:45, 11.51s/it, loss=0.1, lr=0.0001]   \n",
            "Steps:  35%|███▍      | 173/500 [32:36<1:02:45, 11.51s/it, loss=0.0272, lr=0.0001]\n",
            "Steps:  35%|███▍      | 173/500 [32:39<1:02:45, 11.51s/it, loss=0.00361, lr=0.0001]\n",
            "Steps:  35%|███▍      | 173/500 [32:42<1:02:45, 11.51s/it, loss=0.0476, lr=0.0001] \n",
            "Steps:  35%|███▍      | 174/500 [32:45<1:02:25, 11.49s/it, loss=0.0476, lr=0.0001]\n",
            "Steps:  35%|███▍      | 174/500 [32:45<1:02:25, 11.49s/it, loss=0.0158, lr=0.0001]\n",
            "Steps:  35%|███▍      | 174/500 [32:48<1:02:25, 11.49s/it, loss=0.136, lr=0.0001] \n",
            "Steps:  35%|███▍      | 174/500 [32:51<1:02:25, 11.49s/it, loss=0.09, lr=0.0001] \n",
            "Steps:  35%|███▌      | 175/500 [32:54<57:20, 10.59s/it, loss=0.09, lr=0.0001]  \n",
            "Steps:  35%|███▌      | 175/500 [32:54<57:20, 10.59s/it, loss=0.00234, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  35%|███▌      | 175/500 [32:59<57:20, 10.59s/it, loss=0.00384, lr=0.0001]\n",
            "Steps:  35%|███▌      | 175/500 [33:02<57:20, 10.59s/it, loss=0.0165, lr=0.0001] \n",
            "Steps:  35%|███▌      | 175/500 [33:04<57:20, 10.59s/it, loss=0.00229, lr=0.0001]\n",
            "Steps:  35%|███▌      | 176/500 [33:07<1:02:16, 11.53s/it, loss=0.00229, lr=0.0001]\n",
            "Steps:  35%|███▌      | 176/500 [33:07<1:02:16, 11.53s/it, loss=0.0291, lr=0.0001] \n",
            "Steps:  35%|███▌      | 176/500 [33:10<1:02:16, 11.53s/it, loss=0.409, lr=0.0001] \n",
            "Steps:  35%|███▌      | 176/500 [33:13<1:02:16, 11.53s/it, loss=0.137, lr=0.0001]\n",
            "Steps:  35%|███▌      | 176/500 [33:16<1:02:16, 11.53s/it, loss=0.417, lr=0.0001]\n",
            "Steps:  35%|███▌      | 177/500 [33:19<1:01:49, 11.49s/it, loss=0.417, lr=0.0001]\n",
            "Steps:  35%|███▌      | 177/500 [33:19<1:01:49, 11.49s/it, loss=0.0682, lr=0.0001]\n",
            "Steps:  35%|███▌      | 177/500 [33:22<1:01:49, 11.49s/it, loss=0.0875, lr=0.0001]\n",
            "Steps:  35%|███▌      | 177/500 [33:24<1:01:49, 11.49s/it, loss=0.0392, lr=0.0001]\n",
            "Steps:  35%|███▌      | 177/500 [33:28<1:01:49, 11.49s/it, loss=0.226, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  36%|███▌      | 178/500 [33:31<1:02:24, 11.63s/it, loss=0.226, lr=0.0001]\n",
            "Steps:  36%|███▌      | 178/500 [33:31<1:02:24, 11.63s/it, loss=0.0463, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  36%|███▌      | 178/500 [33:34<1:02:24, 11.63s/it, loss=0.0662, lr=0.0001]\n",
            "Steps:  36%|███▌      | 178/500 [33:36<1:02:24, 11.63s/it, loss=0.215, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  36%|███▌      | 178/500 [33:39<1:02:24, 11.63s/it, loss=0.167, lr=0.0001]\n",
            "Steps:  36%|███▌      | 179/500 [33:42<1:02:04, 11.60s/it, loss=0.167, lr=0.0001]\n",
            "Steps:  36%|███▌      | 179/500 [33:42<1:02:04, 11.60s/it, loss=0.0182, lr=0.0001]\n",
            "Steps:  36%|███▌      | 179/500 [33:45<1:02:04, 11.60s/it, loss=0.111, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  36%|███▌      | 179/500 [33:48<1:02:04, 11.60s/it, loss=0.0603, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  36%|███▌      | 180/500 [33:51<56:58, 10.68s/it, loss=0.0603, lr=0.0001]  \n",
            "Steps:  36%|███▌      | 180/500 [33:51<56:58, 10.68s/it, loss=0.0713, lr=0.0001]\n",
            "Steps:  36%|███▌      | 180/500 [33:54<56:58, 10.68s/it, loss=0.223, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  36%|███▌      | 180/500 [33:57<56:58, 10.68s/it, loss=0.0019, lr=0.0001]\n",
            "Steps:  36%|███▌      | 180/500 [33:59<56:58, 10.68s/it, loss=0.046, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  36%|███▌      | 181/500 [34:02<58:13, 10.95s/it, loss=0.046, lr=0.0001]\n",
            "Steps:  36%|███▌      | 181/500 [34:02<58:13, 10.95s/it, loss=0.00507, lr=0.0001]\n",
            "Steps:  36%|███▌      | 181/500 [34:05<58:13, 10.95s/it, loss=0.464, lr=0.0001]  \n",
            "Steps:  36%|███▌      | 181/500 [34:08<58:13, 10.95s/it, loss=0.168, lr=0.0001]\n",
            "Steps:  36%|███▌      | 181/500 [34:11<58:13, 10.95s/it, loss=0.108, lr=0.0001]\n",
            "Steps:  36%|███▋      | 182/500 [34:14<58:49, 11.10s/it, loss=0.108, lr=0.0001]\n",
            "Steps:  36%|███▋      | 182/500 [34:14<58:49, 11.10s/it, loss=0.038, lr=0.0001]\n",
            "Steps:  36%|███▋      | 182/500 [34:17<58:49, 11.10s/it, loss=0.00482, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  36%|███▋      | 182/500 [34:21<58:49, 11.10s/it, loss=0.0727, lr=0.0001] \n",
            "Steps:  36%|███▋      | 182/500 [34:24<58:49, 11.10s/it, loss=0.0292, lr=0.0001]\n",
            "Steps:  37%|███▋      | 183/500 [34:27<1:01:37, 11.66s/it, loss=0.0292, lr=0.0001]\n",
            "Steps:  37%|███▋      | 183/500 [34:27<1:01:37, 11.66s/it, loss=0.0773, lr=0.0001]\n",
            "Steps:  37%|███▋      | 183/500 [34:30<1:01:37, 11.66s/it, loss=0.369, lr=0.0001] \n",
            "Steps:  37%|███▋      | 183/500 [34:33<1:01:37, 11.66s/it, loss=0.0491, lr=0.0001]\n",
            "Steps:  37%|███▋      | 183/500 [34:36<1:01:37, 11.66s/it, loss=0.00298, lr=0.0001]\n",
            "Steps:  37%|███▋      | 184/500 [34:39<1:01:42, 11.72s/it, loss=0.00298, lr=0.0001]\n",
            "Steps:  37%|███▋      | 184/500 [34:39<1:01:42, 11.72s/it, loss=0.209, lr=0.0001]  \n",
            "Steps:  37%|███▋      | 184/500 [34:41<1:01:42, 11.72s/it, loss=0.00245, lr=0.0001]\n",
            "Steps:  37%|███▋      | 184/500 [34:44<1:01:42, 11.72s/it, loss=0.042, lr=0.0001]  \n",
            "Steps:  37%|███▋      | 185/500 [34:47<56:21, 10.73s/it, loss=0.042, lr=0.0001]  \n",
            "Steps:  37%|███▋      | 185/500 [34:47<56:21, 10.73s/it, loss=0.0175, lr=0.0001]\n",
            "Steps:  37%|███▋      | 185/500 [34:50<56:21, 10.73s/it, loss=0.0765, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  37%|███▋      | 185/500 [34:53<56:21, 10.73s/it, loss=0.0668, lr=0.0001]\n",
            "Steps:  37%|███▋      | 185/500 [34:56<56:21, 10.73s/it, loss=0.00631, lr=0.0001]\n",
            "Steps:  37%|███▋      | 186/500 [34:59<57:22, 10.96s/it, loss=0.00631, lr=0.0001]\n",
            "Steps:  37%|███▋      | 186/500 [34:59<57:22, 10.96s/it, loss=0.0068, lr=0.0001] \n",
            "Steps:  37%|███▋      | 186/500 [35:01<57:22, 10.96s/it, loss=0.605, lr=0.0001] \n",
            "Steps:  37%|███▋      | 186/500 [35:04<57:22, 10.96s/it, loss=0.0675, lr=0.0001]\n",
            "Steps:  37%|███▋      | 186/500 [35:07<57:22, 10.96s/it, loss=0.0741, lr=0.0001]\n",
            "Steps:  37%|███▋      | 187/500 [35:10<57:55, 11.10s/it, loss=0.0741, lr=0.0001]\n",
            "Steps:  37%|███▋      | 187/500 [35:10<57:55, 11.10s/it, loss=0.339, lr=0.0001] \n",
            "Steps:  37%|███▋      | 187/500 [35:13<57:55, 11.10s/it, loss=0.0481, lr=0.0001]\n",
            "Steps:  37%|███▋      | 187/500 [35:16<57:55, 11.10s/it, loss=0.211, lr=0.0001] \n",
            "Steps:  37%|███▋      | 187/500 [35:19<57:55, 11.10s/it, loss=0.116, lr=0.0001]\n",
            "Steps:  38%|███▊      | 188/500 [35:21<58:19, 11.22s/it, loss=0.116, lr=0.0001]\n",
            "Steps:  38%|███▊      | 188/500 [35:21<58:19, 11.22s/it, loss=0.0132, lr=0.0001]\n",
            "Steps:  38%|███▊      | 188/500 [35:24<58:19, 11.22s/it, loss=0.096, lr=0.0001] \n",
            "Steps:  38%|███▊      | 188/500 [35:29<58:19, 11.22s/it, loss=0.00136, lr=0.0001]\n",
            "Steps:  38%|███▊      | 188/500 [35:32<58:19, 11.22s/it, loss=0.0821, lr=0.0001] \n",
            "Steps:  38%|███▊      | 189/500 [35:35<1:02:06, 11.98s/it, loss=0.0821, lr=0.0001]\n",
            "Steps:  38%|███▊      | 189/500 [35:35<1:02:06, 11.98s/it, loss=0.101, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  38%|███▊      | 189/500 [35:38<1:02:06, 11.98s/it, loss=0.00388, lr=0.0001]\n",
            "Steps:  38%|███▊      | 189/500 [35:41<1:02:06, 11.98s/it, loss=0.234, lr=0.0001]  \n",
            "Steps:  38%|███▊      | 190/500 [35:44<56:59, 11.03s/it, loss=0.234, lr=0.0001]  \n",
            "Steps:  38%|███▊      | 190/500 [35:44<56:59, 11.03s/it, loss=0.298, lr=0.0001]\n",
            "Steps:  38%|███▊      | 190/500 [35:47<56:59, 11.03s/it, loss=0.0276, lr=0.0001]\n",
            "Steps:  38%|███▊      | 190/500 [35:50<56:59, 11.03s/it, loss=0.0304, lr=0.0001]\n",
            "Steps:  38%|███▊      | 190/500 [35:53<56:59, 11.03s/it, loss=0.421, lr=0.0001] \n",
            "Steps:  38%|███▊      | 191/500 [35:56<57:50, 11.23s/it, loss=0.421, lr=0.0001]\n",
            "Steps:  38%|███▊      | 191/500 [35:56<57:50, 11.23s/it, loss=0.219, lr=0.0001]\n",
            "Steps:  38%|███▊      | 191/500 [35:59<57:50, 11.23s/it, loss=0.00637, lr=0.0001]\n",
            "Steps:  38%|███▊      | 191/500 [36:01<57:50, 11.23s/it, loss=0.185, lr=0.0001]  \n",
            "Steps:  38%|███▊      | 191/500 [36:05<57:50, 11.23s/it, loss=0.0579, lr=0.0001]\n",
            "Steps:  38%|███▊      | 192/500 [36:07<58:24, 11.38s/it, loss=0.0579, lr=0.0001]\n",
            "Steps:  38%|███▊      | 192/500 [36:07<58:24, 11.38s/it, loss=0.264, lr=0.0001] \n",
            "Steps:  38%|███▊      | 192/500 [36:10<58:24, 11.38s/it, loss=0.0623, lr=0.0001]\n",
            "Steps:  38%|███▊      | 192/500 [36:13<58:24, 11.38s/it, loss=0.167, lr=0.0001] \n",
            "Steps:  38%|███▊      | 192/500 [36:16<58:24, 11.38s/it, loss=0.0335, lr=0.0001]\n",
            "Steps:  39%|███▊      | 193/500 [36:19<58:28, 11.43s/it, loss=0.0335, lr=0.0001]\n",
            "Steps:  39%|███▊      | 193/500 [36:19<58:28, 11.43s/it, loss=0.173, lr=0.0001] \n",
            "Steps:  39%|███▊      | 193/500 [36:23<58:28, 11.43s/it, loss=0.0396, lr=0.0001]\n",
            "Steps:  39%|███▊      | 193/500 [36:26<58:28, 11.43s/it, loss=0.00689, lr=0.0001]\n",
            "Steps:  39%|███▊      | 193/500 [36:29<58:28, 11.43s/it, loss=0.00367, lr=0.0001]\n",
            "Steps:  39%|███▉      | 194/500 [36:32<1:00:31, 11.87s/it, loss=0.00367, lr=0.0001]\n",
            "Steps:  39%|███▉      | 194/500 [36:32<1:00:31, 11.87s/it, loss=0.00246, lr=0.0001]\n",
            "Steps:  39%|███▉      | 194/500 [36:35<1:00:31, 11.87s/it, loss=0.0852, lr=0.0001] \n",
            "Steps:  39%|███▉      | 194/500 [36:38<1:00:31, 11.87s/it, loss=0.00219, lr=0.0001]\n",
            "Steps:  39%|███▉      | 195/500 [36:40<55:01, 10.82s/it, loss=0.00219, lr=0.0001]  \n",
            "Steps:  39%|███▉      | 195/500 [36:40<55:01, 10.82s/it, loss=0.0453, lr=0.0001] \n",
            "Steps:  39%|███▉      | 195/500 [36:43<55:01, 10.82s/it, loss=0.418, lr=0.0001] \n",
            "Steps:  39%|███▉      | 195/500 [36:46<55:01, 10.82s/it, loss=0.154, lr=0.0001]\n",
            "Steps:  39%|███▉      | 195/500 [36:49<55:01, 10.82s/it, loss=0.0075, lr=0.0001]\n",
            "Steps:  39%|███▉      | 196/500 [36:52<56:05, 11.07s/it, loss=0.0075, lr=0.0001]\n",
            "Steps:  39%|███▉      | 196/500 [36:52<56:05, 11.07s/it, loss=0.0287, lr=0.0001]\n",
            "Steps:  39%|███▉      | 196/500 [36:55<56:05, 11.07s/it, loss=0.353, lr=0.0001] \n",
            "Steps:  39%|███▉      | 196/500 [36:58<56:05, 11.07s/it, loss=0.159, lr=0.0001]\n",
            "Steps:  39%|███▉      | 196/500 [37:00<56:05, 11.07s/it, loss=0.117, lr=0.0001]\n",
            "Steps:  39%|███▉      | 197/500 [37:03<56:27, 11.18s/it, loss=0.117, lr=0.0001]\n",
            "Steps:  39%|███▉      | 197/500 [37:03<56:27, 11.18s/it, loss=0.501, lr=0.0001]\n",
            "Steps:  39%|███▉      | 197/500 [37:08<56:27, 11.18s/it, loss=0.00694, lr=0.0001]\n",
            "Steps:  39%|███▉      | 197/500 [37:10<56:27, 11.18s/it, loss=0.033, lr=0.0001]  \n",
            "Steps:  39%|███▉      | 197/500 [37:13<56:27, 11.18s/it, loss=0.0304, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  40%|███▉      | 198/500 [37:16<59:09, 11.75s/it, loss=0.0304, lr=0.0001]\n",
            "Steps:  40%|███▉      | 198/500 [37:16<59:09, 11.75s/it, loss=0.143, lr=0.0001] \n",
            "Steps:  40%|███▉      | 198/500 [37:19<59:09, 11.75s/it, loss=0.234, lr=0.0001]\n",
            "Steps:  40%|███▉      | 198/500 [37:22<59:09, 11.75s/it, loss=0.0156, lr=0.0001]\n",
            "Steps:  40%|███▉      | 198/500 [37:25<59:09, 11.75s/it, loss=0.0942, lr=0.0001]\n",
            "Steps:  40%|███▉      | 199/500 [37:28<58:29, 11.66s/it, loss=0.0942, lr=0.0001]\n",
            "Steps:  40%|███▉      | 199/500 [37:28<58:29, 11.66s/it, loss=0.0304, lr=0.0001]\n",
            "Steps:  40%|███▉      | 199/500 [37:31<58:29, 11.66s/it, loss=0.197, lr=0.0001] \n",
            "Steps:  40%|███▉      | 199/500 [37:34<58:29, 11.66s/it, loss=0.00705, lr=0.0001]\n",
            "Steps:  40%|████      | 200/500 [37:37<54:11, 10.84s/it, loss=0.00705, lr=0.0001]\n",
            "Steps:  40%|████      | 200/500 [37:37<54:11, 10.84s/it, loss=0.00154, lr=0.0001]\n",
            "Steps:  40%|████      | 200/500 [37:40<54:11, 10.84s/it, loss=0.00482, lr=0.0001]\n",
            "Steps:  40%|████      | 200/500 [37:43<54:11, 10.84s/it, loss=0.00592, lr=0.0001]\n",
            "Steps:  40%|████      | 200/500 [37:46<54:11, 10.84s/it, loss=0.0702, lr=0.0001] \n",
            "Steps:  40%|████      | 201/500 [37:48<55:02, 11.04s/it, loss=0.0702, lr=0.0001]\n",
            "Steps:  40%|████      | 201/500 [37:48<55:02, 11.04s/it, loss=0.00617, lr=0.0001]\n",
            "Steps:  40%|████      | 201/500 [37:51<55:02, 11.04s/it, loss=0.0544, lr=0.0001] \n",
            "Steps:  40%|████      | 201/500 [37:54<55:02, 11.04s/it, loss=0.00329, lr=0.0001]\n",
            "Steps:  40%|████      | 201/500 [37:57<55:02, 11.04s/it, loss=0.0213, lr=0.0001] \n",
            "Steps:  40%|████      | 202/500 [38:02<58:41, 11.82s/it, loss=0.0213, lr=0.0001]\n",
            "Steps:  40%|████      | 202/500 [38:02<58:41, 11.82s/it, loss=0.499, lr=0.0001] \n",
            "Steps:  40%|████      | 202/500 [38:05<58:41, 11.82s/it, loss=0.0844, lr=0.0001]\n",
            "Steps:  40%|████      | 202/500 [38:08<58:41, 11.82s/it, loss=0.218, lr=0.0001] \n",
            "Steps:  40%|████      | 202/500 [38:11<58:41, 11.82s/it, loss=0.0562, lr=0.0001]\n",
            "Steps:  41%|████      | 203/500 [38:13<57:56, 11.71s/it, loss=0.0562, lr=0.0001]\n",
            "Steps:  41%|████      | 203/500 [38:13<57:56, 11.71s/it, loss=0.0493, lr=0.0001]\n",
            "Steps:  41%|████      | 203/500 [38:16<57:56, 11.71s/it, loss=0.00372, lr=0.0001]\n",
            "Steps:  41%|████      | 203/500 [38:19<57:56, 11.71s/it, loss=0.00147, lr=0.0001]\n",
            "Steps:  41%|████      | 203/500 [38:22<57:56, 11.71s/it, loss=0.36, lr=0.0001]   \n",
            "Steps:  41%|████      | 204/500 [38:25<57:20, 11.62s/it, loss=0.36, lr=0.0001]\n",
            "Steps:  41%|████      | 204/500 [38:25<57:20, 11.62s/it, loss=0.0292, lr=0.0001]\n",
            "Steps:  41%|████      | 204/500 [38:28<57:20, 11.62s/it, loss=0.245, lr=0.0001] \n",
            "Steps:  41%|████      | 204/500 [38:31<57:20, 11.62s/it, loss=0.288, lr=0.0001]\n",
            "Steps:  41%|████      | 205/500 [38:34<53:04, 10.80s/it, loss=0.288, lr=0.0001]\n",
            "Steps:  41%|████      | 205/500 [38:34<53:04, 10.80s/it, loss=0.0289, lr=0.0001]\n",
            "Steps:  41%|████      | 205/500 [38:37<53:04, 10.80s/it, loss=0.0053, lr=0.0001]\n",
            "Steps:  41%|████      | 205/500 [38:41<53:04, 10.80s/it, loss=0.0638, lr=0.0001]\n",
            "Steps:  41%|████      | 205/500 [38:44<53:04, 10.80s/it, loss=0.1, lr=0.0001]   \n",
            "Steps:  41%|████      | 206/500 [38:47<56:07, 11.46s/it, loss=0.1, lr=0.0001]\n",
            "Steps:  41%|████      | 206/500 [38:47<56:07, 11.46s/it, loss=0.167, lr=0.0001]\n",
            "Steps:  41%|████      | 206/500 [38:50<56:07, 11.46s/it, loss=0.0385, lr=0.0001]\n",
            "Steps:  41%|████      | 206/500 [38:52<56:07, 11.46s/it, loss=0.00801, lr=0.0001]\n",
            "Steps:  41%|████      | 206/500 [38:55<56:07, 11.46s/it, loss=0.0122, lr=0.0001] \n",
            "Steps:  41%|████▏     | 207/500 [38:58<56:23, 11.55s/it, loss=0.0122, lr=0.0001]\n",
            "Steps:  41%|████▏     | 207/500 [38:58<56:23, 11.55s/it, loss=0.00244, lr=0.0001]\n",
            "Steps:  41%|████▏     | 207/500 [39:01<56:23, 11.55s/it, loss=0.00621, lr=0.0001]\n",
            "Steps:  41%|████▏     | 207/500 [39:04<56:23, 11.55s/it, loss=0.334, lr=0.0001]  \n",
            "Steps:  41%|████▏     | 207/500 [39:07<56:23, 11.55s/it, loss=0.118, lr=0.0001]\n",
            "Steps:  42%|████▏     | 208/500 [39:10<56:00, 11.51s/it, loss=0.118, lr=0.0001]\n",
            "Steps:  42%|████▏     | 208/500 [39:10<56:00, 11.51s/it, loss=0.159, lr=0.0001]\n",
            "Steps:  42%|████▏     | 208/500 [39:13<56:00, 11.51s/it, loss=0.394, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  42%|████▏     | 208/500 [39:16<56:00, 11.51s/it, loss=0.0576, lr=0.0001]\n",
            "Steps:  42%|████▏     | 208/500 [39:19<56:00, 11.51s/it, loss=0.00325, lr=0.0001]\n",
            "Steps:  42%|████▏     | 209/500 [39:22<56:07, 11.57s/it, loss=0.00325, lr=0.0001]\n",
            "Steps:  42%|████▏     | 209/500 [39:22<56:07, 11.57s/it, loss=0.26, lr=0.0001]   \n",
            "Steps:  42%|████▏     | 209/500 [39:24<56:07, 11.57s/it, loss=0.311, lr=0.0001]\n",
            "Steps:  42%|████▏     | 209/500 [39:27<56:07, 11.57s/it, loss=0.0029, lr=0.0001]\n",
            "Steps:  42%|████▏     | 210/500 [39:30<51:22, 10.63s/it, loss=0.0029, lr=0.0001]\n",
            "Steps:  42%|████▏     | 210/500 [39:30<51:22, 10.63s/it, loss=0.131, lr=0.0001] \n",
            "Steps:  42%|████▏     | 210/500 [39:33<51:22, 10.63s/it, loss=0.29, lr=0.0001] \n",
            "Steps:  42%|████▏     | 210/500 [39:36<51:22, 10.63s/it, loss=0.0349, lr=0.0001]\n",
            "Steps:  42%|████▏     | 210/500 [39:39<51:22, 10.63s/it, loss=0.00596, lr=0.0001]\n",
            "Steps:  42%|████▏     | 211/500 [39:43<54:42, 11.36s/it, loss=0.00596, lr=0.0001]\n",
            "Steps:  42%|████▏     | 211/500 [39:43<54:42, 11.36s/it, loss=0.0401, lr=0.0001] \n",
            "Steps:  42%|████▏     | 211/500 [39:46<54:42, 11.36s/it, loss=0.00828, lr=0.0001]\n",
            "Steps:  42%|████▏     | 211/500 [39:49<54:42, 11.36s/it, loss=0.00583, lr=0.0001]\n",
            "Steps:  42%|████▏     | 211/500 [39:52<54:42, 11.36s/it, loss=0.114, lr=0.0001]  \n",
            "Steps:  42%|████▏     | 212/500 [39:55<54:35, 11.37s/it, loss=0.114, lr=0.0001]\n",
            "Steps:  42%|████▏     | 212/500 [39:55<54:35, 11.37s/it, loss=0.015, lr=0.0001]\n",
            "Steps:  42%|████▏     | 212/500 [39:57<54:35, 11.37s/it, loss=0.132, lr=0.0001]\n",
            "Steps:  42%|████▏     | 212/500 [40:00<54:35, 11.37s/it, loss=0.105, lr=0.0001]\n",
            "Steps:  42%|████▏     | 212/500 [40:03<54:35, 11.37s/it, loss=0.195, lr=0.0001]\n",
            "Steps:  43%|████▎     | 213/500 [40:06<54:36, 11.41s/it, loss=0.195, lr=0.0001]\n",
            "Steps:  43%|████▎     | 213/500 [40:06<54:36, 11.41s/it, loss=0.0116, lr=0.0001]\n",
            "Steps:  43%|████▎     | 213/500 [40:09<54:36, 11.41s/it, loss=0.00869, lr=0.0001]\n",
            "Steps:  43%|████▎     | 213/500 [40:12<54:36, 11.41s/it, loss=0.0025, lr=0.0001] \n",
            "Steps:  43%|████▎     | 213/500 [40:15<54:36, 11.41s/it, loss=0.0159, lr=0.0001]\n",
            "Steps:  43%|████▎     | 214/500 [40:17<54:22, 11.41s/it, loss=0.0159, lr=0.0001]\n",
            "Steps:  43%|████▎     | 214/500 [40:17<54:22, 11.41s/it, loss=0.00461, lr=0.0001]\n",
            "Steps:  43%|████▎     | 214/500 [40:20<54:22, 11.41s/it, loss=0.0122, lr=0.0001] \n",
            "Steps:  43%|████▎     | 214/500 [40:23<54:22, 11.41s/it, loss=0.0223, lr=0.0001]\n",
            "Steps:  43%|████▎     | 215/500 [40:26<50:27, 10.62s/it, loss=0.0223, lr=0.0001]\n",
            "Steps:  43%|████▎     | 215/500 [40:26<50:27, 10.62s/it, loss=0.00269, lr=0.0001]\n",
            "Steps:  43%|████▎     | 215/500 [40:31<50:27, 10.62s/it, loss=0.238, lr=0.0001]  \n",
            "Steps:  43%|████▎     | 215/500 [40:34<50:27, 10.62s/it, loss=0.00667, lr=0.0001]\n",
            "Steps:  43%|████▎     | 215/500 [40:37<50:27, 10.62s/it, loss=0.194, lr=0.0001]  \n",
            "Steps:  43%|████▎     | 216/500 [40:40<54:33, 11.53s/it, loss=0.194, lr=0.0001]\n",
            "Steps:  43%|████▎     | 216/500 [40:40<54:33, 11.53s/it, loss=0.0874, lr=0.0001]\n",
            "Steps:  43%|████▎     | 216/500 [40:43<54:33, 11.53s/it, loss=0.0399, lr=0.0001]\n",
            "Steps:  43%|████▎     | 216/500 [40:46<54:33, 11.53s/it, loss=0.0284, lr=0.0001]\n",
            "Steps:  43%|████▎     | 216/500 [40:49<54:33, 11.53s/it, loss=0.0644, lr=0.0001]\n",
            "Steps:  43%|████▎     | 217/500 [40:51<54:22, 11.53s/it, loss=0.0644, lr=0.0001]\n",
            "Steps:  43%|████▎     | 217/500 [40:51<54:22, 11.53s/it, loss=0.00197, lr=0.0001]\n",
            "Steps:  43%|████▎     | 217/500 [40:54<54:22, 11.53s/it, loss=0.0295, lr=0.0001] \n",
            "Steps:  43%|████▎     | 217/500 [40:57<54:22, 11.53s/it, loss=0.233, lr=0.0001] \n",
            "Steps:  43%|████▎     | 217/500 [41:00<54:22, 11.53s/it, loss=0.00878, lr=0.0001]\n",
            "Steps:  44%|████▎     | 218/500 [41:03<54:34, 11.61s/it, loss=0.00878, lr=0.0001]\n",
            "Steps:  44%|████▎     | 218/500 [41:03<54:34, 11.61s/it, loss=0.00349, lr=0.0001]\n",
            "Steps:  44%|████▎     | 218/500 [41:06<54:34, 11.61s/it, loss=0.0075, lr=0.0001] \n",
            "Steps:  44%|████▎     | 218/500 [41:09<54:34, 11.61s/it, loss=0.0132, lr=0.0001]\n",
            "Steps:  44%|████▎     | 218/500 [41:12<54:34, 11.61s/it, loss=0.248, lr=0.0001] \n",
            "Steps:  44%|████▍     | 219/500 [41:15<54:07, 11.56s/it, loss=0.248, lr=0.0001]\n",
            "Steps:  44%|████▍     | 219/500 [41:15<54:07, 11.56s/it, loss=0.011, lr=0.0001]\n",
            "Steps:  44%|████▍     | 219/500 [41:17<54:07, 11.56s/it, loss=0.181, lr=0.0001]\n",
            "Steps:  44%|████▍     | 219/500 [41:20<54:07, 11.56s/it, loss=0.0156, lr=0.0001]\n",
            "Steps:  44%|████▍     | 220/500 [41:23<49:39, 10.64s/it, loss=0.0156, lr=0.0001]\n",
            "Steps:  44%|████▍     | 220/500 [41:23<49:39, 10.64s/it, loss=0.0034, lr=0.0001]\n",
            "Steps:  44%|████▍     | 220/500 [41:26<49:39, 10.64s/it, loss=0.284, lr=0.0001] \n",
            "Steps:  44%|████▍     | 220/500 [41:29<49:39, 10.64s/it, loss=0.0323, lr=0.0001]\n",
            "Steps:  44%|████▍     | 220/500 [41:32<49:39, 10.64s/it, loss=0.0352, lr=0.0001]\n",
            "Steps:  44%|████▍     | 221/500 [41:35<50:41, 10.90s/it, loss=0.0352, lr=0.0001]\n",
            "Steps:  44%|████▍     | 221/500 [41:35<50:41, 10.90s/it, loss=0.181, lr=0.0001] \n",
            "Steps:  44%|████▍     | 221/500 [41:37<50:41, 10.90s/it, loss=0.195, lr=0.0001]\n",
            "Steps:  44%|████▍     | 221/500 [41:40<50:41, 10.90s/it, loss=0.16, lr=0.0001] \n",
            "Steps:  44%|████▍     | 221/500 [41:43<50:41, 10.90s/it, loss=0.16, lr=0.0001]\n",
            "Steps:  44%|████▍     | 222/500 [41:46<51:18, 11.07s/it, loss=0.16, lr=0.0001]\n",
            "Steps:  44%|████▍     | 222/500 [41:46<51:18, 11.07s/it, loss=0.0574, lr=0.0001]\n",
            "Steps:  44%|████▍     | 222/500 [41:49<51:18, 11.07s/it, loss=0.28, lr=0.0001]  \n",
            "Steps:  44%|████▍     | 222/500 [41:52<51:18, 11.07s/it, loss=0.0579, lr=0.0001]\n",
            "Steps:  44%|████▍     | 222/500 [41:56<51:18, 11.07s/it, loss=0.0576, lr=0.0001]\n",
            "Steps:  45%|████▍     | 223/500 [41:59<53:43, 11.64s/it, loss=0.0576, lr=0.0001]\n",
            "Steps:  45%|████▍     | 223/500 [41:59<53:43, 11.64s/it, loss=0.0204, lr=0.0001]\n",
            "Steps:  45%|████▍     | 223/500 [42:02<53:43, 11.64s/it, loss=0.178, lr=0.0001] \n",
            "Steps:  45%|████▍     | 223/500 [42:05<53:43, 11.64s/it, loss=0.103, lr=0.0001]\n",
            "Steps:  45%|████▍     | 223/500 [42:08<53:43, 11.64s/it, loss=0.203, lr=0.0001]\n",
            "Steps:  45%|████▍     | 224/500 [42:11<53:55, 11.72s/it, loss=0.203, lr=0.0001]\n",
            "Steps:  45%|████▍     | 224/500 [42:11<53:55, 11.72s/it, loss=0.278, lr=0.0001]\n",
            "Steps:  45%|████▍     | 224/500 [42:14<53:55, 11.72s/it, loss=0.0717, lr=0.0001]\n",
            "Steps:  45%|████▍     | 224/500 [42:17<53:55, 11.72s/it, loss=0.00414, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  45%|████▌     | 225/500 [42:19<49:09, 10.73s/it, loss=0.00414, lr=0.0001]\n",
            "Steps:  45%|████▌     | 225/500 [42:19<49:09, 10.73s/it, loss=0.0112, lr=0.0001] \n",
            "Steps:  45%|████▌     | 225/500 [42:22<49:09, 10.73s/it, loss=0.0643, lr=0.0001]\n",
            "Steps:  45%|████▌     | 225/500 [42:27<49:09, 10.73s/it, loss=0.205, lr=0.0001] \n",
            "Steps:  45%|████▌     | 225/500 [42:29<49:09, 10.73s/it, loss=0.00303, lr=0.0001]\n",
            "Steps:  45%|████▌     | 226/500 [42:32<52:08, 11.42s/it, loss=0.00303, lr=0.0001]\n",
            "Steps:  45%|████▌     | 226/500 [42:32<52:08, 11.42s/it, loss=0.383, lr=0.0001]  \n",
            "Steps:  45%|████▌     | 226/500 [42:35<52:08, 11.42s/it, loss=0.0586, lr=0.0001]\n",
            "Steps:  45%|████▌     | 226/500 [42:38<52:08, 11.42s/it, loss=0.233, lr=0.0001] \n",
            "Steps:  45%|████▌     | 226/500 [42:41<52:08, 11.42s/it, loss=0.0352, lr=0.0001]\n",
            "Steps:  45%|████▌     | 227/500 [42:44<52:01, 11.43s/it, loss=0.0352, lr=0.0001]\n",
            "Steps:  45%|████▌     | 227/500 [42:44<52:01, 11.43s/it, loss=0.0111, lr=0.0001]\n",
            "Steps:  45%|████▌     | 227/500 [42:47<52:01, 11.43s/it, loss=0.00421, lr=0.0001]\n",
            "Steps:  45%|████▌     | 227/500 [42:50<52:01, 11.43s/it, loss=0.116, lr=0.0001]  \n",
            "Steps:  45%|████▌     | 227/500 [42:52<52:01, 11.43s/it, loss=0.00515, lr=0.0001]\n",
            "Steps:  46%|████▌     | 228/500 [42:55<51:55, 11.45s/it, loss=0.00515, lr=0.0001]\n",
            "Steps:  46%|████▌     | 228/500 [42:55<51:55, 11.45s/it, loss=0.00656, lr=0.0001]\n",
            "Steps:  46%|████▌     | 228/500 [42:58<51:55, 11.45s/it, loss=0.422, lr=0.0001]  \n",
            "Steps:  46%|████▌     | 228/500 [43:01<51:55, 11.45s/it, loss=0.15, lr=0.0001] \n",
            "Steps:  46%|████▌     | 228/500 [43:04<51:55, 11.45s/it, loss=0.0283, lr=0.0001]\n",
            "Steps:  46%|████▌     | 229/500 [43:07<51:45, 11.46s/it, loss=0.0283, lr=0.0001]\n",
            "Steps:  46%|████▌     | 229/500 [43:07<51:45, 11.46s/it, loss=0.356, lr=0.0001] \n",
            "Steps:  46%|████▌     | 229/500 [43:10<51:45, 11.46s/it, loss=0.0214, lr=0.0001]\n",
            "Steps:  46%|████▌     | 229/500 [43:13<51:45, 11.46s/it, loss=0.116, lr=0.0001] \n",
            "Steps:  46%|████▌     | 230/500 [43:16<47:53, 10.64s/it, loss=0.116, lr=0.0001]\n",
            "Steps:  46%|████▌     | 230/500 [43:16<47:53, 10.64s/it, loss=0.0165, lr=0.0001]\n",
            "Steps:  46%|████▌     | 230/500 [43:19<47:53, 10.64s/it, loss=0.0946, lr=0.0001]\n",
            "Steps:  46%|████▌     | 230/500 [43:21<47:53, 10.64s/it, loss=0.00706, lr=0.0001]\n",
            "Steps:  46%|████▌     | 230/500 [43:24<47:53, 10.64s/it, loss=0.112, lr=0.0001]  \n",
            "Steps:  46%|████▌     | 231/500 [43:27<49:04, 10.95s/it, loss=0.112, lr=0.0001]\n",
            "Steps:  46%|████▌     | 231/500 [43:27<49:04, 10.95s/it, loss=0.00905, lr=0.0001]\n",
            "Steps:  46%|████▌     | 231/500 [43:30<49:04, 10.95s/it, loss=0.0689, lr=0.0001] \n",
            "Steps:  46%|████▌     | 231/500 [43:33<49:04, 10.95s/it, loss=0.162, lr=0.0001] \n",
            "Steps:  46%|████▌     | 231/500 [43:36<49:04, 10.95s/it, loss=0.0137, lr=0.0001]\n",
            "Steps:  46%|████▋     | 232/500 [43:40<51:26, 11.52s/it, loss=0.0137, lr=0.0001]\n",
            "Steps:  46%|████▋     | 232/500 [43:40<51:26, 11.52s/it, loss=0.00842, lr=0.0001]\n",
            "Steps:  46%|████▋     | 232/500 [43:43<51:26, 11.52s/it, loss=0.00689, lr=0.0001]\n",
            "Steps:  46%|████▋     | 232/500 [43:46<51:26, 11.52s/it, loss=0.0722, lr=0.0001] \n",
            "Steps:  46%|████▋     | 232/500 [43:49<51:26, 11.52s/it, loss=0.0255, lr=0.0001]\n",
            "Steps:  47%|████▋     | 233/500 [43:52<51:37, 11.60s/it, loss=0.0255, lr=0.0001]\n",
            "Steps:  47%|████▋     | 233/500 [43:52<51:37, 11.60s/it, loss=0.506, lr=0.0001] \n",
            "Steps:  47%|████▋     | 233/500 [43:55<51:37, 11.60s/it, loss=0.00268, lr=0.0001]\n",
            "Steps:  47%|████▋     | 233/500 [43:58<51:37, 11.60s/it, loss=0.00355, lr=0.0001]\n",
            "Steps:  47%|████▋     | 233/500 [44:00<51:37, 11.60s/it, loss=0.0437, lr=0.0001] \n",
            "Steps:  47%|████▋     | 234/500 [44:03<51:05, 11.52s/it, loss=0.0437, lr=0.0001]\n",
            "Steps:  47%|████▋     | 234/500 [44:03<51:05, 11.52s/it, loss=0.0264, lr=0.0001]\n",
            "Steps:  47%|████▋     | 234/500 [44:06<51:05, 11.52s/it, loss=0.0318, lr=0.0001]\n",
            "Steps:  47%|████▋     | 234/500 [44:09<51:05, 11.52s/it, loss=0.00442, lr=0.0001]\n",
            "Steps:  47%|████▋     | 235/500 [44:12<46:54, 10.62s/it, loss=0.00442, lr=0.0001]\n",
            "Steps:  47%|████▋     | 235/500 [44:12<46:54, 10.62s/it, loss=0.26, lr=0.0001]   \n",
            "Steps:  47%|████▋     | 235/500 [44:15<46:54, 10.62s/it, loss=0.00508, lr=0.0001]\n",
            "Steps:  47%|████▋     | 235/500 [44:18<46:54, 10.62s/it, loss=0.105, lr=0.0001]  \n",
            "Steps:  47%|████▋     | 235/500 [44:20<46:54, 10.62s/it, loss=0.196, lr=0.0001]\n",
            "Steps:  47%|████▋     | 236/500 [44:23<47:59, 10.91s/it, loss=0.196, lr=0.0001]\n",
            "Steps:  47%|████▋     | 236/500 [44:23<47:59, 10.91s/it, loss=0.114, lr=0.0001]\n",
            "Steps:  47%|████▋     | 236/500 [44:26<47:59, 10.91s/it, loss=0.069, lr=0.0001]\n",
            "Steps:  47%|████▋     | 236/500 [44:30<47:59, 10.91s/it, loss=0.00632, lr=0.0001]\n",
            "Steps:  47%|████▋     | 236/500 [44:33<47:59, 10.91s/it, loss=0.0202, lr=0.0001] \n",
            "Steps:  47%|████▋     | 237/500 [44:36<50:23, 11.49s/it, loss=0.0202, lr=0.0001]\n",
            "Steps:  47%|████▋     | 237/500 [44:36<50:23, 11.49s/it, loss=0.0384, lr=0.0001]\n",
            "Steps:  47%|████▋     | 237/500 [44:39<50:23, 11.49s/it, loss=0.0662, lr=0.0001]\n",
            "Steps:  47%|████▋     | 237/500 [44:42<50:23, 11.49s/it, loss=0.0368, lr=0.0001]\n",
            "Steps:  47%|████▋     | 237/500 [44:45<50:23, 11.49s/it, loss=0.0173, lr=0.0001]\n",
            "Steps:  48%|████▊     | 238/500 [44:48<50:06, 11.47s/it, loss=0.0173, lr=0.0001]\n",
            "Steps:  48%|████▊     | 238/500 [44:48<50:06, 11.47s/it, loss=0.16, lr=0.0001]  \n",
            "Steps:  48%|████▊     | 238/500 [44:50<50:06, 11.47s/it, loss=0.0114, lr=0.0001]\n",
            "Steps:  48%|████▊     | 238/500 [44:53<50:06, 11.47s/it, loss=0.00256, lr=0.0001]\n",
            "Steps:  48%|████▊     | 238/500 [44:56<50:06, 11.47s/it, loss=0.00663, lr=0.0001]\n",
            "Steps:  48%|████▊     | 239/500 [44:59<49:55, 11.48s/it, loss=0.00663, lr=0.0001]\n",
            "Steps:  48%|████▊     | 239/500 [44:59<49:55, 11.48s/it, loss=0.021, lr=0.0001]  \n",
            "Steps:  48%|████▊     | 239/500 [45:02<49:55, 11.48s/it, loss=0.00662, lr=0.0001]\n",
            "Steps:  48%|████▊     | 239/500 [45:05<49:55, 11.48s/it, loss=0.371, lr=0.0001]  \n",
            "Steps:  48%|████▊     | 240/500 [45:08<46:15, 10.68s/it, loss=0.371, lr=0.0001]\n",
            "Steps:  48%|████▊     | 240/500 [45:08<46:15, 10.68s/it, loss=0.00757, lr=0.0001]\n",
            "Steps:  48%|████▊     | 240/500 [45:11<46:15, 10.68s/it, loss=0.0445, lr=0.0001] \n",
            "Steps:  48%|████▊     | 240/500 [45:15<46:15, 10.68s/it, loss=0.00661, lr=0.0001]\n",
            "Steps:  48%|████▊     | 240/500 [45:18<46:15, 10.68s/it, loss=0.0051, lr=0.0001] \n",
            "Steps:  48%|████▊     | 241/500 [45:21<48:59, 11.35s/it, loss=0.0051, lr=0.0001]\n",
            "Steps:  48%|████▊     | 241/500 [45:21<48:59, 11.35s/it, loss=0.0247, lr=0.0001]\n",
            "Steps:  48%|████▊     | 241/500 [45:24<48:59, 11.35s/it, loss=0.244, lr=0.0001] \n",
            "Steps:  48%|████▊     | 241/500 [45:27<48:59, 11.35s/it, loss=0.207, lr=0.0001]\n",
            "Steps:  48%|████▊     | 241/500 [45:29<48:59, 11.35s/it, loss=0.0948, lr=0.0001]\n",
            "Steps:  48%|████▊     | 242/500 [45:32<48:59, 11.39s/it, loss=0.0948, lr=0.0001]\n",
            "Steps:  48%|████▊     | 242/500 [45:32<48:59, 11.39s/it, loss=0.0177, lr=0.0001]\n",
            "Steps:  48%|████▊     | 242/500 [45:35<48:59, 11.39s/it, loss=0.0132, lr=0.0001]\n",
            "Steps:  48%|████▊     | 242/500 [45:38<48:59, 11.39s/it, loss=0.0208, lr=0.0001]\n",
            "Steps:  48%|████▊     | 242/500 [45:41<48:59, 11.39s/it, loss=0.126, lr=0.0001] \n",
            "Steps:  49%|████▊     | 243/500 [45:44<48:54, 11.42s/it, loss=0.126, lr=0.0001]\n",
            "Steps:  49%|████▊     | 243/500 [45:44<48:54, 11.42s/it, loss=0.165, lr=0.0001]\n",
            "Steps:  49%|████▊     | 243/500 [45:47<48:54, 11.42s/it, loss=0.265, lr=0.0001]\n",
            "Steps:  49%|████▊     | 243/500 [45:50<48:54, 11.42s/it, loss=0.0623, lr=0.0001]\n",
            "Steps:  49%|████▊     | 243/500 [45:52<48:54, 11.42s/it, loss=0.0465, lr=0.0001]\n",
            "Steps:  49%|████▉     | 244/500 [45:55<48:53, 11.46s/it, loss=0.0465, lr=0.0001]\n",
            "Steps:  49%|████▉     | 244/500 [45:55<48:53, 11.46s/it, loss=0.259, lr=0.0001] \n",
            "Steps:  49%|████▉     | 244/500 [45:58<48:53, 11.46s/it, loss=0.00298, lr=0.0001]\n",
            "Steps:  49%|████▉     | 244/500 [46:01<48:53, 11.46s/it, loss=0.0194, lr=0.0001] \n",
            "Steps:  49%|████▉     | 245/500 [46:04<45:18, 10.66s/it, loss=0.0194, lr=0.0001]\n",
            "Steps:  49%|████▉     | 245/500 [46:04<45:18, 10.66s/it, loss=0.0525, lr=0.0001]\n",
            "Steps:  49%|████▉     | 245/500 [46:07<45:18, 10.66s/it, loss=0.389, lr=0.0001] \n",
            "Steps:  49%|████▉     | 245/500 [46:10<45:18, 10.66s/it, loss=0.124, lr=0.0001]\n",
            "Steps:  49%|████▉     | 245/500 [46:13<45:18, 10.66s/it, loss=0.00664, lr=0.0001]\n",
            "Steps:  49%|████▉     | 246/500 [46:16<46:16, 10.93s/it, loss=0.00664, lr=0.0001]\n",
            "Steps:  49%|████▉     | 246/500 [46:16<46:16, 10.93s/it, loss=0.0125, lr=0.0001] \n",
            "Steps:  49%|████▉     | 246/500 [46:19<46:16, 10.93s/it, loss=0.198, lr=0.0001] \n",
            "Steps:  49%|████▉     | 246/500 [46:21<46:16, 10.93s/it, loss=0.1, lr=0.0001]  \n",
            "Steps:  49%|████▉     | 246/500 [46:24<46:16, 10.93s/it, loss=0.00303, lr=0.0001]\n",
            "Steps:  49%|████▉     | 247/500 [46:27<46:44, 11.08s/it, loss=0.00303, lr=0.0001]\n",
            "Steps:  49%|████▉     | 247/500 [46:27<46:44, 11.08s/it, loss=0.231, lr=0.0001]  \n",
            "Steps:  49%|████▉     | 247/500 [46:30<46:44, 11.08s/it, loss=0.321, lr=0.0001]\n",
            "Steps:  49%|████▉     | 247/500 [46:33<46:44, 11.08s/it, loss=0.00323, lr=0.0001]\n",
            "Steps:  49%|████▉     | 247/500 [46:36<46:44, 11.08s/it, loss=0.0156, lr=0.0001] \n",
            "Steps:  50%|████▉     | 248/500 [46:39<47:15, 11.25s/it, loss=0.0156, lr=0.0001]\n",
            "Steps:  50%|████▉     | 248/500 [46:39<47:15, 11.25s/it, loss=0.0776, lr=0.0001]\n",
            "Steps:  50%|████▉     | 248/500 [46:42<47:15, 11.25s/it, loss=0.00214, lr=0.0001]\n",
            "Steps:  50%|████▉     | 248/500 [46:45<47:15, 11.25s/it, loss=0.00458, lr=0.0001]\n",
            "Steps:  50%|████▉     | 248/500 [46:49<47:15, 11.25s/it, loss=0.0503, lr=0.0001] \n",
            "Steps:  50%|████▉     | 249/500 [46:52<49:13, 11.77s/it, loss=0.0503, lr=0.0001]\n",
            "Steps:  50%|████▉     | 249/500 [46:52<49:13, 11.77s/it, loss=0.0499, lr=0.0001]\n",
            "Steps:  50%|████▉     | 249/500 [46:55<49:13, 11.77s/it, loss=0.171, lr=0.0001] \n",
            "Steps:  50%|████▉     | 249/500 [46:58<49:13, 11.77s/it, loss=0.0402, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  50%|█████     | 250/500 [47:00<45:02, 10.81s/it, loss=0.0402, lr=0.0001]\n",
            "Steps:  50%|█████     | 250/500 [47:00<45:02, 10.81s/it, loss=0.149, lr=0.0001] \n",
            "Steps:  50%|█████     | 250/500 [47:03<45:02, 10.81s/it, loss=0.0105, lr=0.0001]\n",
            "Steps:  50%|█████     | 250/500 [47:06<45:02, 10.81s/it, loss=0.00216, lr=0.0001]\n",
            "Steps:  50%|█████     | 250/500 [47:09<45:02, 10.81s/it, loss=0.00652, lr=0.0001]\n",
            "Steps:  50%|█████     | 251/500 [47:12<45:41, 11.01s/it, loss=0.00652, lr=0.0001]\n",
            "Steps:  50%|█████     | 251/500 [47:12<45:41, 11.01s/it, loss=0.142, lr=0.0001]  \n",
            "Steps:  50%|█████     | 251/500 [47:15<45:41, 11.01s/it, loss=0.0868, lr=0.0001]\n",
            "Steps:  50%|█████     | 251/500 [47:19<45:41, 11.01s/it, loss=0.566, lr=0.0001] \n",
            "Steps:  50%|█████     | 251/500 [47:22<45:41, 11.01s/it, loss=0.00664, lr=0.0001]\n",
            "Steps:  50%|█████     | 252/500 [47:25<47:55, 11.60s/it, loss=0.00664, lr=0.0001]\n",
            "Steps:  50%|█████     | 252/500 [47:25<47:55, 11.60s/it, loss=0.202, lr=0.0001]  \n",
            "Steps:  50%|█████     | 252/500 [47:28<47:55, 11.60s/it, loss=0.223, lr=0.0001]\n",
            "Steps:  50%|█████     | 252/500 [47:30<47:55, 11.60s/it, loss=0.035, lr=0.0001]\n",
            "Steps:  50%|█████     | 252/500 [47:33<47:55, 11.60s/it, loss=0.0927, lr=0.0001]\n",
            "Steps:  51%|█████     | 253/500 [47:36<47:35, 11.56s/it, loss=0.0927, lr=0.0001]\n",
            "Steps:  51%|█████     | 253/500 [47:36<47:35, 11.56s/it, loss=0.199, lr=0.0001] \n",
            "Steps:  51%|█████     | 253/500 [47:40<47:35, 11.56s/it, loss=0.102, lr=0.0001]\n",
            "Steps:  51%|█████     | 253/500 [47:42<47:35, 11.56s/it, loss=0.0493, lr=0.0001]\n",
            "Steps:  51%|█████     | 253/500 [47:45<47:35, 11.56s/it, loss=0.00546, lr=0.0001]\n",
            "Steps:  51%|█████     | 254/500 [47:48<47:49, 11.66s/it, loss=0.00546, lr=0.0001]\n",
            "Steps:  51%|█████     | 254/500 [47:48<47:49, 11.66s/it, loss=0.045, lr=0.0001]  \n",
            "Steps:  51%|█████     | 254/500 [47:51<47:49, 11.66s/it, loss=0.0118, lr=0.0001]\n",
            "Steps:  51%|█████     | 254/500 [47:54<47:49, 11.66s/it, loss=0.026, lr=0.0001] \n",
            "Steps:  51%|█████     | 255/500 [47:57<43:50, 10.74s/it, loss=0.026, lr=0.0001]\n",
            "Steps:  51%|█████     | 255/500 [47:57<43:50, 10.74s/it, loss=0.0513, lr=0.0001]\n",
            "Steps:  51%|█████     | 255/500 [48:00<43:50, 10.74s/it, loss=0.782, lr=0.0001] \n",
            "Steps:  51%|█████     | 255/500 [48:03<43:50, 10.74s/it, loss=0.0119, lr=0.0001]\n",
            "Steps:  51%|█████     | 255/500 [48:05<43:50, 10.74s/it, loss=0.234, lr=0.0001] \n",
            "Steps:  51%|█████     | 256/500 [48:08<44:30, 10.95s/it, loss=0.234, lr=0.0001]\n",
            "Steps:  51%|█████     | 256/500 [48:08<44:30, 10.95s/it, loss=0.00387, lr=0.0001]\n",
            "Steps:  51%|█████     | 256/500 [48:11<44:30, 10.95s/it, loss=0.00477, lr=0.0001]\n",
            "Steps:  51%|█████     | 256/500 [48:15<44:30, 10.95s/it, loss=0.0191, lr=0.0001] \n",
            "Steps:  51%|█████     | 256/500 [48:18<44:30, 10.95s/it, loss=0.034, lr=0.0001] \n",
            "Steps:  51%|█████▏    | 257/500 [48:21<46:44, 11.54s/it, loss=0.034, lr=0.0001]\n",
            "Steps:  51%|█████▏    | 257/500 [48:21<46:44, 11.54s/it, loss=0.119, lr=0.0001]\n",
            "Steps:  51%|█████▏    | 257/500 [48:24<46:44, 11.54s/it, loss=0.0899, lr=0.0001]\n",
            "Steps:  51%|█████▏    | 257/500 [48:27<46:44, 11.54s/it, loss=0.0137, lr=0.0001]\n",
            "Steps:  51%|█████▏    | 257/500 [48:30<46:44, 11.54s/it, loss=0.0102, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 258/500 [48:33<46:44, 11.59s/it, loss=0.0102, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 258/500 [48:33<46:44, 11.59s/it, loss=0.00959, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 258/500 [48:36<46:44, 11.59s/it, loss=0.149, lr=0.0001]  \n",
            "Steps:  52%|█████▏    | 258/500 [48:39<46:44, 11.59s/it, loss=0.0331, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 258/500 [48:41<46:44, 11.59s/it, loss=0.0493, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 259/500 [48:44<46:28, 11.57s/it, loss=0.0493, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 259/500 [48:44<46:28, 11.57s/it, loss=0.0972, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 259/500 [48:47<46:28, 11.57s/it, loss=0.193, lr=0.0001] \n",
            "Steps:  52%|█████▏    | 259/500 [48:50<46:28, 11.57s/it, loss=0.00418, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 260/500 [48:53<42:33, 10.64s/it, loss=0.00418, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 260/500 [48:53<42:33, 10.64s/it, loss=0.00554, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 260/500 [48:56<42:33, 10.64s/it, loss=0.00377, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 260/500 [48:59<42:33, 10.64s/it, loss=0.015, lr=0.0001]  \n",
            "Steps:  52%|█████▏    | 260/500 [49:02<42:33, 10.64s/it, loss=0.172, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 261/500 [49:04<43:36, 10.95s/it, loss=0.172, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 261/500 [49:04<43:36, 10.95s/it, loss=0.103, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 261/500 [49:07<43:36, 10.95s/it, loss=0.231, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 261/500 [49:11<43:36, 10.95s/it, loss=0.0893, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 261/500 [49:14<43:36, 10.95s/it, loss=0.268, lr=0.0001] \n",
            "Steps:  52%|█████▏    | 262/500 [49:16<44:39, 11.26s/it, loss=0.268, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 262/500 [49:16<44:39, 11.26s/it, loss=0.415, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 262/500 [49:19<44:39, 11.26s/it, loss=0.0333, lr=0.0001]\n",
            "Steps:  52%|█████▏    | 262/500 [49:24<44:39, 11.26s/it, loss=0.145, lr=0.0001] \n",
            "Steps:  52%|█████▏    | 262/500 [49:27<44:39, 11.26s/it, loss=0.0799, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 263/500 [49:29<46:31, 11.78s/it, loss=0.0799, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 263/500 [49:29<46:31, 11.78s/it, loss=0.0344, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 263/500 [49:32<46:31, 11.78s/it, loss=0.149, lr=0.0001] \n",
            "Steps:  53%|█████▎    | 263/500 [49:35<46:31, 11.78s/it, loss=0.0268, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 263/500 [49:38<46:31, 11.78s/it, loss=0.374, lr=0.0001] \n",
            "Steps:  53%|█████▎    | 264/500 [49:41<45:54, 11.67s/it, loss=0.374, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 264/500 [49:41<45:54, 11.67s/it, loss=0.0262, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 264/500 [49:44<45:54, 11.67s/it, loss=0.163, lr=0.0001] \n",
            "Steps:  53%|█████▎    | 264/500 [49:47<45:54, 11.67s/it, loss=0.123, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 265/500 [49:49<41:55, 10.71s/it, loss=0.123, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 265/500 [49:49<41:55, 10.71s/it, loss=0.0369, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 265/500 [49:52<41:55, 10.71s/it, loss=0.0158, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 265/500 [49:55<41:55, 10.71s/it, loss=0.298, lr=0.0001] \n",
            "Steps:  53%|█████▎    | 265/500 [49:58<41:55, 10.71s/it, loss=0.32, lr=0.0001] \n",
            "Steps:  53%|█████▎    | 266/500 [50:01<42:45, 10.96s/it, loss=0.32, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 266/500 [50:01<42:45, 10.96s/it, loss=0.167, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 266/500 [50:04<42:45, 10.96s/it, loss=0.154, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 266/500 [50:07<42:45, 10.96s/it, loss=0.102, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 266/500 [50:10<42:45, 10.96s/it, loss=0.00776, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 267/500 [50:13<43:29, 11.20s/it, loss=0.00776, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 267/500 [50:13<43:29, 11.20s/it, loss=0.0107, lr=0.0001] \n",
            "Steps:  53%|█████▎    | 267/500 [50:15<43:29, 11.20s/it, loss=0.0259, lr=0.0001]\n",
            "Steps:  53%|█████▎    | 267/500 [50:20<43:29, 11.20s/it, loss=0.15, lr=0.0001]  \n",
            "Steps:  53%|█████▎    | 267/500 [50:23<43:29, 11.20s/it, loss=0.129, lr=0.0001]\n",
            "Steps:  54%|█████▎    | 268/500 [50:26<45:18, 11.72s/it, loss=0.129, lr=0.0001]\n",
            "Steps:  54%|█████▎    | 268/500 [50:26<45:18, 11.72s/it, loss=0.11, lr=0.0001] \n",
            "Steps:  54%|█████▎    | 268/500 [50:28<45:18, 11.72s/it, loss=0.218, lr=0.0001]\n",
            "Steps:  54%|█████▎    | 268/500 [50:31<45:18, 11.72s/it, loss=0.0398, lr=0.0001]\n",
            "Steps:  54%|█████▎    | 268/500 [50:34<45:18, 11.72s/it, loss=0.0692, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 269/500 [50:37<44:44, 11.62s/it, loss=0.0692, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 269/500 [50:37<44:44, 11.62s/it, loss=0.119, lr=0.0001] \n",
            "Steps:  54%|█████▍    | 269/500 [50:40<44:44, 11.62s/it, loss=0.194, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 269/500 [50:43<44:44, 11.62s/it, loss=0.191, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 270/500 [50:46<41:06, 10.72s/it, loss=0.191, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 270/500 [50:46<41:06, 10.72s/it, loss=0.0433, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 270/500 [50:48<41:06, 10.72s/it, loss=0.00755, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 270/500 [50:51<41:06, 10.72s/it, loss=0.0819, lr=0.0001] \n",
            "Steps:  54%|█████▍    | 270/500 [50:54<41:06, 10.72s/it, loss=0.0378, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 271/500 [50:57<41:55, 10.98s/it, loss=0.0378, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 271/500 [50:57<41:55, 10.98s/it, loss=0.0391, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 271/500 [51:00<41:55, 10.98s/it, loss=0.102, lr=0.0001] \n",
            "Steps:  54%|█████▍    | 271/500 [51:03<41:55, 10.98s/it, loss=0.017, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 271/500 [51:06<41:55, 10.98s/it, loss=0.0668, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 272/500 [51:09<42:09, 11.10s/it, loss=0.0668, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 272/500 [51:09<42:09, 11.10s/it, loss=0.0551, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 272/500 [51:11<42:09, 11.10s/it, loss=0.25, lr=0.0001]  \n",
            "Steps:  54%|█████▍    | 272/500 [51:14<42:09, 11.10s/it, loss=0.0245, lr=0.0001]\n",
            "Steps:  54%|█████▍    | 272/500 [51:17<42:09, 11.10s/it, loss=0.00162, lr=0.0001]\n",
            "Steps:  55%|█████▍    | 273/500 [51:21<44:03, 11.64s/it, loss=0.00162, lr=0.0001]\n",
            "Steps:  55%|█████▍    | 273/500 [51:21<44:03, 11.64s/it, loss=0.0451, lr=0.0001] \n",
            "Steps:  55%|█████▍    | 273/500 [51:24<44:03, 11.64s/it, loss=0.0124, lr=0.0001]\n",
            "Steps:  55%|█████▍    | 273/500 [51:27<44:03, 11.64s/it, loss=0.334, lr=0.0001] \n",
            "Steps:  55%|█████▍    | 273/500 [51:30<44:03, 11.64s/it, loss=0.00317, lr=0.0001]\n",
            "Steps:  55%|█████▍    | 274/500 [51:33<43:40, 11.59s/it, loss=0.00317, lr=0.0001]\n",
            "Steps:  55%|█████▍    | 274/500 [51:33<43:40, 11.59s/it, loss=0.428, lr=0.0001]  \n",
            "Steps:  55%|█████▍    | 274/500 [51:36<43:40, 11.59s/it, loss=0.00714, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  55%|█████▍    | 274/500 [51:39<43:40, 11.59s/it, loss=0.0507, lr=0.0001] \n",
            "Steps:  55%|█████▌    | 275/500 [51:42<40:16, 10.74s/it, loss=0.0507, lr=0.0001]\n",
            "Steps:  55%|█████▌    | 275/500 [51:42<40:16, 10.74s/it, loss=0.00828, lr=0.0001]\n",
            "Steps:  55%|█████▌    | 275/500 [51:47<40:16, 10.74s/it, loss=0.0499, lr=0.0001] \n",
            "Steps:  55%|█████▌    | 275/500 [51:50<40:16, 10.74s/it, loss=0.0601, lr=0.0001]\n",
            "Steps:  55%|█████▌    | 275/500 [51:52<40:16, 10.74s/it, loss=0.0334, lr=0.0001]\n",
            "Steps:  55%|█████▌    | 276/500 [51:55<43:12, 11.58s/it, loss=0.0334, lr=0.0001]\n",
            "Steps:  55%|█████▌    | 276/500 [51:55<43:12, 11.58s/it, loss=0.0222, lr=0.0001]\n",
            "Steps:  55%|█████▌    | 276/500 [51:58<43:12, 11.58s/it, loss=0.324, lr=0.0001] \n",
            "Steps:  55%|█████▌    | 276/500 [52:01<43:12, 11.58s/it, loss=0.0942, lr=0.0001]\n",
            "Steps:  55%|█████▌    | 276/500 [52:04<43:12, 11.58s/it, loss=0.147, lr=0.0001] \n",
            "Steps:  55%|█████▌    | 277/500 [52:07<42:56, 11.55s/it, loss=0.147, lr=0.0001]\n",
            "Steps:  55%|█████▌    | 277/500 [52:07<42:56, 11.55s/it, loss=0.00336, lr=0.0001]\n",
            "Steps:  55%|█████▌    | 277/500 [52:10<42:56, 11.55s/it, loss=0.0328, lr=0.0001] \n",
            "Steps:  55%|█████▌    | 277/500 [52:12<42:56, 11.55s/it, loss=0.159, lr=0.0001] \n",
            "Steps:  55%|█████▌    | 277/500 [52:15<42:56, 11.55s/it, loss=0.111, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 278/500 [52:18<42:31, 11.49s/it, loss=0.111, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 278/500 [52:18<42:31, 11.49s/it, loss=0.00456, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 278/500 [52:21<42:31, 11.49s/it, loss=0.0453, lr=0.0001] \n",
            "Steps:  56%|█████▌    | 278/500 [52:24<42:31, 11.49s/it, loss=0.00304, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 278/500 [52:27<42:31, 11.49s/it, loss=0.178, lr=0.0001]  \n",
            "Steps:  56%|█████▌    | 279/500 [52:30<42:20, 11.50s/it, loss=0.178, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 279/500 [52:30<42:20, 11.50s/it, loss=0.332, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 279/500 [52:32<42:20, 11.50s/it, loss=0.00224, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 279/500 [52:36<42:20, 11.50s/it, loss=0.0859, lr=0.0001] \n",
            "Steps:  56%|█████▌    | 280/500 [52:38<39:08, 10.67s/it, loss=0.0859, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 280/500 [52:38<39:08, 10.67s/it, loss=0.00829, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 280/500 [52:41<39:08, 10.67s/it, loss=0.00355, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 280/500 [52:44<39:08, 10.67s/it, loss=0.0024, lr=0.0001] \n",
            "Steps:  56%|█████▌    | 280/500 [52:47<39:08, 10.67s/it, loss=0.218, lr=0.0001] \n",
            "Steps:  56%|█████▌    | 281/500 [52:50<40:05, 10.99s/it, loss=0.218, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 281/500 [52:50<40:05, 10.99s/it, loss=0.119, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 281/500 [52:53<40:05, 10.99s/it, loss=0.175, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 281/500 [52:56<40:05, 10.99s/it, loss=0.0745, lr=0.0001]\n",
            "Steps:  56%|█████▌    | 281/500 [52:58<40:05, 10.99s/it, loss=0.221, lr=0.0001] \n",
            "Steps:  56%|█████▋    | 282/500 [53:01<40:15, 11.08s/it, loss=0.221, lr=0.0001]\n",
            "Steps:  56%|█████▋    | 282/500 [53:01<40:15, 11.08s/it, loss=0.00912, lr=0.0001]\n",
            "Steps:  56%|█████▋    | 282/500 [53:04<40:15, 11.08s/it, loss=0.0117, lr=0.0001] \n",
            "Steps:  56%|█████▋    | 282/500 [53:07<40:15, 11.08s/it, loss=0.0138, lr=0.0001]\n",
            "Steps:  56%|█████▋    | 282/500 [53:10<40:15, 11.08s/it, loss=0.192, lr=0.0001] \n",
            "Steps:  57%|█████▋    | 283/500 [53:13<40:41, 11.25s/it, loss=0.192, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 283/500 [53:13<40:41, 11.25s/it, loss=0.111, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 283/500 [53:16<40:41, 11.25s/it, loss=0.171, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 283/500 [53:19<40:41, 11.25s/it, loss=0.00226, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 283/500 [53:22<40:41, 11.25s/it, loss=0.0473, lr=0.0001] \n",
            "Steps:  57%|█████▋    | 284/500 [53:26<42:17, 11.75s/it, loss=0.0473, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 284/500 [53:26<42:17, 11.75s/it, loss=0.0284, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 284/500 [53:29<42:17, 11.75s/it, loss=0.00675, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 284/500 [53:32<42:17, 11.75s/it, loss=0.0111, lr=0.0001] \n",
            "Steps:  57%|█████▋    | 285/500 [53:34<38:44, 10.81s/it, loss=0.0111, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 285/500 [53:34<38:44, 10.81s/it, loss=0.0106, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 285/500 [53:39<38:44, 10.81s/it, loss=0.00748, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 285/500 [53:42<38:44, 10.81s/it, loss=0.0322, lr=0.0001] \n",
            "Steps:  57%|█████▋    | 285/500 [53:44<38:44, 10.81s/it, loss=0.0404, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 286/500 [53:47<40:45, 11.43s/it, loss=0.0404, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 286/500 [53:47<40:45, 11.43s/it, loss=0.0394, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 286/500 [53:50<40:45, 11.43s/it, loss=0.0466, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 286/500 [53:53<40:45, 11.43s/it, loss=0.587, lr=0.0001] \n",
            "Steps:  57%|█████▋    | 286/500 [53:56<40:45, 11.43s/it, loss=0.0515, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 287/500 [53:59<40:30, 11.41s/it, loss=0.0515, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 287/500 [53:59<40:30, 11.41s/it, loss=0.0275, lr=0.0001]\n",
            "Steps:  57%|█████▋    | 287/500 [54:02<40:30, 11.41s/it, loss=0.171, lr=0.0001] \n",
            "Steps:  57%|█████▋    | 287/500 [54:05<40:30, 11.41s/it, loss=0.42, lr=0.0001] \n",
            "Steps:  57%|█████▋    | 287/500 [54:08<40:30, 11.41s/it, loss=0.0225, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 288/500 [54:11<40:54, 11.58s/it, loss=0.0225, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 288/500 [54:11<40:54, 11.58s/it, loss=0.121, lr=0.0001] \n",
            "Steps:  58%|█████▊    | 288/500 [54:14<40:54, 11.58s/it, loss=0.00249, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 288/500 [54:17<40:54, 11.58s/it, loss=0.113, lr=0.0001]  \n",
            "Steps:  58%|█████▊    | 288/500 [54:19<40:54, 11.58s/it, loss=0.142, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 289/500 [54:22<40:39, 11.56s/it, loss=0.142, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 289/500 [54:22<40:39, 11.56s/it, loss=0.0118, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 289/500 [54:25<40:39, 11.56s/it, loss=0.0972, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 289/500 [54:28<40:39, 11.56s/it, loss=0.45, lr=0.0001]  \n",
            "Steps:  58%|█████▊    | 290/500 [54:31<37:21, 10.68s/it, loss=0.45, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 290/500 [54:31<37:21, 10.68s/it, loss=0.014, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 290/500 [54:34<37:21, 10.68s/it, loss=0.00354, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 290/500 [54:37<37:21, 10.68s/it, loss=0.124, lr=0.0001]  \n",
            "Steps:  58%|█████▊    | 290/500 [54:40<37:21, 10.68s/it, loss=0.0056, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 291/500 [54:44<40:02, 11.50s/it, loss=0.0056, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 291/500 [54:44<40:02, 11.50s/it, loss=0.444, lr=0.0001] \n",
            "Steps:  58%|█████▊    | 291/500 [54:47<40:02, 11.50s/it, loss=0.0478, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 291/500 [54:50<40:02, 11.50s/it, loss=0.0033, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 291/500 [54:53<40:02, 11.50s/it, loss=0.352, lr=0.0001] \n",
            "Steps:  58%|█████▊    | 292/500 [54:56<39:49, 11.49s/it, loss=0.352, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 292/500 [54:56<39:49, 11.49s/it, loss=0.422, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 292/500 [54:59<39:49, 11.49s/it, loss=0.0539, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 292/500 [55:01<39:49, 11.49s/it, loss=0.00239, lr=0.0001]\n",
            "Steps:  58%|█████▊    | 292/500 [55:04<39:49, 11.49s/it, loss=0.00466, lr=0.0001]\n",
            "Steps:  59%|█████▊    | 293/500 [55:07<39:37, 11.48s/it, loss=0.00466, lr=0.0001]\n",
            "Steps:  59%|█████▊    | 293/500 [55:07<39:37, 11.48s/it, loss=0.0727, lr=0.0001] \n",
            "Steps:  59%|█████▊    | 293/500 [55:10<39:37, 11.48s/it, loss=0.203, lr=0.0001] \n",
            "Steps:  59%|█████▊    | 293/500 [55:13<39:37, 11.48s/it, loss=0.0638, lr=0.0001]\n",
            "Steps:  59%|█████▊    | 293/500 [55:16<39:37, 11.48s/it, loss=0.00921, lr=0.0001]\n",
            "Steps:  59%|█████▉    | 294/500 [55:19<39:23, 11.47s/it, loss=0.00921, lr=0.0001]\n",
            "Steps:  59%|█████▉    | 294/500 [55:19<39:23, 11.47s/it, loss=0.0639, lr=0.0001] \n",
            "Steps:  59%|█████▉    | 294/500 [55:21<39:23, 11.47s/it, loss=0.00263, lr=0.0001]\n",
            "Steps:  59%|█████▉    | 294/500 [55:24<39:23, 11.47s/it, loss=0.0247, lr=0.0001] \n",
            "Steps:  59%|█████▉    | 295/500 [55:27<36:07, 10.57s/it, loss=0.0247, lr=0.0001]\n",
            "Steps:  59%|█████▉    | 295/500 [55:27<36:07, 10.57s/it, loss=0.00489, lr=0.0001]\n",
            "Steps:  59%|█████▉    | 295/500 [55:30<36:07, 10.57s/it, loss=0.0144, lr=0.0001] \n",
            "Steps:  59%|█████▉    | 295/500 [55:33<36:07, 10.57s/it, loss=0.239, lr=0.0001] \n",
            "Steps:  59%|█████▉    | 295/500 [55:36<36:07, 10.57s/it, loss=0.151, lr=0.0001]\n",
            "Steps:  59%|█████▉    | 296/500 [55:39<37:15, 10.96s/it, loss=0.151, lr=0.0001]\n",
            "Steps:  59%|█████▉    | 296/500 [55:39<37:15, 10.96s/it, loss=0.0789, lr=0.0001]\n",
            "Steps:  59%|█████▉    | 296/500 [55:43<37:15, 10.96s/it, loss=0.00473, lr=0.0001]\n",
            "Steps:  59%|█████▉    | 296/500 [55:46<37:15, 10.96s/it, loss=0.101, lr=0.0001]  \n",
            "Steps:  59%|█████▉    | 296/500 [55:49<37:15, 10.96s/it, loss=0.0296, lr=0.0001]\n",
            "Steps:  59%|█████▉    | 297/500 [55:52<39:00, 11.53s/it, loss=0.0296, lr=0.0001]\n",
            "Steps:  59%|█████▉    | 297/500 [55:52<39:00, 11.53s/it, loss=0.206, lr=0.0001] \n",
            "Steps:  59%|█████▉    | 297/500 [55:55<39:00, 11.53s/it, loss=0.352, lr=0.0001]\n",
            "Steps:  59%|█████▉    | 297/500 [55:58<39:00, 11.53s/it, loss=0.0166, lr=0.0001]\n",
            "Steps:  59%|█████▉    | 297/500 [56:00<39:00, 11.53s/it, loss=0.195, lr=0.0001] \n",
            "Steps:  60%|█████▉    | 298/500 [56:03<38:50, 11.54s/it, loss=0.195, lr=0.0001]\n",
            "Steps:  60%|█████▉    | 298/500 [56:03<38:50, 11.54s/it, loss=0.162, lr=0.0001]\n",
            "Steps:  60%|█████▉    | 298/500 [56:06<38:50, 11.54s/it, loss=0.0554, lr=0.0001]\n",
            "Steps:  60%|█████▉    | 298/500 [56:09<38:50, 11.54s/it, loss=0.1, lr=0.0001]   \n",
            "Steps:  60%|█████▉    | 298/500 [56:12<38:50, 11.54s/it, loss=0.481, lr=0.0001]\n",
            "Steps:  60%|█████▉    | 299/500 [56:15<38:33, 11.51s/it, loss=0.481, lr=0.0001]\n",
            "Steps:  60%|█████▉    | 299/500 [56:15<38:33, 11.51s/it, loss=0.00304, lr=0.0001]\n",
            "Steps:  60%|█████▉    | 299/500 [56:18<38:33, 11.51s/it, loss=0.103, lr=0.0001]  INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  60%|█████▉    | 299/500 [56:21<38:33, 11.51s/it, loss=0.0157, lr=0.0001]\n",
            "Steps:  60%|██████    | 300/500 [56:23<35:23, 10.62s/it, loss=0.0157, lr=0.0001]\n",
            "Steps:  60%|██████    | 300/500 [56:23<35:23, 10.62s/it, loss=0.256, lr=0.0001] \n",
            "Steps:  60%|██████    | 300/500 [56:27<35:23, 10.62s/it, loss=0.0294, lr=0.0001]\n",
            "Steps:  60%|██████    | 300/500 [56:29<35:23, 10.62s/it, loss=0.00208, lr=0.0001]\n",
            "Steps:  60%|██████    | 300/500 [56:32<35:23, 10.62s/it, loss=0.00391, lr=0.0001]\n",
            "Steps:  60%|██████    | 301/500 [56:35<36:23, 10.97s/it, loss=0.00391, lr=0.0001]\n",
            "Steps:  60%|██████    | 301/500 [56:35<36:23, 10.97s/it, loss=0.0729, lr=0.0001] \n",
            "Steps:  60%|██████    | 301/500 [56:38<36:23, 10.97s/it, loss=0.0861, lr=0.0001]\n",
            "Steps:  60%|██████    | 301/500 [56:41<36:23, 10.97s/it, loss=0.0853, lr=0.0001]\n",
            "Steps:  60%|██████    | 301/500 [56:44<36:23, 10.97s/it, loss=0.00488, lr=0.0001]\n",
            "Steps:  60%|██████    | 302/500 [56:49<38:52, 11.78s/it, loss=0.00488, lr=0.0001]\n",
            "Steps:  60%|██████    | 302/500 [56:49<38:52, 11.78s/it, loss=0.0483, lr=0.0001] \n",
            "Steps:  60%|██████    | 302/500 [56:52<38:52, 11.78s/it, loss=0.00296, lr=0.0001]\n",
            "Steps:  60%|██████    | 302/500 [56:55<38:52, 11.78s/it, loss=0.219, lr=0.0001]  \n",
            "Steps:  60%|██████    | 302/500 [56:57<38:52, 11.78s/it, loss=0.00458, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  61%|██████    | 303/500 [57:00<38:25, 11.70s/it, loss=0.00458, lr=0.0001]\n",
            "Steps:  61%|██████    | 303/500 [57:00<38:25, 11.70s/it, loss=0.255, lr=0.0001]  \n",
            "Steps:  61%|██████    | 303/500 [57:03<38:25, 11.70s/it, loss=0.0492, lr=0.0001]\n",
            "Steps:  61%|██████    | 303/500 [57:06<38:25, 11.70s/it, loss=0.0267, lr=0.0001]\n",
            "Steps:  61%|██████    | 303/500 [57:09<38:25, 11.70s/it, loss=0.294, lr=0.0001] \n",
            "Steps:  61%|██████    | 304/500 [57:12<37:58, 11.62s/it, loss=0.294, lr=0.0001]\n",
            "Steps:  61%|██████    | 304/500 [57:12<37:58, 11.62s/it, loss=0.048, lr=0.0001]\n",
            "Steps:  61%|██████    | 304/500 [57:15<37:58, 11.62s/it, loss=0.123, lr=0.0001]\n",
            "Steps:  61%|██████    | 304/500 [57:18<37:58, 11.62s/it, loss=0.0226, lr=0.0001]\n",
            "Steps:  61%|██████    | 305/500 [57:20<34:44, 10.69s/it, loss=0.0226, lr=0.0001]\n",
            "Steps:  61%|██████    | 305/500 [57:20<34:44, 10.69s/it, loss=0.0721, lr=0.0001]\n",
            "Steps:  61%|██████    | 305/500 [57:23<34:44, 10.69s/it, loss=0.0393, lr=0.0001]\n",
            "Steps:  61%|██████    | 305/500 [57:26<34:44, 10.69s/it, loss=0.0518, lr=0.0001]\n",
            "Steps:  61%|██████    | 305/500 [57:29<34:44, 10.69s/it, loss=0.029, lr=0.0001] \n",
            "Steps:  61%|██████    | 306/500 [57:32<35:49, 11.08s/it, loss=0.029, lr=0.0001]\n",
            "Steps:  61%|██████    | 306/500 [57:32<35:49, 11.08s/it, loss=0.00493, lr=0.0001]\n",
            "Steps:  61%|██████    | 306/500 [57:35<35:49, 11.08s/it, loss=0.323, lr=0.0001]  \n",
            "Steps:  61%|██████    | 306/500 [57:38<35:49, 11.08s/it, loss=0.0437, lr=0.0001]\n",
            "Steps:  61%|██████    | 306/500 [57:41<35:49, 11.08s/it, loss=0.0619, lr=0.0001]\n",
            "Steps:  61%|██████▏   | 307/500 [57:44<35:56, 11.17s/it, loss=0.0619, lr=0.0001]\n",
            "Steps:  61%|██████▏   | 307/500 [57:44<35:56, 11.17s/it, loss=0.0367, lr=0.0001]\n",
            "Steps:  61%|██████▏   | 307/500 [57:47<35:56, 11.17s/it, loss=0.0422, lr=0.0001]\n",
            "Steps:  61%|██████▏   | 307/500 [57:49<35:56, 11.17s/it, loss=0.107, lr=0.0001] \n",
            "Steps:  61%|██████▏   | 307/500 [57:52<35:56, 11.17s/it, loss=0.00201, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 308/500 [57:55<35:53, 11.22s/it, loss=0.00201, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 308/500 [57:55<35:53, 11.22s/it, loss=0.0611, lr=0.0001] \n",
            "Steps:  62%|██████▏   | 308/500 [57:58<35:53, 11.22s/it, loss=0.00381, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 308/500 [58:01<35:53, 11.22s/it, loss=0.673, lr=0.0001]  \n",
            "Steps:  62%|██████▏   | 308/500 [58:04<35:53, 11.22s/it, loss=0.261, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 309/500 [58:07<36:00, 11.31s/it, loss=0.261, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 309/500 [58:07<36:00, 11.31s/it, loss=0.184, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 309/500 [58:09<36:00, 11.31s/it, loss=0.0782, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 309/500 [58:14<36:00, 11.31s/it, loss=0.133, lr=0.0001] \n",
            "Steps:  62%|██████▏   | 310/500 [58:17<34:37, 10.93s/it, loss=0.133, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 310/500 [58:17<34:37, 10.93s/it, loss=0.0531, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 310/500 [58:20<34:37, 10.93s/it, loss=0.00462, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 310/500 [58:22<34:37, 10.93s/it, loss=0.204, lr=0.0001]  \n",
            "Steps:  62%|██████▏   | 310/500 [58:25<34:37, 10.93s/it, loss=0.136, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 311/500 [58:28<34:57, 11.10s/it, loss=0.136, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 311/500 [58:28<34:57, 11.10s/it, loss=0.0113, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 311/500 [58:31<34:57, 11.10s/it, loss=0.0244, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 311/500 [58:34<34:57, 11.10s/it, loss=0.135, lr=0.0001] \n",
            "Steps:  62%|██████▏   | 311/500 [58:37<34:57, 11.10s/it, loss=0.013, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 312/500 [58:40<35:08, 11.22s/it, loss=0.013, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 312/500 [58:40<35:08, 11.22s/it, loss=0.0518, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 312/500 [58:42<35:08, 11.22s/it, loss=0.00251, lr=0.0001]\n",
            "Steps:  62%|██████▏   | 312/500 [58:45<35:08, 11.22s/it, loss=0.153, lr=0.0001]  \n",
            "Steps:  62%|██████▏   | 312/500 [58:49<35:08, 11.22s/it, loss=0.101, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 313/500 [58:53<37:02, 11.89s/it, loss=0.101, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 313/500 [58:53<37:02, 11.89s/it, loss=0.337, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 313/500 [58:56<37:02, 11.89s/it, loss=0.337, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 313/500 [58:59<37:02, 11.89s/it, loss=0.092, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 313/500 [59:02<37:02, 11.89s/it, loss=0.0519, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 314/500 [59:05<36:28, 11.77s/it, loss=0.0519, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 314/500 [59:05<36:28, 11.77s/it, loss=0.011, lr=0.0001] \n",
            "Steps:  63%|██████▎   | 314/500 [59:07<36:28, 11.77s/it, loss=0.00701, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 314/500 [59:10<36:28, 11.77s/it, loss=0.0369, lr=0.0001] \n",
            "Steps:  63%|██████▎   | 315/500 [59:13<33:15, 10.79s/it, loss=0.0369, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 315/500 [59:13<33:15, 10.79s/it, loss=0.567, lr=0.0001] \n",
            "Steps:  63%|██████▎   | 315/500 [59:16<33:15, 10.79s/it, loss=0.152, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 315/500 [59:19<33:15, 10.79s/it, loss=0.153, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 315/500 [59:22<33:15, 10.79s/it, loss=0.00116, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 316/500 [59:24<33:39, 10.97s/it, loss=0.00116, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 316/500 [59:24<33:39, 10.97s/it, loss=0.0486, lr=0.0001] \n",
            "Steps:  63%|██████▎   | 316/500 [59:27<33:39, 10.97s/it, loss=0.0316, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 316/500 [59:30<33:39, 10.97s/it, loss=0.00386, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 316/500 [59:33<33:39, 10.97s/it, loss=0.139, lr=0.0001]  \n",
            "Steps:  63%|██████▎   | 317/500 [59:36<34:23, 11.27s/it, loss=0.139, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 317/500 [59:36<34:23, 11.27s/it, loss=0.0217, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 317/500 [59:39<34:23, 11.27s/it, loss=0.298, lr=0.0001] \n",
            "Steps:  63%|██████▎   | 317/500 [59:42<34:23, 11.27s/it, loss=0.0924, lr=0.0001]\n",
            "Steps:  63%|██████▎   | 317/500 [59:45<34:23, 11.27s/it, loss=0.0165, lr=0.0001]\n",
            "Steps:  64%|██████▎   | 318/500 [59:48<34:35, 11.40s/it, loss=0.0165, lr=0.0001]\n",
            "Steps:  64%|██████▎   | 318/500 [59:48<34:35, 11.40s/it, loss=0.0335, lr=0.0001]\n",
            "Steps:  64%|██████▎   | 318/500 [59:53<34:35, 11.40s/it, loss=0.101, lr=0.0001] \n",
            "Steps:  64%|██████▎   | 318/500 [59:56<34:35, 11.40s/it, loss=0.00254, lr=0.0001]\n",
            "Steps:  64%|██████▎   | 318/500 [59:59<34:35, 11.40s/it, loss=0.0579, lr=0.0001] \n",
            "Steps:  64%|██████▍   | 319/500 [1:00:02<36:14, 12.01s/it, loss=0.0579, lr=0.0001]\n",
            "Steps:  64%|██████▍   | 319/500 [1:00:02<36:14, 12.01s/it, loss=0.0028, lr=0.0001]\n",
            "Steps:  64%|██████▍   | 319/500 [1:00:04<36:14, 12.01s/it, loss=0.117, lr=0.0001] \n",
            "Steps:  64%|██████▍   | 319/500 [1:00:07<36:14, 12.01s/it, loss=0.249, lr=0.0001]\n",
            "Steps:  64%|██████▍   | 320/500 [1:00:10<32:58, 10.99s/it, loss=0.249, lr=0.0001]\n",
            "Steps:  64%|██████▍   | 320/500 [1:00:10<32:58, 10.99s/it, loss=0.0436, lr=0.0001]\n",
            "Steps:  64%|██████▍   | 320/500 [1:00:13<32:58, 10.99s/it, loss=0.0604, lr=0.0001]\n",
            "Steps:  64%|██████▍   | 320/500 [1:00:16<32:58, 10.99s/it, loss=0.0249, lr=0.0001]\n",
            "Steps:  64%|██████▍   | 320/500 [1:00:19<32:58, 10.99s/it, loss=0.158, lr=0.0001] \n",
            "Steps:  64%|██████▍   | 321/500 [1:00:22<33:18, 11.16s/it, loss=0.158, lr=0.0001]\n",
            "Steps:  64%|██████▍   | 321/500 [1:00:22<33:18, 11.16s/it, loss=0.0384, lr=0.0001]\n",
            "Steps:  64%|██████▍   | 321/500 [1:00:25<33:18, 11.16s/it, loss=0.369, lr=0.0001] \n",
            "Steps:  64%|██████▍   | 321/500 [1:00:28<33:18, 11.16s/it, loss=0.0923, lr=0.0001]\n",
            "Steps:  64%|██████▍   | 321/500 [1:00:30<33:18, 11.16s/it, loss=0.00505, lr=0.0001]\n",
            "Steps:  64%|██████▍   | 322/500 [1:00:36<35:30, 11.97s/it, loss=0.00505, lr=0.0001]\n",
            "Steps:  64%|██████▍   | 322/500 [1:00:36<35:30, 11.97s/it, loss=0.0179, lr=0.0001] \n",
            "Steps:  64%|██████▍   | 322/500 [1:00:38<35:30, 11.97s/it, loss=0.294, lr=0.0001] \n",
            "Steps:  64%|██████▍   | 322/500 [1:00:41<35:30, 11.97s/it, loss=0.0318, lr=0.0001]\n",
            "Steps:  64%|██████▍   | 322/500 [1:00:44<35:30, 11.97s/it, loss=0.0933, lr=0.0001]\n",
            "Steps:  65%|██████▍   | 323/500 [1:00:47<34:45, 11.78s/it, loss=0.0933, lr=0.0001]\n",
            "Steps:  65%|██████▍   | 323/500 [1:00:47<34:45, 11.78s/it, loss=0.0158, lr=0.0001]\n",
            "Steps:  65%|██████▍   | 323/500 [1:00:50<34:45, 11.78s/it, loss=0.0342, lr=0.0001]\n",
            "Steps:  65%|██████▍   | 323/500 [1:00:53<34:45, 11.78s/it, loss=0.0201, lr=0.0001]\n",
            "Steps:  65%|██████▍   | 323/500 [1:00:56<34:45, 11.78s/it, loss=0.319, lr=0.0001] \n",
            "Steps:  65%|██████▍   | 324/500 [1:00:58<34:24, 11.73s/it, loss=0.319, lr=0.0001]\n",
            "Steps:  65%|██████▍   | 324/500 [1:00:58<34:24, 11.73s/it, loss=0.0244, lr=0.0001]\n",
            "Steps:  65%|██████▍   | 324/500 [1:01:01<34:24, 11.73s/it, loss=0.00321, lr=0.0001]\n",
            "Steps:  65%|██████▍   | 324/500 [1:01:04<34:24, 11.73s/it, loss=0.315, lr=0.0001]  \n",
            "Steps:  65%|██████▌   | 325/500 [1:01:07<31:20, 10.74s/it, loss=0.315, lr=0.0001]\n",
            "Steps:  65%|██████▌   | 325/500 [1:01:07<31:20, 10.74s/it, loss=0.0141, lr=0.0001]\n",
            "Steps:  65%|██████▌   | 325/500 [1:01:10<31:20, 10.74s/it, loss=0.0582, lr=0.0001]\n",
            "Steps:  65%|██████▌   | 325/500 [1:01:13<31:20, 10.74s/it, loss=0.241, lr=0.0001] \n",
            "Steps:  65%|██████▌   | 325/500 [1:01:16<31:20, 10.74s/it, loss=0.00403, lr=0.0001]\n",
            "Steps:  65%|██████▌   | 326/500 [1:01:19<31:52, 10.99s/it, loss=0.00403, lr=0.0001]\n",
            "Steps:  65%|██████▌   | 326/500 [1:01:19<31:52, 10.99s/it, loss=0.0471, lr=0.0001] \n",
            "Steps:  65%|██████▌   | 326/500 [1:01:21<31:52, 10.99s/it, loss=0.0993, lr=0.0001]\n",
            "Steps:  65%|██████▌   | 326/500 [1:01:24<31:52, 10.99s/it, loss=0.00693, lr=0.0001]\n",
            "Steps:  65%|██████▌   | 326/500 [1:01:27<31:52, 10.99s/it, loss=0.0186, lr=0.0001] \n",
            "Steps:  65%|██████▌   | 327/500 [1:01:30<32:00, 11.10s/it, loss=0.0186, lr=0.0001]\n",
            "Steps:  65%|██████▌   | 327/500 [1:01:30<32:00, 11.10s/it, loss=0.00316, lr=0.0001]\n",
            "Steps:  65%|██████▌   | 327/500 [1:01:33<32:00, 11.10s/it, loss=0.454, lr=0.0001]  \n",
            "Steps:  65%|██████▌   | 327/500 [1:01:36<32:00, 11.10s/it, loss=0.214, lr=0.0001]\n",
            "Steps:  65%|██████▌   | 327/500 [1:01:40<32:00, 11.10s/it, loss=0.0289, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 328/500 [1:01:43<33:37, 11.73s/it, loss=0.0289, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 328/500 [1:01:43<33:37, 11.73s/it, loss=0.0521, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 328/500 [1:01:46<33:37, 11.73s/it, loss=0.00428, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 328/500 [1:01:49<33:37, 11.73s/it, loss=0.0919, lr=0.0001] \n",
            "Steps:  66%|██████▌   | 328/500 [1:01:52<33:37, 11.73s/it, loss=0.0589, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 329/500 [1:01:54<33:10, 11.64s/it, loss=0.0589, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 329/500 [1:01:54<33:10, 11.64s/it, loss=0.0783, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 329/500 [1:01:57<33:10, 11.64s/it, loss=0.0361, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 329/500 [1:02:00<33:10, 11.64s/it, loss=0.0186, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 330/500 [1:02:03<30:22, 10.72s/it, loss=0.0186, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 330/500 [1:02:03<30:22, 10.72s/it, loss=0.02, lr=0.0001]  \n",
            "Steps:  66%|██████▌   | 330/500 [1:02:06<30:22, 10.72s/it, loss=0.0129, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 330/500 [1:02:09<30:22, 10.72s/it, loss=0.0985, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 330/500 [1:02:12<30:22, 10.72s/it, loss=0.00915, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 331/500 [1:02:15<30:56, 10.98s/it, loss=0.00915, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 331/500 [1:02:15<30:56, 10.98s/it, loss=0.112, lr=0.0001]  \n",
            "Steps:  66%|██████▌   | 331/500 [1:02:18<30:56, 10.98s/it, loss=0.634, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 331/500 [1:02:20<30:56, 10.98s/it, loss=0.246, lr=0.0001]\n",
            "Steps:  66%|██████▌   | 331/500 [1:02:23<30:56, 10.98s/it, loss=0.322, lr=0.0001]\n",
            "Steps:  66%|██████▋   | 332/500 [1:02:26<31:06, 11.11s/it, loss=0.322, lr=0.0001]\n",
            "Steps:  66%|██████▋   | 332/500 [1:02:26<31:06, 11.11s/it, loss=0.0427, lr=0.0001]\n",
            "Steps:  66%|██████▋   | 332/500 [1:02:30<31:06, 11.11s/it, loss=0.00168, lr=0.0001]\n",
            "Steps:  66%|██████▋   | 332/500 [1:02:33<31:06, 11.11s/it, loss=0.00786, lr=0.0001]\n",
            "Steps:  66%|██████▋   | 332/500 [1:02:36<31:06, 11.11s/it, loss=0.0419, lr=0.0001] \n",
            "Steps:  67%|██████▋   | 333/500 [1:02:39<32:46, 11.78s/it, loss=0.0419, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 333/500 [1:02:39<32:46, 11.78s/it, loss=0.0147, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 333/500 [1:02:42<32:46, 11.78s/it, loss=0.0579, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 333/500 [1:02:45<32:46, 11.78s/it, loss=0.743, lr=0.0001] \n",
            "Steps:  67%|██████▋   | 333/500 [1:02:48<32:46, 11.78s/it, loss=0.143, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 334/500 [1:02:51<32:19, 11.69s/it, loss=0.143, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 334/500 [1:02:51<32:19, 11.69s/it, loss=0.222, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 334/500 [1:02:54<32:19, 11.69s/it, loss=0.0198, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 334/500 [1:02:57<32:19, 11.69s/it, loss=0.00567, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 335/500 [1:02:59<29:32, 10.74s/it, loss=0.00567, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 335/500 [1:02:59<29:32, 10.74s/it, loss=0.0015, lr=0.0001] \n",
            "Steps:  67%|██████▋   | 335/500 [1:03:04<29:32, 10.74s/it, loss=0.0102, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 335/500 [1:03:07<29:32, 10.74s/it, loss=0.0885, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 335/500 [1:03:10<29:32, 10.74s/it, loss=0.13, lr=0.0001]  \n",
            "Steps:  67%|██████▋   | 336/500 [1:03:12<31:11, 11.41s/it, loss=0.13, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 336/500 [1:03:12<31:11, 11.41s/it, loss=0.00359, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 336/500 [1:03:15<31:11, 11.41s/it, loss=0.0209, lr=0.0001] \n",
            "Steps:  67%|██████▋   | 336/500 [1:03:18<31:11, 11.41s/it, loss=0.316, lr=0.0001] \n",
            "Steps:  67%|██████▋   | 336/500 [1:03:21<31:11, 11.41s/it, loss=0.674, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 337/500 [1:03:24<31:27, 11.58s/it, loss=0.674, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 337/500 [1:03:24<31:27, 11.58s/it, loss=0.171, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 337/500 [1:03:27<31:27, 11.58s/it, loss=0.0275, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 337/500 [1:03:30<31:27, 11.58s/it, loss=0.0771, lr=0.0001]\n",
            "Steps:  67%|██████▋   | 337/500 [1:03:33<31:27, 11.58s/it, loss=0.518, lr=0.0001] \n",
            "Steps:  68%|██████▊   | 338/500 [1:03:36<31:09, 11.54s/it, loss=0.518, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 338/500 [1:03:36<31:09, 11.54s/it, loss=0.593, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 338/500 [1:03:39<31:09, 11.54s/it, loss=0.00522, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 338/500 [1:03:42<31:09, 11.54s/it, loss=0.116, lr=0.0001]  \n",
            "Steps:  68%|██████▊   | 338/500 [1:03:44<31:09, 11.54s/it, loss=0.00368, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 339/500 [1:03:47<30:55, 11.53s/it, loss=0.00368, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 339/500 [1:03:47<30:55, 11.53s/it, loss=0.0157, lr=0.0001] \n",
            "Steps:  68%|██████▊   | 339/500 [1:03:50<30:55, 11.53s/it, loss=0.0091, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 339/500 [1:03:53<30:55, 11.53s/it, loss=0.0527, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 340/500 [1:03:56<28:23, 10.65s/it, loss=0.0527, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 340/500 [1:03:56<28:23, 10.65s/it, loss=0.00834, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 340/500 [1:03:59<28:23, 10.65s/it, loss=0.261, lr=0.0001]  \n",
            "Steps:  68%|██████▊   | 340/500 [1:04:02<28:23, 10.65s/it, loss=0.263, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 340/500 [1:04:04<28:23, 10.65s/it, loss=0.00473, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 341/500 [1:04:07<28:52, 10.90s/it, loss=0.00473, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 341/500 [1:04:07<28:52, 10.90s/it, loss=0.00336, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 341/500 [1:04:10<28:52, 10.90s/it, loss=0.125, lr=0.0001]  \n",
            "Steps:  68%|██████▊   | 341/500 [1:04:13<28:52, 10.90s/it, loss=0.0405, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 341/500 [1:04:16<28:52, 10.90s/it, loss=0.0631, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 342/500 [1:04:19<29:17, 11.12s/it, loss=0.0631, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 342/500 [1:04:19<29:17, 11.12s/it, loss=0.406, lr=0.0001] \n",
            "Steps:  68%|██████▊   | 342/500 [1:04:22<29:17, 11.12s/it, loss=0.0259, lr=0.0001]\n",
            "Steps:  68%|██████▊   | 342/500 [1:04:25<29:17, 11.12s/it, loss=0.146, lr=0.0001] \n",
            "Steps:  68%|██████▊   | 342/500 [1:04:28<29:17, 11.12s/it, loss=0.0541, lr=0.0001]\n",
            "Steps:  69%|██████▊   | 343/500 [1:04:31<29:29, 11.27s/it, loss=0.0541, lr=0.0001]\n",
            "Steps:  69%|██████▊   | 343/500 [1:04:31<29:29, 11.27s/it, loss=0.279, lr=0.0001] \n",
            "Steps:  69%|██████▊   | 343/500 [1:04:33<29:29, 11.27s/it, loss=0.179, lr=0.0001]\n",
            "Steps:  69%|██████▊   | 343/500 [1:04:36<29:29, 11.27s/it, loss=0.0109, lr=0.0001]\n",
            "Steps:  69%|██████▊   | 343/500 [1:04:41<29:29, 11.27s/it, loss=0.0154, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 344/500 [1:04:44<30:51, 11.87s/it, loss=0.0154, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 344/500 [1:04:44<30:51, 11.87s/it, loss=0.00167, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 344/500 [1:04:47<30:51, 11.87s/it, loss=0.383, lr=0.0001]  \n",
            "Steps:  69%|██████▉   | 344/500 [1:04:50<30:51, 11.87s/it, loss=0.0168, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 345/500 [1:04:52<28:01, 10.85s/it, loss=0.0168, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 345/500 [1:04:52<28:01, 10.85s/it, loss=0.00635, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 345/500 [1:04:55<28:01, 10.85s/it, loss=0.133, lr=0.0001]  \n",
            "Steps:  69%|██████▉   | 345/500 [1:04:58<28:01, 10.85s/it, loss=0.0316, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 345/500 [1:05:01<28:01, 10.85s/it, loss=0.204, lr=0.0001] \n",
            "Steps:  69%|██████▉   | 346/500 [1:05:05<29:33, 11.51s/it, loss=0.204, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 346/500 [1:05:05<29:33, 11.51s/it, loss=0.228, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 346/500 [1:05:08<29:33, 11.51s/it, loss=0.0196, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 346/500 [1:05:11<29:33, 11.51s/it, loss=0.0643, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 346/500 [1:05:14<29:33, 11.51s/it, loss=0.00326, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 347/500 [1:05:17<29:20, 11.51s/it, loss=0.00326, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 347/500 [1:05:17<29:20, 11.51s/it, loss=0.0942, lr=0.0001] \n",
            "Steps:  69%|██████▉   | 347/500 [1:05:20<29:20, 11.51s/it, loss=0.445, lr=0.0001] \n",
            "Steps:  69%|██████▉   | 347/500 [1:05:23<29:20, 11.51s/it, loss=0.027, lr=0.0001]\n",
            "Steps:  69%|██████▉   | 347/500 [1:05:26<29:20, 11.51s/it, loss=0.0184, lr=0.0001]\n",
            "Steps:  70%|██████▉   | 348/500 [1:05:29<29:19, 11.57s/it, loss=0.0184, lr=0.0001]\n",
            "Steps:  70%|██████▉   | 348/500 [1:05:29<29:19, 11.57s/it, loss=0.0056, lr=0.0001]\n",
            "Steps:  70%|██████▉   | 348/500 [1:05:32<29:19, 11.57s/it, loss=0.028, lr=0.0001] \n",
            "Steps:  70%|██████▉   | 348/500 [1:05:34<29:19, 11.57s/it, loss=0.251, lr=0.0001]\n",
            "Steps:  70%|██████▉   | 348/500 [1:05:37<29:19, 11.57s/it, loss=0.17, lr=0.0001] \n",
            "Steps:  70%|██████▉   | 349/500 [1:05:40<29:04, 11.55s/it, loss=0.17, lr=0.0001]\n",
            "Steps:  70%|██████▉   | 349/500 [1:05:40<29:04, 11.55s/it, loss=0.071, lr=0.0001]\n",
            "Steps:  70%|██████▉   | 349/500 [1:05:43<29:04, 11.55s/it, loss=0.585, lr=0.0001]\n",
            "Steps:  70%|██████▉   | 349/500 [1:05:46<29:04, 11.55s/it, loss=0.0098, lr=0.0001]\n",
            "Steps:  70%|███████   | 350/500 [1:05:49<26:32, 10.61s/it, loss=0.0098, lr=0.0001]\n",
            "Steps:  70%|███████   | 350/500 [1:05:49<26:32, 10.61s/it, loss=0.0104, lr=0.0001]\n",
            "Steps:  70%|███████   | 350/500 [1:05:52<26:32, 10.61s/it, loss=0.307, lr=0.0001] \n",
            "Steps:  70%|███████   | 350/500 [1:05:55<26:32, 10.61s/it, loss=0.00447, lr=0.0001]\n",
            "Steps:  70%|███████   | 350/500 [1:05:58<26:32, 10.61s/it, loss=0.0124, lr=0.0001] \n",
            "Steps:  70%|███████   | 351/500 [1:06:01<27:29, 11.07s/it, loss=0.0124, lr=0.0001]\n",
            "Steps:  70%|███████   | 351/500 [1:06:01<27:29, 11.07s/it, loss=0.0665, lr=0.0001]\n",
            "Steps:  70%|███████   | 351/500 [1:06:04<27:29, 11.07s/it, loss=0.00359, lr=0.0001]\n",
            "Steps:  70%|███████   | 351/500 [1:06:06<27:29, 11.07s/it, loss=0.012, lr=0.0001]  \n",
            "Steps:  70%|███████   | 351/500 [1:06:09<27:29, 11.07s/it, loss=0.0157, lr=0.0001]\n",
            "Steps:  70%|███████   | 352/500 [1:06:12<27:27, 11.13s/it, loss=0.0157, lr=0.0001]\n",
            "Steps:  70%|███████   | 352/500 [1:06:12<27:27, 11.13s/it, loss=0.108, lr=0.0001] \n",
            "Steps:  70%|███████   | 352/500 [1:06:15<27:27, 11.13s/it, loss=0.133, lr=0.0001]\n",
            "Steps:  70%|███████   | 352/500 [1:06:18<27:27, 11.13s/it, loss=0.0492, lr=0.0001]\n",
            "Steps:  70%|███████   | 352/500 [1:06:21<27:27, 11.13s/it, loss=0.0601, lr=0.0001]\n",
            "Steps:  71%|███████   | 353/500 [1:06:23<27:26, 11.20s/it, loss=0.0601, lr=0.0001]\n",
            "Steps:  71%|███████   | 353/500 [1:06:23<27:26, 11.20s/it, loss=0.314, lr=0.0001] \n",
            "Steps:  71%|███████   | 353/500 [1:06:26<27:26, 11.20s/it, loss=0.0184, lr=0.0001]\n",
            "Steps:  71%|███████   | 353/500 [1:06:29<27:26, 11.20s/it, loss=0.0202, lr=0.0001]\n",
            "Steps:  71%|███████   | 353/500 [1:06:32<27:26, 11.20s/it, loss=0.00467, lr=0.0001]\n",
            "Steps:  71%|███████   | 354/500 [1:06:36<28:31, 11.72s/it, loss=0.00467, lr=0.0001]\n",
            "Steps:  71%|███████   | 354/500 [1:06:36<28:31, 11.72s/it, loss=0.00778, lr=0.0001]\n",
            "Steps:  71%|███████   | 354/500 [1:06:39<28:31, 11.72s/it, loss=0.0777, lr=0.0001] \n",
            "Steps:  71%|███████   | 354/500 [1:06:42<28:31, 11.72s/it, loss=0.0795, lr=0.0001]\n",
            "Steps:  71%|███████   | 355/500 [1:06:45<26:03, 10.78s/it, loss=0.0795, lr=0.0001]\n",
            "Steps:  71%|███████   | 355/500 [1:06:45<26:03, 10.78s/it, loss=0.00416, lr=0.0001]\n",
            "Steps:  71%|███████   | 355/500 [1:06:48<26:03, 10.78s/it, loss=0.0444, lr=0.0001] \n",
            "Steps:  71%|███████   | 355/500 [1:06:51<26:03, 10.78s/it, loss=0.171, lr=0.0001] \n",
            "Steps:  71%|███████   | 355/500 [1:06:54<26:03, 10.78s/it, loss=0.03, lr=0.0001] \n",
            "Steps:  71%|███████   | 356/500 [1:06:57<26:35, 11.08s/it, loss=0.03, lr=0.0001]\n",
            "Steps:  71%|███████   | 356/500 [1:06:57<26:35, 11.08s/it, loss=0.0776, lr=0.0001]\n",
            "Steps:  71%|███████   | 356/500 [1:07:00<26:35, 11.08s/it, loss=0.079, lr=0.0001] \n",
            "Steps:  71%|███████   | 356/500 [1:07:02<26:35, 11.08s/it, loss=0.0766, lr=0.0001]\n",
            "Steps:  71%|███████   | 356/500 [1:07:05<26:35, 11.08s/it, loss=0.492, lr=0.0001] \n",
            "Steps:  71%|███████▏  | 357/500 [1:07:08<26:40, 11.19s/it, loss=0.492, lr=0.0001]\n",
            "Steps:  71%|███████▏  | 357/500 [1:07:08<26:40, 11.19s/it, loss=0.0882, lr=0.0001]\n",
            "Steps:  71%|███████▏  | 357/500 [1:07:13<26:40, 11.19s/it, loss=0.00432, lr=0.0001]\n",
            "Steps:  71%|███████▏  | 357/500 [1:07:16<26:40, 11.19s/it, loss=0.0793, lr=0.0001] \n",
            "Steps:  71%|███████▏  | 357/500 [1:07:19<26:40, 11.19s/it, loss=0.153, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  72%|███████▏  | 358/500 [1:07:22<28:15, 11.94s/it, loss=0.153, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 358/500 [1:07:22<28:15, 11.94s/it, loss=0.00662, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 358/500 [1:07:25<28:15, 11.94s/it, loss=0.346, lr=0.0001]  \n",
            "Steps:  72%|███████▏  | 358/500 [1:07:27<28:15, 11.94s/it, loss=0.00712, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 358/500 [1:07:30<28:15, 11.94s/it, loss=0.225, lr=0.0001]  \n",
            "Steps:  72%|███████▏  | 359/500 [1:07:33<27:40, 11.78s/it, loss=0.225, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 359/500 [1:07:33<27:40, 11.78s/it, loss=0.0135, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 359/500 [1:07:36<27:40, 11.78s/it, loss=0.0476, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 359/500 [1:07:39<27:40, 11.78s/it, loss=0.45, lr=0.0001]  \n",
            "Steps:  72%|███████▏  | 360/500 [1:07:42<25:12, 10.80s/it, loss=0.45, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 360/500 [1:07:42<25:12, 10.80s/it, loss=0.154, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 360/500 [1:07:45<25:12, 10.80s/it, loss=0.124, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 360/500 [1:07:49<25:12, 10.80s/it, loss=0.353, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 360/500 [1:07:52<25:12, 10.80s/it, loss=0.0765, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 361/500 [1:07:55<26:33, 11.46s/it, loss=0.0765, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 361/500 [1:07:55<26:33, 11.46s/it, loss=0.0142, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 361/500 [1:07:58<26:33, 11.46s/it, loss=0.0477, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 361/500 [1:08:00<26:33, 11.46s/it, loss=0.271, lr=0.0001] \n",
            "Steps:  72%|███████▏  | 361/500 [1:08:03<26:33, 11.46s/it, loss=0.0153, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 362/500 [1:08:06<26:22, 11.47s/it, loss=0.0153, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 362/500 [1:08:06<26:22, 11.47s/it, loss=0.00629, lr=0.0001]\n",
            "Steps:  72%|███████▏  | 362/500 [1:08:09<26:22, 11.47s/it, loss=0.123, lr=0.0001]  \n",
            "Steps:  72%|███████▏  | 362/500 [1:08:12<26:22, 11.47s/it, loss=0.2, lr=0.0001]  \n",
            "Steps:  72%|███████▏  | 362/500 [1:08:15<26:22, 11.47s/it, loss=0.52, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 363/500 [1:08:18<26:19, 11.53s/it, loss=0.52, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 363/500 [1:08:18<26:19, 11.53s/it, loss=0.285, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 363/500 [1:08:21<26:19, 11.53s/it, loss=0.00245, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 363/500 [1:08:24<26:19, 11.53s/it, loss=0.00347, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 363/500 [1:08:27<26:19, 11.53s/it, loss=0.565, lr=0.0001]  \n",
            "Steps:  73%|███████▎  | 364/500 [1:08:29<26:09, 11.54s/it, loss=0.565, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 364/500 [1:08:29<26:09, 11.54s/it, loss=0.213, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 364/500 [1:08:32<26:09, 11.54s/it, loss=0.0136, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 364/500 [1:08:35<26:09, 11.54s/it, loss=0.0498, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 365/500 [1:08:38<23:51, 10.61s/it, loss=0.0498, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 365/500 [1:08:38<23:51, 10.61s/it, loss=0.219, lr=0.0001] \n",
            "Steps:  73%|███████▎  | 365/500 [1:08:41<23:51, 10.61s/it, loss=0.00537, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 365/500 [1:08:44<23:51, 10.61s/it, loss=0.555, lr=0.0001]  \n",
            "Steps:  73%|███████▎  | 365/500 [1:08:48<23:51, 10.61s/it, loss=0.0508, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 366/500 [1:08:51<25:19, 11.34s/it, loss=0.0508, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 366/500 [1:08:51<25:19, 11.34s/it, loss=0.0405, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 366/500 [1:08:54<25:19, 11.34s/it, loss=0.139, lr=0.0001] \n",
            "Steps:  73%|███████▎  | 366/500 [1:08:57<25:19, 11.34s/it, loss=0.148, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 366/500 [1:09:00<25:19, 11.34s/it, loss=0.0252, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 367/500 [1:09:02<25:12, 11.37s/it, loss=0.0252, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 367/500 [1:09:02<25:12, 11.37s/it, loss=0.0106, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 367/500 [1:09:05<25:12, 11.37s/it, loss=0.0513, lr=0.0001]\n",
            "Steps:  73%|███████▎  | 367/500 [1:09:08<25:12, 11.37s/it, loss=0.29, lr=0.0001]  \n",
            "Steps:  73%|███████▎  | 367/500 [1:09:11<25:12, 11.37s/it, loss=0.0498, lr=0.0001]\n",
            "Steps:  74%|███████▎  | 368/500 [1:09:14<25:03, 11.39s/it, loss=0.0498, lr=0.0001]\n",
            "Steps:  74%|███████▎  | 368/500 [1:09:14<25:03, 11.39s/it, loss=0.0273, lr=0.0001]\n",
            "Steps:  74%|███████▎  | 368/500 [1:09:17<25:03, 11.39s/it, loss=0.0448, lr=0.0001]\n",
            "Steps:  74%|███████▎  | 368/500 [1:09:20<25:03, 11.39s/it, loss=0.148, lr=0.0001] \n",
            "Steps:  74%|███████▎  | 368/500 [1:09:23<25:03, 11.39s/it, loss=0.00747, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 369/500 [1:09:26<25:07, 11.51s/it, loss=0.00747, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 369/500 [1:09:26<25:07, 11.51s/it, loss=0.334, lr=0.0001]  \n",
            "Steps:  74%|███████▍  | 369/500 [1:09:28<25:07, 11.51s/it, loss=0.166, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 369/500 [1:09:31<25:07, 11.51s/it, loss=0.116, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 370/500 [1:09:34<23:02, 10.63s/it, loss=0.116, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 370/500 [1:09:34<23:02, 10.63s/it, loss=0.19, lr=0.0001] \n",
            "Steps:  74%|███████▍  | 370/500 [1:09:37<23:02, 10.63s/it, loss=0.139, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 370/500 [1:09:40<23:02, 10.63s/it, loss=0.00396, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 370/500 [1:09:43<23:02, 10.63s/it, loss=0.159, lr=0.0001]  \n",
            "Steps:  74%|███████▍  | 371/500 [1:09:48<25:01, 11.64s/it, loss=0.159, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 371/500 [1:09:48<25:01, 11.64s/it, loss=0.198, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 371/500 [1:09:51<25:01, 11.64s/it, loss=0.121, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 371/500 [1:09:54<25:01, 11.64s/it, loss=0.0296, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 371/500 [1:09:57<25:01, 11.64s/it, loss=0.05, lr=0.0001]  INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  74%|███████▍  | 372/500 [1:10:00<24:39, 11.56s/it, loss=0.05, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 372/500 [1:10:00<24:39, 11.56s/it, loss=0.0168, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 372/500 [1:10:02<24:39, 11.56s/it, loss=0.0113, lr=0.0001]\n",
            "Steps:  74%|███████▍  | 372/500 [1:10:05<24:39, 11.56s/it, loss=0.385, lr=0.0001] \n",
            "Steps:  74%|███████▍  | 372/500 [1:10:08<24:39, 11.56s/it, loss=0.0418, lr=0.0001]\n",
            "Steps:  75%|███████▍  | 373/500 [1:10:11<24:26, 11.55s/it, loss=0.0418, lr=0.0001]\n",
            "Steps:  75%|███████▍  | 373/500 [1:10:11<24:26, 11.55s/it, loss=0.00255, lr=0.0001]\n",
            "Steps:  75%|███████▍  | 373/500 [1:10:14<24:26, 11.55s/it, loss=0.00497, lr=0.0001]\n",
            "Steps:  75%|███████▍  | 373/500 [1:10:17<24:26, 11.55s/it, loss=0.00218, lr=0.0001]\n",
            "Steps:  75%|███████▍  | 373/500 [1:10:20<24:26, 11.55s/it, loss=0.00165, lr=0.0001]\n",
            "Steps:  75%|███████▍  | 374/500 [1:10:23<24:11, 11.52s/it, loss=0.00165, lr=0.0001]\n",
            "Steps:  75%|███████▍  | 374/500 [1:10:23<24:11, 11.52s/it, loss=0.0059, lr=0.0001] \n",
            "Steps:  75%|███████▍  | 374/500 [1:10:25<24:11, 11.52s/it, loss=0.295, lr=0.0001] \n",
            "Steps:  75%|███████▍  | 374/500 [1:10:28<24:11, 11.52s/it, loss=0.0812, lr=0.0001]\n",
            "Steps:  75%|███████▌  | 375/500 [1:10:31<22:06, 10.61s/it, loss=0.0812, lr=0.0001]\n",
            "Steps:  75%|███████▌  | 375/500 [1:10:31<22:06, 10.61s/it, loss=0.241, lr=0.0001] \n",
            "Steps:  75%|███████▌  | 375/500 [1:10:34<22:06, 10.61s/it, loss=0.0125, lr=0.0001]\n",
            "Steps:  75%|███████▌  | 375/500 [1:10:37<22:06, 10.61s/it, loss=0.0404, lr=0.0001]\n",
            "Steps:  75%|███████▌  | 375/500 [1:10:40<22:06, 10.61s/it, loss=0.152, lr=0.0001] \n",
            "Steps:  75%|███████▌  | 376/500 [1:10:43<22:28, 10.87s/it, loss=0.152, lr=0.0001]\n",
            "Steps:  75%|███████▌  | 376/500 [1:10:43<22:28, 10.87s/it, loss=0.176, lr=0.0001]\n",
            "Steps:  75%|███████▌  | 376/500 [1:10:45<22:28, 10.87s/it, loss=0.00495, lr=0.0001]\n",
            "Steps:  75%|███████▌  | 376/500 [1:10:48<22:28, 10.87s/it, loss=0.0326, lr=0.0001] \n",
            "Steps:  75%|███████▌  | 376/500 [1:10:53<22:28, 10.87s/it, loss=0.503, lr=0.0001] \n",
            "Steps:  75%|███████▌  | 377/500 [1:10:56<23:36, 11.52s/it, loss=0.503, lr=0.0001]\n",
            "Steps:  75%|███████▌  | 377/500 [1:10:56<23:36, 11.52s/it, loss=0.0582, lr=0.0001]\n",
            "Steps:  75%|███████▌  | 377/500 [1:10:58<23:36, 11.52s/it, loss=0.278, lr=0.0001] \n",
            "Steps:  75%|███████▌  | 377/500 [1:11:01<23:36, 11.52s/it, loss=0.00499, lr=0.0001]\n",
            "Steps:  75%|███████▌  | 377/500 [1:11:04<23:36, 11.52s/it, loss=0.0345, lr=0.0001] \n",
            "Steps:  76%|███████▌  | 378/500 [1:11:07<23:30, 11.56s/it, loss=0.0345, lr=0.0001]\n",
            "Steps:  76%|███████▌  | 378/500 [1:11:07<23:30, 11.56s/it, loss=0.0814, lr=0.0001]\n",
            "Steps:  76%|███████▌  | 378/500 [1:11:10<23:30, 11.56s/it, loss=0.0155, lr=0.0001]\n",
            "Steps:  76%|███████▌  | 378/500 [1:11:13<23:30, 11.56s/it, loss=0.0241, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  76%|███████▌  | 378/500 [1:11:16<23:30, 11.56s/it, loss=0.0314, lr=0.0001]\n",
            "Steps:  76%|███████▌  | 379/500 [1:11:19<23:14, 11.53s/it, loss=0.0314, lr=0.0001]\n",
            "Steps:  76%|███████▌  | 379/500 [1:11:19<23:14, 11.53s/it, loss=0.0171, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  76%|███████▌  | 379/500 [1:11:21<23:14, 11.53s/it, loss=0.00307, lr=0.0001]\n",
            "Steps:  76%|███████▌  | 379/500 [1:11:24<23:14, 11.53s/it, loss=0.0248, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  76%|███████▌  | 380/500 [1:11:27<21:15, 10.63s/it, loss=0.0248, lr=0.0001]\n",
            "Steps:  76%|███████▌  | 380/500 [1:11:27<21:15, 10.63s/it, loss=0.0189, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  76%|███████▌  | 380/500 [1:11:30<21:15, 10.63s/it, loss=0.00365, lr=0.0001]\n",
            "Steps:  76%|███████▌  | 380/500 [1:11:33<21:15, 10.63s/it, loss=0.085, lr=0.0001]  \n",
            "Steps:  76%|███████▌  | 380/500 [1:11:36<21:15, 10.63s/it, loss=0.174, lr=0.0001]\n",
            "Steps:  76%|███████▌  | 381/500 [1:11:39<21:41, 10.94s/it, loss=0.174, lr=0.0001]\n",
            "Steps:  76%|███████▌  | 381/500 [1:11:39<21:41, 10.94s/it, loss=0.0764, lr=0.0001]\n",
            "Steps:  76%|███████▌  | 381/500 [1:11:42<21:41, 10.94s/it, loss=0.263, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  76%|███████▌  | 381/500 [1:11:45<21:41, 10.94s/it, loss=0.107, lr=0.0001]\n",
            "Steps:  76%|███████▌  | 381/500 [1:11:48<21:41, 10.94s/it, loss=0.00705, lr=0.0001]\n",
            "Steps:  76%|███████▋  | 382/500 [1:11:50<21:55, 11.15s/it, loss=0.00705, lr=0.0001]\n",
            "Steps:  76%|███████▋  | 382/500 [1:11:50<21:55, 11.15s/it, loss=0.0156, lr=0.0001] \n",
            "Steps:  76%|███████▋  | 382/500 [1:11:53<21:55, 11.15s/it, loss=0.0832, lr=0.0001]\n",
            "Steps:  76%|███████▋  | 382/500 [1:11:56<21:55, 11.15s/it, loss=0.00696, lr=0.0001]\n",
            "Steps:  76%|███████▋  | 382/500 [1:11:59<21:55, 11.15s/it, loss=0.00883, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  77%|███████▋  | 383/500 [1:12:02<21:58, 11.26s/it, loss=0.00883, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 383/500 [1:12:02<21:58, 11.26s/it, loss=0.144, lr=0.0001]  \n",
            "Steps:  77%|███████▋  | 383/500 [1:12:05<21:58, 11.26s/it, loss=0.271, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 383/500 [1:12:08<21:58, 11.26s/it, loss=0.00211, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 383/500 [1:12:11<21:58, 11.26s/it, loss=0.077, lr=0.0001]  \n",
            "Steps:  77%|███████▋  | 384/500 [1:12:13<21:51, 11.30s/it, loss=0.077, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 384/500 [1:12:13<21:51, 11.30s/it, loss=0.053, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 384/500 [1:12:18<21:51, 11.30s/it, loss=0.07, lr=0.0001] \n",
            "Steps:  77%|███████▋  | 384/500 [1:12:21<21:51, 11.30s/it, loss=0.0382, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 385/500 [1:12:24<21:18, 11.12s/it, loss=0.0382, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 385/500 [1:12:24<21:18, 11.12s/it, loss=0.00925, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  77%|███████▋  | 385/500 [1:12:29<21:18, 11.12s/it, loss=0.172, lr=0.0001]  \n",
            "Steps:  77%|███████▋  | 385/500 [1:12:31<21:18, 11.12s/it, loss=0.0231, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 385/500 [1:12:34<21:18, 11.12s/it, loss=0.0918, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 386/500 [1:12:37<22:13, 11.70s/it, loss=0.0918, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 386/500 [1:12:37<22:13, 11.70s/it, loss=0.0213, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 386/500 [1:12:40<22:13, 11.70s/it, loss=0.0405, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 386/500 [1:12:43<22:13, 11.70s/it, loss=0.192, lr=0.0001] \n",
            "Steps:  77%|███████▋  | 386/500 [1:12:46<22:13, 11.70s/it, loss=0.0133, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 387/500 [1:12:49<21:58, 11.67s/it, loss=0.0133, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 387/500 [1:12:49<21:58, 11.67s/it, loss=0.00309, lr=0.0001]\n",
            "Steps:  77%|███████▋  | 387/500 [1:12:52<21:58, 11.67s/it, loss=0.0278, lr=0.0001] \n",
            "Steps:  77%|███████▋  | 387/500 [1:12:54<21:58, 11.67s/it, loss=0.399, lr=0.0001] \n",
            "Steps:  77%|███████▋  | 387/500 [1:12:57<21:58, 11.67s/it, loss=0.178, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 388/500 [1:13:00<21:37, 11.59s/it, loss=0.178, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 388/500 [1:13:00<21:37, 11.59s/it, loss=0.163, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  78%|███████▊  | 388/500 [1:13:03<21:37, 11.59s/it, loss=0.0364, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 388/500 [1:13:06<21:37, 11.59s/it, loss=0.319, lr=0.0001] \n",
            "Steps:  78%|███████▊  | 388/500 [1:13:09<21:37, 11.59s/it, loss=0.262, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 389/500 [1:13:12<21:25, 11.58s/it, loss=0.262, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 389/500 [1:13:12<21:25, 11.58s/it, loss=0.00615, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 389/500 [1:13:15<21:25, 11.58s/it, loss=0.0847, lr=0.0001] \n",
            "Steps:  78%|███████▊  | 389/500 [1:13:17<21:25, 11.58s/it, loss=0.0491, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 390/500 [1:13:20<19:32, 10.66s/it, loss=0.0491, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 390/500 [1:13:20<19:32, 10.66s/it, loss=0.0652, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 390/500 [1:13:23<19:32, 10.66s/it, loss=0.566, lr=0.0001] \n",
            "Steps:  78%|███████▊  | 390/500 [1:13:26<19:32, 10.66s/it, loss=0.263, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 390/500 [1:13:30<19:32, 10.66s/it, loss=0.0327, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 391/500 [1:13:33<20:43, 11.41s/it, loss=0.0327, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 391/500 [1:13:33<20:43, 11.41s/it, loss=0.0565, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 391/500 [1:13:36<20:43, 11.41s/it, loss=0.0275, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 391/500 [1:13:39<20:43, 11.41s/it, loss=0.439, lr=0.0001] \n",
            "Steps:  78%|███████▊  | 391/500 [1:13:42<20:43, 11.41s/it, loss=0.018, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 392/500 [1:13:45<20:43, 11.51s/it, loss=0.018, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 392/500 [1:13:45<20:43, 11.51s/it, loss=0.0657, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 392/500 [1:13:48<20:43, 11.51s/it, loss=0.213, lr=0.0001] \n",
            "Steps:  78%|███████▊  | 392/500 [1:13:51<20:43, 11.51s/it, loss=0.0371, lr=0.0001]\n",
            "Steps:  78%|███████▊  | 392/500 [1:13:54<20:43, 11.51s/it, loss=0.00286, lr=0.0001]\n",
            "Steps:  79%|███████▊  | 393/500 [1:13:57<20:31, 11.51s/it, loss=0.00286, lr=0.0001]\n",
            "Steps:  79%|███████▊  | 393/500 [1:13:57<20:31, 11.51s/it, loss=0.122, lr=0.0001]  \n",
            "Steps:  79%|███████▊  | 393/500 [1:13:59<20:31, 11.51s/it, loss=0.00759, lr=0.0001]\n",
            "Steps:  79%|███████▊  | 393/500 [1:14:02<20:31, 11.51s/it, loss=0.559, lr=0.0001]  \n",
            "Steps:  79%|███████▊  | 393/500 [1:14:05<20:31, 11.51s/it, loss=0.699, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 394/500 [1:14:08<20:20, 11.52s/it, loss=0.699, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 394/500 [1:14:08<20:20, 11.52s/it, loss=0.0379, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 394/500 [1:14:11<20:20, 11.52s/it, loss=0.00833, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 394/500 [1:14:14<20:20, 11.52s/it, loss=0.0809, lr=0.0001] \n",
            "Steps:  79%|███████▉  | 395/500 [1:14:17<18:33, 10.60s/it, loss=0.0809, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 395/500 [1:14:17<18:33, 10.60s/it, loss=0.0695, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  79%|███████▉  | 395/500 [1:14:20<18:33, 10.60s/it, loss=0.0843, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 395/500 [1:14:23<18:33, 10.60s/it, loss=0.0298, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 395/500 [1:14:25<18:33, 10.60s/it, loss=0.476, lr=0.0001] \n",
            "Steps:  79%|███████▉  | 396/500 [1:14:28<18:53, 10.90s/it, loss=0.476, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 396/500 [1:14:28<18:53, 10.90s/it, loss=0.0366, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 396/500 [1:14:31<18:53, 10.90s/it, loss=0.373, lr=0.0001] \n",
            "Steps:  79%|███████▉  | 396/500 [1:14:34<18:53, 10.90s/it, loss=0.00726, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 396/500 [1:14:37<18:53, 10.90s/it, loss=0.0653, lr=0.0001] \n",
            "Steps:  79%|███████▉  | 397/500 [1:14:40<19:10, 11.17s/it, loss=0.0653, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 397/500 [1:14:40<19:10, 11.17s/it, loss=0.0892, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 397/500 [1:14:43<19:10, 11.17s/it, loss=0.0164, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 397/500 [1:14:46<19:10, 11.17s/it, loss=0.0257, lr=0.0001]\n",
            "Steps:  79%|███████▉  | 397/500 [1:14:49<19:10, 11.17s/it, loss=0.00401, lr=0.0001]\n",
            "Steps:  80%|███████▉  | 398/500 [1:14:53<20:07, 11.84s/it, loss=0.00401, lr=0.0001]\n",
            "Steps:  80%|███████▉  | 398/500 [1:14:53<20:07, 11.84s/it, loss=0.0638, lr=0.0001] \n",
            "Steps:  80%|███████▉  | 398/500 [1:14:56<20:07, 11.84s/it, loss=0.00463, lr=0.0001]\n",
            "Steps:  80%|███████▉  | 398/500 [1:14:59<20:07, 11.84s/it, loss=0.229, lr=0.0001]  \n",
            "Steps:  80%|███████▉  | 398/500 [1:15:02<20:07, 11.84s/it, loss=0.163, lr=0.0001]\n",
            "Steps:  80%|███████▉  | 399/500 [1:15:05<19:42, 11.70s/it, loss=0.163, lr=0.0001]\n",
            "Steps:  80%|███████▉  | 399/500 [1:15:05<19:42, 11.70s/it, loss=0.0219, lr=0.0001]\n",
            "Steps:  80%|███████▉  | 399/500 [1:15:08<19:42, 11.70s/it, loss=0.0031, lr=0.0001]\n",
            "Steps:  80%|███████▉  | 399/500 [1:15:11<19:42, 11.70s/it, loss=0.013, lr=0.0001] \n",
            "Steps:  80%|████████  | 400/500 [1:15:13<17:56, 10.76s/it, loss=0.013, lr=0.0001]\n",
            "Steps:  80%|████████  | 400/500 [1:15:13<17:56, 10.76s/it, loss=0.00422, lr=0.0001]\n",
            "Steps:  80%|████████  | 400/500 [1:15:16<17:56, 10.76s/it, loss=0.0999, lr=0.0001] \n",
            "Steps:  80%|████████  | 400/500 [1:15:19<17:56, 10.76s/it, loss=0.00733, lr=0.0001]\n",
            "Steps:  80%|████████  | 400/500 [1:15:22<17:56, 10.76s/it, loss=0.187, lr=0.0001]  \n",
            "Steps:  80%|████████  | 401/500 [1:15:25<18:06, 10.97s/it, loss=0.187, lr=0.0001]\n",
            "Steps:  80%|████████  | 401/500 [1:15:25<18:06, 10.97s/it, loss=0.0164, lr=0.0001]\n",
            "Steps:  80%|████████  | 401/500 [1:15:28<18:06, 10.97s/it, loss=0.0131, lr=0.0001]\n",
            "Steps:  80%|████████  | 401/500 [1:15:31<18:06, 10.97s/it, loss=0.0752, lr=0.0001]\n",
            "Steps:  80%|████████  | 401/500 [1:15:33<18:06, 10.97s/it, loss=0.0297, lr=0.0001]\n",
            "Steps:  80%|████████  | 402/500 [1:15:36<18:11, 11.13s/it, loss=0.0297, lr=0.0001]\n",
            "Steps:  80%|████████  | 402/500 [1:15:36<18:11, 11.13s/it, loss=0.102, lr=0.0001] \n",
            "Steps:  80%|████████  | 402/500 [1:15:39<18:11, 11.13s/it, loss=0.172, lr=0.0001]\n",
            "Steps:  80%|████████  | 402/500 [1:15:42<18:11, 11.13s/it, loss=0.167, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  80%|████████  | 402/500 [1:15:45<18:11, 11.13s/it, loss=0.174, lr=0.0001]\n",
            "Steps:  81%|████████  | 403/500 [1:15:48<18:17, 11.32s/it, loss=0.174, lr=0.0001]\n",
            "Steps:  81%|████████  | 403/500 [1:15:48<18:17, 11.32s/it, loss=0.0458, lr=0.0001]\n",
            "Steps:  81%|████████  | 403/500 [1:15:51<18:17, 11.32s/it, loss=0.013, lr=0.0001] \n",
            "Steps:  81%|████████  | 403/500 [1:15:54<18:17, 11.32s/it, loss=0.00787, lr=0.0001]\n",
            "Steps:  81%|████████  | 403/500 [1:15:58<18:17, 11.32s/it, loss=0.121, lr=0.0001]  \n",
            "Steps:  81%|████████  | 404/500 [1:16:01<18:53, 11.81s/it, loss=0.121, lr=0.0001]\n",
            "Steps:  81%|████████  | 404/500 [1:16:01<18:53, 11.81s/it, loss=0.336, lr=0.0001]\n",
            "Steps:  81%|████████  | 404/500 [1:16:04<18:53, 11.81s/it, loss=0.325, lr=0.0001]\n",
            "Steps:  81%|████████  | 404/500 [1:16:07<18:53, 11.81s/it, loss=0.0716, lr=0.0001]\n",
            "Steps:  81%|████████  | 405/500 [1:16:10<17:07, 10.82s/it, loss=0.0716, lr=0.0001]\n",
            "Steps:  81%|████████  | 405/500 [1:16:10<17:07, 10.82s/it, loss=0.132, lr=0.0001] \n",
            "Steps:  81%|████████  | 405/500 [1:16:14<17:07, 10.82s/it, loss=0.123, lr=0.0001]\n",
            "Steps:  81%|████████  | 405/500 [1:16:17<17:07, 10.82s/it, loss=0.0327, lr=0.0001]\n",
            "Steps:  81%|████████  | 405/500 [1:16:20<17:07, 10.82s/it, loss=0.074, lr=0.0001] \n",
            "Steps:  81%|████████  | 406/500 [1:16:23<17:58, 11.48s/it, loss=0.074, lr=0.0001]\n",
            "Steps:  81%|████████  | 406/500 [1:16:23<17:58, 11.48s/it, loss=0.355, lr=0.0001]\n",
            "Steps:  81%|████████  | 406/500 [1:16:25<17:58, 11.48s/it, loss=0.0214, lr=0.0001]\n",
            "Steps:  81%|████████  | 406/500 [1:16:28<17:58, 11.48s/it, loss=0.421, lr=0.0001] \n",
            "Steps:  81%|████████  | 406/500 [1:16:31<17:58, 11.48s/it, loss=0.0122, lr=0.0001]\n",
            "Steps:  81%|████████▏ | 407/500 [1:16:34<17:53, 11.54s/it, loss=0.0122, lr=0.0001]\n",
            "Steps:  81%|████████▏ | 407/500 [1:16:34<17:53, 11.54s/it, loss=0.0676, lr=0.0001]\n",
            "Steps:  81%|████████▏ | 407/500 [1:16:37<17:53, 11.54s/it, loss=0.275, lr=0.0001] \n",
            "Steps:  81%|████████▏ | 407/500 [1:16:40<17:53, 11.54s/it, loss=0.0422, lr=0.0001]\n",
            "Steps:  81%|████████▏ | 407/500 [1:16:43<17:53, 11.54s/it, loss=0.481, lr=0.0001] \n",
            "Steps:  82%|████████▏ | 408/500 [1:16:46<17:40, 11.53s/it, loss=0.481, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 408/500 [1:16:46<17:40, 11.53s/it, loss=0.163, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 408/500 [1:16:49<17:40, 11.53s/it, loss=0.0647, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 408/500 [1:16:51<17:40, 11.53s/it, loss=0.0123, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 408/500 [1:16:54<17:40, 11.53s/it, loss=0.307, lr=0.0001] \n",
            "Steps:  82%|████████▏ | 409/500 [1:16:57<17:25, 11.49s/it, loss=0.307, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 409/500 [1:16:57<17:25, 11.49s/it, loss=0.00362, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 409/500 [1:17:00<17:25, 11.49s/it, loss=0.152, lr=0.0001]  \n",
            "Steps:  82%|████████▏ | 409/500 [1:17:03<17:25, 11.49s/it, loss=0.0121, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 410/500 [1:17:06<15:54, 10.60s/it, loss=0.0121, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 410/500 [1:17:06<15:54, 10.60s/it, loss=0.00878, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 410/500 [1:17:09<15:54, 10.60s/it, loss=0.58, lr=0.0001]   \n",
            "Steps:  82%|████████▏ | 410/500 [1:17:12<15:54, 10.60s/it, loss=0.0204, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 410/500 [1:17:14<15:54, 10.60s/it, loss=0.00243, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  82%|████████▏ | 411/500 [1:17:17<16:10, 10.90s/it, loss=0.00243, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 411/500 [1:17:17<16:10, 10.90s/it, loss=0.0184, lr=0.0001] \n",
            "Steps:  82%|████████▏ | 411/500 [1:17:20<16:10, 10.90s/it, loss=0.0331, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 411/500 [1:17:23<16:10, 10.90s/it, loss=0.022, lr=0.0001] \n",
            "Steps:  82%|████████▏ | 411/500 [1:17:26<16:10, 10.90s/it, loss=0.103, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 412/500 [1:17:29<16:17, 11.10s/it, loss=0.103, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 412/500 [1:17:29<16:17, 11.10s/it, loss=0.0559, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 412/500 [1:17:32<16:17, 11.10s/it, loss=0.195, lr=0.0001] \n",
            "Steps:  82%|████████▏ | 412/500 [1:17:35<16:17, 11.10s/it, loss=0.138, lr=0.0001]\n",
            "Steps:  82%|████████▏ | 412/500 [1:17:37<16:17, 11.10s/it, loss=0.0288, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 413/500 [1:17:40<16:14, 11.20s/it, loss=0.0288, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 413/500 [1:17:40<16:14, 11.20s/it, loss=0.0123, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 413/500 [1:17:45<16:14, 11.20s/it, loss=0.279, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  83%|████████▎ | 413/500 [1:17:47<16:14, 11.20s/it, loss=0.00669, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 413/500 [1:17:50<16:14, 11.20s/it, loss=0.0716, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  83%|████████▎ | 414/500 [1:17:53<16:50, 11.74s/it, loss=0.0716, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 414/500 [1:17:53<16:50, 11.74s/it, loss=0.307, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  83%|████████▎ | 414/500 [1:17:57<16:50, 11.74s/it, loss=0.399, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  83%|████████▎ | 414/500 [1:17:59<16:50, 11.74s/it, loss=0.22, lr=0.0001] \n",
            "Steps:  83%|████████▎ | 415/500 [1:18:02<15:26, 10.90s/it, loss=0.22, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 415/500 [1:18:02<15:26, 10.90s/it, loss=0.0566, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 415/500 [1:18:05<15:26, 10.90s/it, loss=0.0664, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  83%|████████▎ | 415/500 [1:18:08<15:26, 10.90s/it, loss=0.462, lr=0.0001] \n",
            "Steps:  83%|████████▎ | 415/500 [1:18:11<15:26, 10.90s/it, loss=0.014, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 416/500 [1:18:14<15:40, 11.19s/it, loss=0.014, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 416/500 [1:18:14<15:40, 11.19s/it, loss=0.011, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  83%|████████▎ | 416/500 [1:18:17<15:40, 11.19s/it, loss=0.243, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 416/500 [1:18:20<15:40, 11.19s/it, loss=0.00513, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 416/500 [1:18:23<15:40, 11.19s/it, loss=0.275, lr=0.0001]  \n",
            "Steps:  83%|████████▎ | 417/500 [1:18:28<16:31, 11.95s/it, loss=0.275, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 417/500 [1:18:28<16:31, 11.95s/it, loss=0.00203, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 417/500 [1:18:31<16:31, 11.95s/it, loss=0.0519, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  83%|████████▎ | 417/500 [1:18:34<16:31, 11.95s/it, loss=0.00973, lr=0.0001]\n",
            "Steps:  83%|████████▎ | 417/500 [1:18:36<16:31, 11.95s/it, loss=0.00183, lr=0.0001]\n",
            "Steps:  84%|████████▎ | 418/500 [1:18:39<16:06, 11.78s/it, loss=0.00183, lr=0.0001]\n",
            "Steps:  84%|████████▎ | 418/500 [1:18:39<16:06, 11.78s/it, loss=0.127, lr=0.0001]  \n",
            "Steps:  84%|████████▎ | 418/500 [1:18:42<16:06, 11.78s/it, loss=0.286, lr=0.0001]\n",
            "Steps:  84%|████████▎ | 418/500 [1:18:45<16:06, 11.78s/it, loss=0.0019, lr=0.0001]\n",
            "Steps:  84%|████████▎ | 418/500 [1:18:48<16:06, 11.78s/it, loss=0.00494, lr=0.0001]\n",
            "Steps:  84%|████████▍ | 419/500 [1:18:51<15:47, 11.69s/it, loss=0.00494, lr=0.0001]\n",
            "Steps:  84%|████████▍ | 419/500 [1:18:51<15:47, 11.69s/it, loss=0.00704, lr=0.0001]\n",
            "Steps:  84%|████████▍ | 419/500 [1:18:54<15:47, 11.69s/it, loss=0.0142, lr=0.0001] \n",
            "Steps:  84%|████████▍ | 419/500 [1:18:57<15:47, 11.69s/it, loss=0.00337, lr=0.0001]\n",
            "Steps:  84%|████████▍ | 420/500 [1:18:59<14:21, 10.77s/it, loss=0.00337, lr=0.0001]\n",
            "Steps:  84%|████████▍ | 420/500 [1:18:59<14:21, 10.77s/it, loss=0.157, lr=0.0001]  \n",
            "Steps:  84%|████████▍ | 420/500 [1:19:02<14:21, 10.77s/it, loss=0.31, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  84%|████████▍ | 420/500 [1:19:05<14:21, 10.77s/it, loss=0.0586, lr=0.0001]\n",
            "Steps:  84%|████████▍ | 420/500 [1:19:08<14:21, 10.77s/it, loss=0.0209, lr=0.0001]\n",
            "Steps:  84%|████████▍ | 421/500 [1:19:11<14:31, 11.03s/it, loss=0.0209, lr=0.0001]\n",
            "Steps:  84%|████████▍ | 421/500 [1:19:11<14:31, 11.03s/it, loss=0.00514, lr=0.0001]\n",
            "Steps:  84%|████████▍ | 421/500 [1:19:14<14:31, 11.03s/it, loss=0.0249, lr=0.0001] \n",
            "Steps:  84%|████████▍ | 421/500 [1:19:17<14:31, 11.03s/it, loss=0.0989, lr=0.0001]\n",
            "Steps:  84%|████████▍ | 421/500 [1:19:19<14:31, 11.03s/it, loss=0.0036, lr=0.0001]\n",
            "Steps:  84%|████████▍ | 422/500 [1:19:24<15:13, 11.72s/it, loss=0.0036, lr=0.0001]\n",
            "Steps:  84%|████████▍ | 422/500 [1:19:24<15:13, 11.72s/it, loss=0.0338, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  84%|████████▍ | 422/500 [1:19:27<15:13, 11.72s/it, loss=0.0166, lr=0.0001]\n",
            "Steps:  84%|████████▍ | 422/500 [1:19:30<15:13, 11.72s/it, loss=0.0367, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  84%|████████▍ | 422/500 [1:19:33<15:13, 11.72s/it, loss=0.00421, lr=0.0001]\n",
            "Steps:  85%|████████▍ | 423/500 [1:19:36<15:01, 11.71s/it, loss=0.00421, lr=0.0001]\n",
            "Steps:  85%|████████▍ | 423/500 [1:19:36<15:01, 11.71s/it, loss=0.0164, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  85%|████████▍ | 423/500 [1:19:39<15:01, 11.71s/it, loss=0.0216, lr=0.0001]\n",
            "Steps:  85%|████████▍ | 423/500 [1:19:42<15:01, 11.71s/it, loss=0.136, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  85%|████████▍ | 423/500 [1:19:45<15:01, 11.71s/it, loss=0.182, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  85%|████████▍ | 424/500 [1:19:48<14:45, 11.66s/it, loss=0.182, lr=0.0001]\n",
            "Steps:  85%|████████▍ | 424/500 [1:19:48<14:45, 11.66s/it, loss=0.0865, lr=0.0001]\n",
            "Steps:  85%|████████▍ | 424/500 [1:19:50<14:45, 11.66s/it, loss=0.0883, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  85%|████████▍ | 424/500 [1:19:53<14:45, 11.66s/it, loss=0.185, lr=0.0001] \n",
            "Steps:  85%|████████▌ | 425/500 [1:19:56<13:24, 10.72s/it, loss=0.185, lr=0.0001]\n",
            "Steps:  85%|████████▌ | 425/500 [1:19:56<13:24, 10.72s/it, loss=0.151, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  85%|████████▌ | 425/500 [1:20:01<13:24, 10.72s/it, loss=0.14, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  85%|████████▌ | 425/500 [1:20:03<13:24, 10.72s/it, loss=0.219, lr=0.0001]\n",
            "Steps:  85%|████████▌ | 425/500 [1:20:06<13:24, 10.72s/it, loss=0.0611, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  85%|████████▌ | 426/500 [1:20:09<14:06, 11.44s/it, loss=0.0611, lr=0.0001]\n",
            "Steps:  85%|████████▌ | 426/500 [1:20:09<14:06, 11.44s/it, loss=0.114, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  85%|████████▌ | 426/500 [1:20:12<14:06, 11.44s/it, loss=0.0247, lr=0.0001]\n",
            "Steps:  85%|████████▌ | 426/500 [1:20:15<14:06, 11.44s/it, loss=0.0572, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  85%|████████▌ | 426/500 [1:20:18<14:06, 11.44s/it, loss=0.03, lr=0.0001]  \n",
            "Steps:  85%|████████▌ | 427/500 [1:20:21<13:56, 11.46s/it, loss=0.03, lr=0.0001]\n",
            "Steps:  85%|████████▌ | 427/500 [1:20:21<13:56, 11.46s/it, loss=0.0915, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  85%|████████▌ | 427/500 [1:20:23<13:56, 11.46s/it, loss=0.022, lr=0.0001] \n",
            "Steps:  85%|████████▌ | 427/500 [1:20:27<13:56, 11.46s/it, loss=0.0022, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  85%|████████▌ | 427/500 [1:20:30<13:56, 11.46s/it, loss=0.149, lr=0.0001] \n",
            "Steps:  86%|████████▌ | 428/500 [1:20:32<13:53, 11.57s/it, loss=0.149, lr=0.0001]\n",
            "Steps:  86%|████████▌ | 428/500 [1:20:32<13:53, 11.57s/it, loss=0.00837, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  86%|████████▌ | 428/500 [1:20:35<13:53, 11.57s/it, loss=0.155, lr=0.0001]  \n",
            "Steps:  86%|████████▌ | 428/500 [1:20:38<13:53, 11.57s/it, loss=0.0673, lr=0.0001]\n",
            "Steps:  86%|████████▌ | 428/500 [1:20:41<13:53, 11.57s/it, loss=0.025, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  86%|████████▌ | 429/500 [1:20:44<13:41, 11.56s/it, loss=0.025, lr=0.0001]\n",
            "Steps:  86%|████████▌ | 429/500 [1:20:44<13:41, 11.56s/it, loss=0.403, lr=0.0001]\n",
            "Steps:  86%|████████▌ | 429/500 [1:20:47<13:41, 11.56s/it, loss=0.0431, lr=0.0001]\n",
            "Steps:  86%|████████▌ | 429/500 [1:20:50<13:41, 11.56s/it, loss=0.0131, lr=0.0001]\n",
            "Steps:  86%|████████▌ | 430/500 [1:20:53<12:27, 10.67s/it, loss=0.0131, lr=0.0001]\n",
            "Steps:  86%|████████▌ | 430/500 [1:20:53<12:27, 10.67s/it, loss=0.0108, lr=0.0001]\n",
            "Steps:  86%|████████▌ | 430/500 [1:20:56<12:27, 10.67s/it, loss=0.00585, lr=0.0001]\n",
            "Steps:  86%|████████▌ | 430/500 [1:20:59<12:27, 10.67s/it, loss=0.148, lr=0.0001]  INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  86%|████████▌ | 430/500 [1:21:02<12:27, 10.67s/it, loss=0.00383, lr=0.0001]\n",
            "Steps:  86%|████████▌ | 431/500 [1:21:05<12:41, 11.03s/it, loss=0.00383, lr=0.0001]\n",
            "Steps:  86%|████████▌ | 431/500 [1:21:05<12:41, 11.03s/it, loss=0.0801, lr=0.0001] \n",
            "Steps:  86%|████████▌ | 431/500 [1:21:07<12:41, 11.03s/it, loss=0.0984, lr=0.0001]\n",
            "Steps:  86%|████████▌ | 431/500 [1:21:10<12:41, 11.03s/it, loss=0.0242, lr=0.0001]\n",
            "Steps:  86%|████████▌ | 431/500 [1:21:13<12:41, 11.03s/it, loss=0.0399, lr=0.0001]\n",
            "Steps:  86%|████████▋ | 432/500 [1:21:16<12:40, 11.18s/it, loss=0.0399, lr=0.0001]\n",
            "Steps:  86%|████████▋ | 432/500 [1:21:16<12:40, 11.18s/it, loss=0.305, lr=0.0001] \n",
            "Steps:  86%|████████▋ | 432/500 [1:21:19<12:40, 11.18s/it, loss=0.1, lr=0.0001]  \n",
            "Steps:  86%|████████▋ | 432/500 [1:21:22<12:40, 11.18s/it, loss=0.032, lr=0.0001]\n",
            "Steps:  86%|████████▋ | 432/500 [1:21:25<12:40, 11.18s/it, loss=0.0739, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 433/500 [1:21:27<12:33, 11.24s/it, loss=0.0739, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 433/500 [1:21:27<12:33, 11.24s/it, loss=0.276, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  87%|████████▋ | 433/500 [1:21:32<12:33, 11.24s/it, loss=0.0199, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 433/500 [1:21:35<12:33, 11.24s/it, loss=0.00329, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 433/500 [1:21:38<12:33, 11.24s/it, loss=0.00218, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 434/500 [1:21:41<13:07, 11.93s/it, loss=0.00218, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 434/500 [1:21:41<13:07, 11.93s/it, loss=0.0269, lr=0.0001] \n",
            "Steps:  87%|████████▋ | 434/500 [1:21:44<13:07, 11.93s/it, loss=0.276, lr=0.0001] \n",
            "Steps:  87%|████████▋ | 434/500 [1:21:47<13:07, 11.93s/it, loss=0.195, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  87%|████████▋ | 435/500 [1:21:50<11:49, 10.92s/it, loss=0.195, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 435/500 [1:21:50<11:49, 10.92s/it, loss=0.116, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 435/500 [1:21:52<11:49, 10.92s/it, loss=0.0205, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 435/500 [1:21:55<11:49, 10.92s/it, loss=0.153, lr=0.0001] \n",
            "Steps:  87%|████████▋ | 435/500 [1:21:58<11:49, 10.92s/it, loss=0.0129, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 436/500 [1:22:02<12:00, 11.25s/it, loss=0.0129, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 436/500 [1:22:02<12:00, 11.25s/it, loss=0.159, lr=0.0001] \n",
            "Steps:  87%|████████▋ | 436/500 [1:22:04<12:00, 11.25s/it, loss=0.109, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 436/500 [1:22:07<12:00, 11.25s/it, loss=0.0214, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 436/500 [1:22:10<12:00, 11.25s/it, loss=0.0116, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 437/500 [1:22:13<11:52, 11.31s/it, loss=0.0116, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 437/500 [1:22:13<11:52, 11.31s/it, loss=0.15, lr=0.0001]  \n",
            "Steps:  87%|████████▋ | 437/500 [1:22:16<11:52, 11.31s/it, loss=0.00529, lr=0.0001]\n",
            "Steps:  87%|████████▋ | 437/500 [1:22:19<11:52, 11.31s/it, loss=0.0622, lr=0.0001] \n",
            "Steps:  87%|████████▋ | 437/500 [1:22:23<11:52, 11.31s/it, loss=0.00581, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 438/500 [1:22:26<12:11, 11.79s/it, loss=0.00581, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 438/500 [1:22:26<12:11, 11.79s/it, loss=0.108, lr=0.0001]  \n",
            "Steps:  88%|████████▊ | 438/500 [1:22:29<12:11, 11.79s/it, loss=0.231, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 438/500 [1:22:32<12:11, 11.79s/it, loss=0.00631, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 438/500 [1:22:34<12:11, 11.79s/it, loss=0.518, lr=0.0001]  \n",
            "Steps:  88%|████████▊ | 439/500 [1:22:37<11:53, 11.69s/it, loss=0.518, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 439/500 [1:22:37<11:53, 11.69s/it, loss=0.0103, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 439/500 [1:22:40<11:53, 11.69s/it, loss=0.396, lr=0.0001] \n",
            "Steps:  88%|████████▊ | 439/500 [1:22:43<11:53, 11.69s/it, loss=0.136, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 440/500 [1:22:46<10:42, 10.71s/it, loss=0.136, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 440/500 [1:22:46<10:42, 10.71s/it, loss=0.0572, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 440/500 [1:22:49<10:42, 10.71s/it, loss=0.0548, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 440/500 [1:22:52<10:42, 10.71s/it, loss=0.477, lr=0.0001] \n",
            "Steps:  88%|████████▊ | 440/500 [1:22:55<10:42, 10.71s/it, loss=0.117, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  88%|████████▊ | 441/500 [1:22:57<10:46, 10.96s/it, loss=0.117, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 441/500 [1:22:57<10:46, 10.96s/it, loss=0.042, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 441/500 [1:23:00<10:46, 10.96s/it, loss=0.0952, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 441/500 [1:23:03<10:46, 10.96s/it, loss=0.208, lr=0.0001] \n",
            "Steps:  88%|████████▊ | 441/500 [1:23:07<10:46, 10.96s/it, loss=0.0617, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 442/500 [1:23:10<11:10, 11.56s/it, loss=0.0617, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 442/500 [1:23:10<11:10, 11.56s/it, loss=0.067, lr=0.0001] \n",
            "Steps:  88%|████████▊ | 442/500 [1:23:13<11:10, 11.56s/it, loss=0.277, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 442/500 [1:23:16<11:10, 11.56s/it, loss=0.311, lr=0.0001]\n",
            "Steps:  88%|████████▊ | 442/500 [1:23:19<11:10, 11.56s/it, loss=0.144, lr=0.0001]\n",
            "Steps:  89%|████████▊ | 443/500 [1:23:22<11:02, 11.61s/it, loss=0.144, lr=0.0001]\n",
            "Steps:  89%|████████▊ | 443/500 [1:23:22<11:02, 11.61s/it, loss=0.443, lr=0.0001]\n",
            "Steps:  89%|████████▊ | 443/500 [1:23:25<11:02, 11.61s/it, loss=0.023, lr=0.0001]\n",
            "Steps:  89%|████████▊ | 443/500 [1:23:28<11:02, 11.61s/it, loss=0.0832, lr=0.0001]\n",
            "Steps:  89%|████████▊ | 443/500 [1:23:31<11:02, 11.61s/it, loss=0.464, lr=0.0001] \n",
            "Steps:  89%|████████▉ | 444/500 [1:23:34<10:48, 11.58s/it, loss=0.464, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 444/500 [1:23:34<10:48, 11.58s/it, loss=0.0162, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 444/500 [1:23:36<10:48, 11.58s/it, loss=0.171, lr=0.0001] \n",
            "Steps:  89%|████████▉ | 444/500 [1:23:39<10:48, 11.58s/it, loss=0.00139, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 445/500 [1:23:42<09:44, 10.64s/it, loss=0.00139, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 445/500 [1:23:42<09:44, 10.64s/it, loss=0.109, lr=0.0001]  \n",
            "Steps:  89%|████████▉ | 445/500 [1:23:45<09:44, 10.64s/it, loss=0.102, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 445/500 [1:23:48<09:44, 10.64s/it, loss=0.0354, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 445/500 [1:23:51<09:44, 10.64s/it, loss=0.0819, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 446/500 [1:23:54<09:49, 10.93s/it, loss=0.0819, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 446/500 [1:23:54<09:49, 10.93s/it, loss=0.0828, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 446/500 [1:23:56<09:49, 10.93s/it, loss=0.0193, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 446/500 [1:23:59<09:49, 10.93s/it, loss=0.039, lr=0.0001] \n",
            "Steps:  89%|████████▉ | 446/500 [1:24:02<09:49, 10.93s/it, loss=0.00281, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 447/500 [1:24:05<09:47, 11.09s/it, loss=0.00281, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 447/500 [1:24:05<09:47, 11.09s/it, loss=0.217, lr=0.0001]  \n",
            "Steps:  89%|████████▉ | 447/500 [1:24:08<09:47, 11.09s/it, loss=0.254, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 447/500 [1:24:11<09:47, 11.09s/it, loss=0.0283, lr=0.0001]\n",
            "Steps:  89%|████████▉ | 447/500 [1:24:15<09:47, 11.09s/it, loss=0.0327, lr=0.0001]\n",
            "Steps:  90%|████████▉ | 448/500 [1:24:18<10:04, 11.63s/it, loss=0.0327, lr=0.0001]\n",
            "Steps:  90%|████████▉ | 448/500 [1:24:18<10:04, 11.63s/it, loss=0.0862, lr=0.0001]\n",
            "Steps:  90%|████████▉ | 448/500 [1:24:21<10:04, 11.63s/it, loss=0.0259, lr=0.0001]\n",
            "Steps:  90%|████████▉ | 448/500 [1:24:24<10:04, 11.63s/it, loss=0.0663, lr=0.0001]\n",
            "Steps:  90%|████████▉ | 448/500 [1:24:27<10:04, 11.63s/it, loss=0.0176, lr=0.0001]\n",
            "Steps:  90%|████████▉ | 449/500 [1:24:29<09:51, 11.61s/it, loss=0.0176, lr=0.0001]\n",
            "Steps:  90%|████████▉ | 449/500 [1:24:29<09:51, 11.61s/it, loss=0.286, lr=0.0001] INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  90%|████████▉ | 449/500 [1:24:32<09:51, 11.61s/it, loss=0.291, lr=0.0001]\n",
            "Steps:  90%|████████▉ | 449/500 [1:24:36<09:51, 11.61s/it, loss=0.0349, lr=0.0001]\n",
            "Steps:  90%|█████████ | 450/500 [1:24:38<09:00, 10.81s/it, loss=0.0349, lr=0.0001]\n",
            "Steps:  90%|█████████ | 450/500 [1:24:38<09:00, 10.81s/it, loss=0.007, lr=0.0001] \n",
            "Steps:  90%|█████████ | 450/500 [1:24:41<09:00, 10.81s/it, loss=0.104, lr=0.0001]\n",
            "Steps:  90%|█████████ | 450/500 [1:24:44<09:00, 10.81s/it, loss=0.135, lr=0.0001]\n",
            "Steps:  90%|█████████ | 450/500 [1:24:47<09:00, 10.81s/it, loss=0.0144, lr=0.0001]\n",
            "Steps:  90%|█████████ | 451/500 [1:24:50<09:00, 11.04s/it, loss=0.0144, lr=0.0001]\n",
            "Steps:  90%|█████████ | 451/500 [1:24:50<09:00, 11.04s/it, loss=0.167, lr=0.0001] \n",
            "Steps:  90%|█████████ | 451/500 [1:24:53<09:00, 11.04s/it, loss=0.198, lr=0.0001]\n",
            "Steps:  90%|█████████ | 451/500 [1:24:57<09:00, 11.04s/it, loss=0.0214, lr=0.0001]\n",
            "Steps:  90%|█████████ | 451/500 [1:25:00<09:00, 11.04s/it, loss=0.0714, lr=0.0001]\n",
            "Steps:  90%|█████████ | 452/500 [1:25:03<09:16, 11.60s/it, loss=0.0714, lr=0.0001]\n",
            "Steps:  90%|█████████ | 452/500 [1:25:03<09:16, 11.60s/it, loss=0.00457, lr=0.0001]\n",
            "Steps:  90%|█████████ | 452/500 [1:25:06<09:16, 11.60s/it, loss=0.0399, lr=0.0001] \n",
            "Steps:  90%|█████████ | 452/500 [1:25:09<09:16, 11.60s/it, loss=0.457, lr=0.0001] \n",
            "Steps:  90%|█████████ | 452/500 [1:25:12<09:16, 11.60s/it, loss=0.0573, lr=0.0001]\n",
            "Steps:  91%|█████████ | 453/500 [1:25:14<09:04, 11.58s/it, loss=0.0573, lr=0.0001]\n",
            "Steps:  91%|█████████ | 453/500 [1:25:14<09:04, 11.58s/it, loss=0.296, lr=0.0001] \n",
            "Steps:  91%|█████████ | 453/500 [1:25:17<09:04, 11.58s/it, loss=0.0198, lr=0.0001]\n",
            "Steps:  91%|█████████ | 453/500 [1:25:20<09:04, 11.58s/it, loss=0.0567, lr=0.0001]\n",
            "Steps:  91%|█████████ | 453/500 [1:25:23<09:04, 11.58s/it, loss=0.0102, lr=0.0001]\n",
            "Steps:  91%|█████████ | 454/500 [1:25:26<08:56, 11.65s/it, loss=0.0102, lr=0.0001]\n",
            "Steps:  91%|█████████ | 454/500 [1:25:26<08:56, 11.65s/it, loss=0.00776, lr=0.0001]\n",
            "Steps:  91%|█████████ | 454/500 [1:25:29<08:56, 11.65s/it, loss=0.00935, lr=0.0001]\n",
            "Steps:  91%|█████████ | 454/500 [1:25:32<08:56, 11.65s/it, loss=0.00463, lr=0.0001]\n",
            "Steps:  91%|█████████ | 455/500 [1:25:35<08:01, 10.70s/it, loss=0.00463, lr=0.0001]\n",
            "Steps:  91%|█████████ | 455/500 [1:25:35<08:01, 10.70s/it, loss=0.265, lr=0.0001]  \n",
            "Steps:  91%|█████████ | 455/500 [1:25:38<08:01, 10.70s/it, loss=0.00284, lr=0.0001]\n",
            "Steps:  91%|█████████ | 455/500 [1:25:41<08:01, 10.70s/it, loss=0.00733, lr=0.0001]\n",
            "Steps:  91%|█████████ | 455/500 [1:25:43<08:01, 10.70s/it, loss=0.0124, lr=0.0001] \n",
            "Steps:  91%|█████████ | 456/500 [1:25:46<08:01, 10.95s/it, loss=0.0124, lr=0.0001]\n",
            "Steps:  91%|█████████ | 456/500 [1:25:46<08:01, 10.95s/it, loss=0.0358, lr=0.0001]\n",
            "Steps:  91%|█████████ | 456/500 [1:25:49<08:01, 10.95s/it, loss=0.00476, lr=0.0001]\n",
            "Steps:  91%|█████████ | 456/500 [1:25:52<08:01, 10.95s/it, loss=0.00509, lr=0.0001]\n",
            "Steps:  91%|█████████ | 456/500 [1:25:55<08:01, 10.95s/it, loss=0.134, lr=0.0001]  \n",
            "Steps:  91%|█████████▏| 457/500 [1:25:58<08:02, 11.22s/it, loss=0.134, lr=0.0001]\n",
            "Steps:  91%|█████████▏| 457/500 [1:25:58<08:02, 11.22s/it, loss=0.0551, lr=0.0001]\n",
            "Steps:  91%|█████████▏| 457/500 [1:26:01<08:02, 11.22s/it, loss=0.0023, lr=0.0001]\n",
            "Steps:  91%|█████████▏| 457/500 [1:26:04<08:02, 11.22s/it, loss=0.0528, lr=0.0001]\n",
            "Steps:  91%|█████████▏| 457/500 [1:26:09<08:02, 11.22s/it, loss=0.258, lr=0.0001] \n",
            "Steps:  92%|█████████▏| 458/500 [1:26:12<08:22, 11.95s/it, loss=0.258, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 458/500 [1:26:12<08:22, 11.95s/it, loss=0.0289, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 458/500 [1:26:15<08:22, 11.95s/it, loss=0.0414, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 458/500 [1:26:17<08:22, 11.95s/it, loss=0.00256, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 458/500 [1:26:20<08:22, 11.95s/it, loss=0.0336, lr=0.0001] \n",
            "Steps:  92%|█████████▏| 459/500 [1:26:23<08:02, 11.78s/it, loss=0.0336, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 459/500 [1:26:23<08:02, 11.78s/it, loss=0.00505, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 459/500 [1:26:26<08:02, 11.78s/it, loss=0.023, lr=0.0001]  \n",
            "Steps:  92%|█████████▏| 459/500 [1:26:29<08:02, 11.78s/it, loss=0.148, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 460/500 [1:26:32<07:12, 10.81s/it, loss=0.148, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 460/500 [1:26:32<07:12, 10.81s/it, loss=0.00513, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 460/500 [1:26:36<07:12, 10.81s/it, loss=0.0785, lr=0.0001] \n",
            "Steps:  92%|█████████▏| 460/500 [1:26:39<07:12, 10.81s/it, loss=0.00159, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 460/500 [1:26:42<07:12, 10.81s/it, loss=0.203, lr=0.0001]  INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  92%|█████████▏| 461/500 [1:26:45<07:27, 11.48s/it, loss=0.203, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 461/500 [1:26:45<07:27, 11.48s/it, loss=0.0131, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 461/500 [1:26:48<07:27, 11.48s/it, loss=0.0844, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 461/500 [1:26:50<07:27, 11.48s/it, loss=0.15, lr=0.0001]  \n",
            "Steps:  92%|█████████▏| 461/500 [1:26:53<07:27, 11.48s/it, loss=0.0392, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 462/500 [1:26:56<07:17, 11.51s/it, loss=0.0392, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 462/500 [1:26:56<07:17, 11.51s/it, loss=0.172, lr=0.0001] \n",
            "Steps:  92%|█████████▏| 462/500 [1:26:59<07:17, 11.51s/it, loss=0.0379, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 462/500 [1:27:02<07:17, 11.51s/it, loss=0.00197, lr=0.0001]\n",
            "Steps:  92%|█████████▏| 462/500 [1:27:05<07:17, 11.51s/it, loss=0.215, lr=0.0001]  \n",
            "Steps:  93%|█████████▎| 463/500 [1:27:08<07:04, 11.48s/it, loss=0.215, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 463/500 [1:27:08<07:04, 11.48s/it, loss=0.00556, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 463/500 [1:27:11<07:04, 11.48s/it, loss=0.214, lr=0.0001]  \n",
            "Steps:  93%|█████████▎| 463/500 [1:27:13<07:04, 11.48s/it, loss=0.0134, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 463/500 [1:27:16<07:04, 11.48s/it, loss=0.026, lr=0.0001] \n",
            "Steps:  93%|█████████▎| 464/500 [1:27:19<06:52, 11.45s/it, loss=0.026, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 464/500 [1:27:19<06:52, 11.45s/it, loss=0.0478, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 464/500 [1:27:22<06:52, 11.45s/it, loss=0.0398, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 464/500 [1:27:25<06:52, 11.45s/it, loss=0.0067, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 465/500 [1:27:28<06:14, 10.71s/it, loss=0.0067, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 465/500 [1:27:28<06:14, 10.71s/it, loss=0.0939, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 465/500 [1:27:32<06:14, 10.71s/it, loss=0.0414, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 465/500 [1:27:35<06:14, 10.71s/it, loss=0.256, lr=0.0001] \n",
            "Steps:  93%|█████████▎| 465/500 [1:27:38<06:14, 10.71s/it, loss=0.0693, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 466/500 [1:27:41<06:27, 11.39s/it, loss=0.0693, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 466/500 [1:27:41<06:27, 11.39s/it, loss=0.0125, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 466/500 [1:27:44<06:27, 11.39s/it, loss=0.0421, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 466/500 [1:27:47<06:27, 11.39s/it, loss=0.00478, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 466/500 [1:27:50<06:27, 11.39s/it, loss=0.0146, lr=0.0001] \n",
            "Steps:  93%|█████████▎| 467/500 [1:27:53<06:17, 11.43s/it, loss=0.0146, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 467/500 [1:27:53<06:17, 11.43s/it, loss=0.433, lr=0.0001] \n",
            "Steps:  93%|█████████▎| 467/500 [1:27:55<06:17, 11.43s/it, loss=0.00193, lr=0.0001]\n",
            "Steps:  93%|█████████▎| 467/500 [1:27:58<06:17, 11.43s/it, loss=0.0251, lr=0.0001] \n",
            "Steps:  93%|█████████▎| 467/500 [1:28:02<06:17, 11.43s/it, loss=0.213, lr=0.0001] \n",
            "Steps:  94%|█████████▎| 468/500 [1:28:05<06:11, 11.60s/it, loss=0.213, lr=0.0001]\n",
            "Steps:  94%|█████████▎| 468/500 [1:28:05<06:11, 11.60s/it, loss=0.0486, lr=0.0001]\n",
            "Steps:  94%|█████████▎| 468/500 [1:28:07<06:11, 11.60s/it, loss=0.177, lr=0.0001] \n",
            "Steps:  94%|█████████▎| 468/500 [1:28:10<06:11, 11.60s/it, loss=0.261, lr=0.0001]\n",
            "Steps:  94%|█████████▎| 468/500 [1:28:13<06:11, 11.60s/it, loss=0.261, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 469/500 [1:28:16<05:58, 11.56s/it, loss=0.261, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 469/500 [1:28:16<05:58, 11.56s/it, loss=0.452, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 469/500 [1:28:19<05:58, 11.56s/it, loss=0.00574, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 469/500 [1:28:22<05:58, 11.56s/it, loss=0.192, lr=0.0001]  \n",
            "Steps:  94%|█████████▍| 470/500 [1:28:25<05:19, 10.64s/it, loss=0.192, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 470/500 [1:28:25<05:19, 10.64s/it, loss=0.00481, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 470/500 [1:28:27<05:19, 10.64s/it, loss=0.184, lr=0.0001]  \n",
            "Steps:  94%|█████████▍| 470/500 [1:28:30<05:19, 10.64s/it, loss=0.169, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 470/500 [1:28:33<05:19, 10.64s/it, loss=0.0105, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 471/500 [1:28:36<05:16, 10.91s/it, loss=0.0105, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 471/500 [1:28:36<05:16, 10.91s/it, loss=0.0897, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 471/500 [1:28:39<05:16, 10.91s/it, loss=0.129, lr=0.0001] \n",
            "Steps:  94%|█████████▍| 471/500 [1:28:44<05:16, 10.91s/it, loss=0.182, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 471/500 [1:28:47<05:16, 10.91s/it, loss=0.0729, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 472/500 [1:28:50<05:28, 11.74s/it, loss=0.0729, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 472/500 [1:28:50<05:28, 11.74s/it, loss=0.0932, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 472/500 [1:28:53<05:28, 11.74s/it, loss=0.0383, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  94%|█████████▍| 472/500 [1:28:56<05:28, 11.74s/it, loss=0.0821, lr=0.0001]\n",
            "Steps:  94%|█████████▍| 472/500 [1:28:59<05:28, 11.74s/it, loss=0.0666, lr=0.0001]\n",
            "Steps:  95%|█████████▍| 473/500 [1:29:02<05:16, 11.74s/it, loss=0.0666, lr=0.0001]\n",
            "Steps:  95%|█████████▍| 473/500 [1:29:02<05:16, 11.74s/it, loss=0.00217, lr=0.0001]\n",
            "Steps:  95%|█████████▍| 473/500 [1:29:04<05:16, 11.74s/it, loss=0.135, lr=0.0001]  \n",
            "Steps:  95%|█████████▍| 473/500 [1:29:07<05:16, 11.74s/it, loss=0.0807, lr=0.0001]\n",
            "Steps:  95%|█████████▍| 473/500 [1:29:10<05:16, 11.74s/it, loss=0.283, lr=0.0001] \n",
            "Steps:  95%|█████████▍| 474/500 [1:29:13<05:03, 11.68s/it, loss=0.283, lr=0.0001]\n",
            "Steps:  95%|█████████▍| 474/500 [1:29:13<05:03, 11.68s/it, loss=0.0845, lr=0.0001]\n",
            "Steps:  95%|█████████▍| 474/500 [1:29:16<05:03, 11.68s/it, loss=0.209, lr=0.0001] \n",
            "Steps:  95%|█████████▍| 474/500 [1:29:19<05:03, 11.68s/it, loss=0.182, lr=0.0001]\n",
            "Steps:  95%|█████████▌| 475/500 [1:29:22<04:28, 10.73s/it, loss=0.182, lr=0.0001]\n",
            "Steps:  95%|█████████▌| 475/500 [1:29:22<04:28, 10.73s/it, loss=0.142, lr=0.0001]\n",
            "Steps:  95%|█████████▌| 475/500 [1:29:25<04:28, 10.73s/it, loss=0.00278, lr=0.0001]\n",
            "Steps:  95%|█████████▌| 475/500 [1:29:28<04:28, 10.73s/it, loss=0.482, lr=0.0001]  \n",
            "Steps:  95%|█████████▌| 475/500 [1:29:30<04:28, 10.73s/it, loss=0.0271, lr=0.0001]\n",
            "Steps:  95%|█████████▌| 476/500 [1:29:33<04:24, 11.01s/it, loss=0.0271, lr=0.0001]\n",
            "Steps:  95%|█████████▌| 476/500 [1:29:33<04:24, 11.01s/it, loss=0.18, lr=0.0001]  \n",
            "Steps:  95%|█████████▌| 476/500 [1:29:36<04:24, 11.01s/it, loss=0.475, lr=0.0001]\n",
            "Steps:  95%|█████████▌| 476/500 [1:29:39<04:24, 11.01s/it, loss=0.035, lr=0.0001]\n",
            "Steps:  95%|█████████▌| 476/500 [1:29:42<04:24, 11.01s/it, loss=0.0157, lr=0.0001]\n",
            "Steps:  95%|█████████▌| 477/500 [1:29:45<04:16, 11.14s/it, loss=0.0157, lr=0.0001]\n",
            "Steps:  95%|█████████▌| 477/500 [1:29:45<04:16, 11.14s/it, loss=0.0174, lr=0.0001]\n",
            "Steps:  95%|█████████▌| 477/500 [1:29:47<04:16, 11.14s/it, loss=0.00699, lr=0.0001]\n",
            "Steps:  95%|█████████▌| 477/500 [1:29:50<04:16, 11.14s/it, loss=0.0745, lr=0.0001] \n",
            "Steps:  95%|█████████▌| 477/500 [1:29:53<04:16, 11.14s/it, loss=0.143, lr=0.0001] \n",
            "Steps:  96%|█████████▌| 478/500 [1:29:56<04:06, 11.23s/it, loss=0.143, lr=0.0001]\n",
            "Steps:  96%|█████████▌| 478/500 [1:29:56<04:06, 11.23s/it, loss=0.0456, lr=0.0001]\n",
            "Steps:  96%|█████████▌| 478/500 [1:29:59<04:06, 11.23s/it, loss=0.142, lr=0.0001] \n",
            "Steps:  96%|█████████▌| 478/500 [1:30:02<04:06, 11.23s/it, loss=0.118, lr=0.0001]\n",
            "Steps:  96%|█████████▌| 478/500 [1:30:05<04:06, 11.23s/it, loss=0.381, lr=0.0001]\n",
            "Steps:  96%|█████████▌| 479/500 [1:30:08<03:59, 11.41s/it, loss=0.381, lr=0.0001]\n",
            "Steps:  96%|█████████▌| 479/500 [1:30:08<03:59, 11.41s/it, loss=0.0474, lr=0.0001]\n",
            "Steps:  96%|█████████▌| 479/500 [1:30:11<03:59, 11.41s/it, loss=0.00299, lr=0.0001]\n",
            "Steps:  96%|█████████▌| 479/500 [1:30:16<03:59, 11.41s/it, loss=0.0261, lr=0.0001] \n",
            "Steps:  96%|█████████▌| 480/500 [1:30:18<03:42, 11.11s/it, loss=0.0261, lr=0.0001]\n",
            "Steps:  96%|█████████▌| 480/500 [1:30:18<03:42, 11.11s/it, loss=0.00253, lr=0.0001]\n",
            "Steps:  96%|█████████▌| 480/500 [1:30:21<03:42, 11.11s/it, loss=0.0167, lr=0.0001] \n",
            "Steps:  96%|█████████▌| 480/500 [1:30:24<03:42, 11.11s/it, loss=0.0133, lr=0.0001]\n",
            "Steps:  96%|█████████▌| 480/500 [1:30:27<03:42, 11.11s/it, loss=0.0927, lr=0.0001]\n",
            "Steps:  96%|█████████▌| 481/500 [1:30:30<03:33, 11.22s/it, loss=0.0927, lr=0.0001]\n",
            "Steps:  96%|█████████▌| 481/500 [1:30:30<03:33, 11.22s/it, loss=0.124, lr=0.0001] \n",
            "Steps:  96%|█████████▌| 481/500 [1:30:33<03:33, 11.22s/it, loss=0.0181, lr=0.0001]\n",
            "Steps:  96%|█████████▌| 481/500 [1:30:36<03:33, 11.22s/it, loss=0.273, lr=0.0001] \n",
            "Steps:  96%|█████████▌| 481/500 [1:30:38<03:33, 11.22s/it, loss=0.383, lr=0.0001]\n",
            "Steps:  96%|█████████▋| 482/500 [1:30:42<03:25, 11.42s/it, loss=0.383, lr=0.0001]\n",
            "Steps:  96%|█████████▋| 482/500 [1:30:42<03:25, 11.42s/it, loss=0.0477, lr=0.0001]\n",
            "Steps:  96%|█████████▋| 482/500 [1:30:45<03:25, 11.42s/it, loss=0.0803, lr=0.0001]\n",
            "Steps:  96%|█████████▋| 482/500 [1:30:48<03:25, 11.42s/it, loss=0.00815, lr=0.0001]\n",
            "Steps:  96%|█████████▋| 482/500 [1:30:50<03:25, 11.42s/it, loss=0.218, lr=0.0001]  \n",
            "Steps:  97%|█████████▋| 483/500 [1:30:53<03:14, 11.46s/it, loss=0.218, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 483/500 [1:30:53<03:14, 11.46s/it, loss=0.0369, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 483/500 [1:30:56<03:14, 11.46s/it, loss=0.0258, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 483/500 [1:30:59<03:14, 11.46s/it, loss=0.00516, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 483/500 [1:31:03<03:14, 11.46s/it, loss=0.0162, lr=0.0001] \n",
            "Steps:  97%|█████████▋| 484/500 [1:31:06<03:10, 11.91s/it, loss=0.0162, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 484/500 [1:31:06<03:10, 11.91s/it, loss=0.0043, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 484/500 [1:31:09<03:10, 11.91s/it, loss=0.0723, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 484/500 [1:31:12<03:10, 11.91s/it, loss=0.033, lr=0.0001] \n",
            "Steps:  97%|█████████▋| 485/500 [1:31:15<02:43, 10.87s/it, loss=0.033, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 485/500 [1:31:15<02:43, 10.87s/it, loss=0.00364, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  97%|█████████▋| 485/500 [1:31:18<02:43, 10.87s/it, loss=0.00853, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 485/500 [1:31:20<02:43, 10.87s/it, loss=0.0159, lr=0.0001] \n",
            "Steps:  97%|█████████▋| 485/500 [1:31:23<02:43, 10.87s/it, loss=0.397, lr=0.0001] \n",
            "Steps:  97%|█████████▋| 486/500 [1:31:26<02:34, 11.05s/it, loss=0.397, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 486/500 [1:31:26<02:34, 11.05s/it, loss=0.0231, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 486/500 [1:31:29<02:34, 11.05s/it, loss=0.00279, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 486/500 [1:31:32<02:34, 11.05s/it, loss=0.152, lr=0.0001]  \n",
            "Steps:  97%|█████████▋| 486/500 [1:31:35<02:34, 11.05s/it, loss=0.217, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 487/500 [1:31:38<02:25, 11.19s/it, loss=0.217, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 487/500 [1:31:38<02:25, 11.19s/it, loss=0.00907, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 487/500 [1:31:41<02:25, 11.19s/it, loss=0.00248, lr=0.0001]\n",
            "Steps:  97%|█████████▋| 487/500 [1:31:43<02:25, 11.19s/it, loss=0.0714, lr=0.0001] \n",
            "Steps:  97%|█████████▋| 487/500 [1:31:48<02:25, 11.19s/it, loss=0.00529, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 488/500 [1:31:51<02:21, 11.77s/it, loss=0.00529, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 488/500 [1:31:51<02:21, 11.77s/it, loss=0.152, lr=0.0001]  \n",
            "Steps:  98%|█████████▊| 488/500 [1:31:54<02:21, 11.77s/it, loss=0.0138, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 488/500 [1:31:57<02:21, 11.77s/it, loss=0.0145, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 488/500 [1:32:00<02:21, 11.77s/it, loss=0.0198, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 489/500 [1:32:03<02:09, 11.78s/it, loss=0.0198, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 489/500 [1:32:03<02:09, 11.78s/it, loss=0.436, lr=0.0001] \n",
            "Steps:  98%|█████████▊| 489/500 [1:32:05<02:09, 11.78s/it, loss=0.0145, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 489/500 [1:32:08<02:09, 11.78s/it, loss=0.0142, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 490/500 [1:32:11<01:48, 10.80s/it, loss=0.0142, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 490/500 [1:32:11<01:48, 10.80s/it, loss=0.0567, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 490/500 [1:32:14<01:48, 10.80s/it, loss=0.0949, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 490/500 [1:32:19<01:48, 10.80s/it, loss=0.677, lr=0.0001] \n",
            "Steps:  98%|█████████▊| 490/500 [1:32:21<01:48, 10.80s/it, loss=0.0855, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 491/500 [1:32:24<01:43, 11.53s/it, loss=0.0855, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 491/500 [1:32:24<01:43, 11.53s/it, loss=0.0899, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 491/500 [1:32:27<01:43, 11.53s/it, loss=0.00683, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 491/500 [1:32:30<01:43, 11.53s/it, loss=0.414, lr=0.0001]  \n",
            "Steps:  98%|█████████▊| 491/500 [1:32:33<01:43, 11.53s/it, loss=0.117, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 492/500 [1:32:36<01:31, 11.48s/it, loss=0.117, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 492/500 [1:32:36<01:31, 11.48s/it, loss=0.0252, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 492/500 [1:32:39<01:31, 11.48s/it, loss=0.411, lr=0.0001] \n",
            "Steps:  98%|█████████▊| 492/500 [1:32:42<01:31, 11.48s/it, loss=0.0024, lr=0.0001]\n",
            "Steps:  98%|█████████▊| 492/500 [1:32:45<01:31, 11.48s/it, loss=0.069, lr=0.0001] \n",
            "Steps:  99%|█████████▊| 493/500 [1:32:48<01:21, 11.60s/it, loss=0.069, lr=0.0001]\n",
            "Steps:  99%|█████████▊| 493/500 [1:32:48<01:21, 11.60s/it, loss=0.229, lr=0.0001]\n",
            "Steps:  99%|█████████▊| 493/500 [1:32:50<01:21, 11.60s/it, loss=0.0593, lr=0.0001]\n",
            "Steps:  99%|█████████▊| 493/500 [1:32:53<01:21, 11.60s/it, loss=0.103, lr=0.0001] \n",
            "Steps:  99%|█████████▊| 493/500 [1:32:56<01:21, 11.60s/it, loss=0.0342, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 494/500 [1:32:59<01:09, 11.55s/it, loss=0.0342, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 494/500 [1:32:59<01:09, 11.55s/it, loss=0.00389, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 494/500 [1:33:02<01:09, 11.55s/it, loss=0.167, lr=0.0001]  \n",
            "Steps:  99%|█████████▉| 494/500 [1:33:05<01:09, 11.55s/it, loss=0.122, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 495/500 [1:33:08<00:53, 10.64s/it, loss=0.122, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 495/500 [1:33:08<00:53, 10.64s/it, loss=0.0122, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 495/500 [1:33:10<00:53, 10.64s/it, loss=0.0622, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 495/500 [1:33:13<00:53, 10.64s/it, loss=0.0727, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 495/500 [1:33:16<00:53, 10.64s/it, loss=0.0697, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 496/500 [1:33:19<00:43, 10.91s/it, loss=0.0697, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 496/500 [1:33:19<00:43, 10.91s/it, loss=0.0723, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 496/500 [1:33:22<00:43, 10.91s/it, loss=0.00311, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 496/500 [1:33:25<00:43, 10.91s/it, loss=0.107, lr=0.0001]  \n",
            "Steps:  99%|█████████▉| 496/500 [1:33:28<00:43, 10.91s/it, loss=0.0115, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 497/500 [1:33:33<00:35, 11.74s/it, loss=0.0115, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 497/500 [1:33:33<00:35, 11.74s/it, loss=0.0239, lr=0.0001]INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\n",
            "Steps:  99%|█████████▉| 497/500 [1:33:36<00:35, 11.74s/it, loss=0.0313, lr=0.0001]\n",
            "Steps:  99%|█████████▉| 497/500 [1:33:39<00:35, 11.74s/it, loss=0.476, lr=0.0001] \n",
            "Steps:  99%|█████████▉| 497/500 [1:33:41<00:35, 11.74s/it, loss=0.046, lr=0.0001]\n",
            "Steps: 100%|█████████▉| 498/500 [1:33:44<00:23, 11.66s/it, loss=0.046, lr=0.0001]\n",
            "Steps: 100%|█████████▉| 498/500 [1:33:44<00:23, 11.66s/it, loss=0.0716, lr=0.0001]\n",
            "Steps: 100%|█████████▉| 498/500 [1:33:47<00:23, 11.66s/it, loss=0.017, lr=0.0001] \n",
            "Steps: 100%|█████████▉| 498/500 [1:33:50<00:23, 11.66s/it, loss=0.00621, lr=0.0001]\n",
            "Steps: 100%|█████████▉| 498/500 [1:33:53<00:23, 11.66s/it, loss=0.0135, lr=0.0001] \n",
            "Steps: 100%|█████████▉| 499/500 [1:33:56<00:11, 11.70s/it, loss=0.0135, lr=0.0001]\n",
            "Steps: 100%|█████████▉| 499/500 [1:33:56<00:11, 11.70s/it, loss=0.0575, lr=0.0001]\n",
            "Steps: 100%|█████████▉| 499/500 [1:33:59<00:11, 11.70s/it, loss=0.24, lr=0.0001]  \n",
            "Steps: 100%|█████████▉| 499/500 [1:34:02<00:11, 11.70s/it, loss=0.0616, lr=0.0001]\n",
            "Steps: 100%|██████████| 500/500 [1:34:05<00:00, 10.79s/it, loss=0.0616, lr=0.0001]06/09/2024 13:44:15 - INFO - accelerate.accelerator - Saving current state to advertisement-photography-SD15-LoRA/checkpoint-500\n",
            "Model weights saved in advertisement-photography-SD15-LoRA/checkpoint-500/pytorch_lora_weights.safetensors\n",
            "06/09/2024 13:44:15 - INFO - accelerate.checkpointing - Optimizer state saved in advertisement-photography-SD15-LoRA/checkpoint-500/optimizer.bin\n",
            "06/09/2024 13:44:15 - INFO - accelerate.checkpointing - Scheduler state saved in advertisement-photography-SD15-LoRA/checkpoint-500/scheduler.bin\n",
            "06/09/2024 13:44:15 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in advertisement-photography-SD15-LoRA/checkpoint-500/sampler.bin\n",
            "06/09/2024 13:44:15 - INFO - accelerate.checkpointing - Gradient scaler state saved in advertisement-photography-SD15-LoRA/checkpoint-500/scaler.pt\n",
            "06/09/2024 13:44:15 - INFO - accelerate.checkpointing - Random states saved in advertisement-photography-SD15-LoRA/checkpoint-500/random_states_0.pkl\n",
            "INFO     | 2024-06-09 13:44:15 | autotrain.trainers.dreambooth.train:main:916 - Saved state to advertisement-photography-SD15-LoRA/checkpoint-500\n",
            "\n",
            "Steps: 100%|██████████| 500/500 [1:34:05<00:00, 10.79s/it, loss=0.324, lr=0.0001] Model weights saved in advertisement-photography-SD15-LoRA/pytorch_lora_weights.safetensors\n",
            "\n",
            "Steps: 100%|██████████| 500/500 [1:34:05<00:00, 11.29s/it, loss=0.324, lr=0.0001]\n",
            "INFO     | 2024-06-09 13:44:15 | __main__:train:201 - Converting model to Kohya format...\n",
            "\n",
            "optimizer.bin:   0%|          | 0.00/6.59M [00:00<?, ?B/s]\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|          | 0.00/3.23M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "random_states_0.pkl:   0%|          | 0.00/14.3k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "scheduler.bin:   0%|          | 0.00/1.00k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 7 LFS files:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scaler.pt:   0%|          | 0.00/988 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "optimizer.bin:   0%|          | 16.4k/6.59M [00:00<01:39, 66.1kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scaler.pt: 100%|██████████| 988/988 [00:00<00:00, 3.70kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   1%|          | 16.4k/3.23M [00:00<00:54, 58.9kB/s]\u001b[A\n",
            "\n",
            "\n",
            "random_states_0.pkl: 100%|██████████| 14.3k/14.3k [00:00<00:00, 51.4kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "scheduler.bin: 100%|██████████| 1.00k/1.00k [00:00<00:00, 3.47kB/s]\u001b[A\u001b[A\u001b[A\n",
            "optimizer.bin:  68%|██████▊   | 4.49M/6.59M [00:00<00:00, 16.1MB/s]\n",
            "random_states_0.pkl: 100%|██████████| 14.3k/14.3k [00:00<00:00, 39.1kB/s]\n",
            "\n",
            "scheduler.bin: 100%|██████████| 1.00k/1.00k [00:00<00:00, 2.73kB/s]\n",
            "\n",
            "scaler.pt: 100%|██████████| 988/988 [00:00<00:00, 2.68kB/s]\n",
            "\n",
            "optimizer.bin: 100%|██████████| 6.59M/6.59M [00:00<00:00, 12.3MB/s]\n",
            "\n",
            "pytorch_lora_weights.safetensors: 100%|██████████| 3.23M/3.23M [00:00<00:00, 5.55MB/s]\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|          | 0.00/3.23M [00:00<?, ?B/s]\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|          | 0.00/3.24M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 7 LFS files:  14%|█▍        | 1/7 [00:00<00:04,  1.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|██████████| 3.24M/3.24M [00:00<00:00, 13.7MB/s]\n",
            "\n",
            "pytorch_lora_weights.safetensors: 100%|██████████| 3.23M/3.23M [00:00<00:00, 11.1MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 7 LFS files:  86%|████████▌ | 6/7 [00:00<00:00,  7.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Upload 7 LFS files: 100%|██████████| 7/7 [00:00<00:00,  7.06it/s]\n",
            "INFO     | 2024-06-09 13:46:05 | autotrain.app.utils:get_running_jobs:26 - Killing PID: 3535\n",
            "INFO     | 2024-06-09 13:46:05 | autotrain.app.utils:kill_process_by_pid:52 - Sent SIGTERM to process with PID 3535\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/accelerators HTTP/1.1\" 200 OK\n",
            "INFO:     2a09:bac2:4d86:c8::14:27e:0 - \"GET /ui/is_model_training HTTP/1.1\" 200 OK\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-06-09 13:48:36\u001b[0m | \u001b[36mautotrain.cli.run_app\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m133\u001b[0m - \u001b[33m\u001b[1mAttempting to terminate the process...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-09 13:48:36\u001b[0m | \u001b[36mautotrain.cli.run_app\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mProcess terminated by user\u001b[0m\n",
            "INFO     | 2024-06-09 13:48:36 | autotrain.app.ui_routes:graceful_exit:280 - SIGTERM received. Performing cleanup...\n",
            "Exception in thread Thread-2 (handle_output):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autotrain/cli/run_app.py\", line 20, in handle_output\n",
            "    log_file.write(line)\n",
            "ValueError: I/O operation on closed file.\n"
          ]
        }
      ],
      "source": [
        "#@title 🤗 AutoTrain\n",
        "#@markdown In order to use this colab\n",
        "#@markdown - Enter your [Hugging Face Write Token](https://huggingface.co/settings/tokens)\n",
        "#@markdown - Enter your [ngrok auth token](https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "huggingface_token = 'token here' # @param {type:\"string\"}\n",
        "ngrok_token = \"token here\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown\n",
        "#@markdown - Attach appropriate accelerator `Runtime > Change runtime type > Hardware accelerator`\n",
        "#@markdown - click `Runtime > Run all`\n",
        "#@markdown - Follow the link to access the UI\n",
        "#@markdown - Training happens inside this Google Colab\n",
        "#@markdown - report issues / feature requests [here](https://github.com/huggingface/autotrain-advanced/issues)\n",
        "\n",
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = str(huggingface_token)\n",
        "os.environ[\"NGROK_AUTH_TOKEN\"] = str(ngrok_token)\n",
        "os.environ[\"AUTOTRAIN_LOCAL\"] = \"1\"\n",
        "\n",
        "!pip install -U autotrain-advanced > install_logs.txt 2>&1\n",
        "!autotrain app --share"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}